{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf04d1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Library/Frameworks/Python.framework/Versions/3.10/lib/python310.zip', '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10', '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload', '', '/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "from src.training import SegmentationTrainer, TrainingConfig\n",
    "from src.models import build_dual_encoder_mobilenet_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07aa5499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageNet pretrained MobileNetV3-Small weights...\n",
      "âœ“ Successfully loaded ImageNet pretrained MobileNetV3-Small weights\n",
      "Loading ImageNet pretrained MobileNetV3-Small weights for depth encoder...\n",
      "âœ“ Successfully loaded ImageNet pretrained MobileNetV3-Small weights\n",
      "âœ“ Adapted first conv layer for depth input using averaged RGB weights\n",
      "Dual-Encoder UNet-MobileNetV3-SMALL initialized:\n",
      "  Total parameters: 3,340,012\n",
      "  Trainable parameters: 3,340,012\n",
      "  RGB encoder channels: [16, 16, 24, 48, 96]\n",
      "  Depth encoder channels: [16, 16, 24, 48, 96]\n",
      "  Fused channels: [16, 16, 24, 48, 96]\n",
      "Using device: mps\n",
      "EarlyStopping: monitoring 'val_miou' with patience=5 (mode=max)\n"
     ]
    }
   ],
   "source": [
    "config = TrainingConfig(\n",
    "      data_root=\"datasets/NYUDepthv2\",\n",
    "      use_rgb=True,\n",
    "      use_depth=True,\n",
    "      lr=1e-3,\n",
    "      epochs=20,\n",
    "      batch_size=32,\n",
    "      early_stopping_enabled=True,\n",
    "      early_stopping_patience=5,\n",
    "      device=\"auto\",\n",
    "      save_best_path=\"checkpoints/dual_encoder_unet_mobilenet/best2.pth\",\n",
    "      save_latest_path=\"checkpoints/dual_encoder_unet_mobilenet/latest2.pth\",\n",
    "      num_classes=40,\n",
    ")\n",
    "\n",
    "# Create model and train\n",
    "model = build_dual_encoder_mobilenet_unet(num_classes=config.num_classes, variant='small')\n",
    "\n",
    "trainer = SegmentationTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7b1f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3-small encoder frozen: parameters will not be updated during training\n",
      "MobileNetV3-small depth encoder frozen: parameters will not be updated during training\n",
      "Training configuration:\n",
      "  Use RGB: True\n",
      "  Use Depth: True\n",
      "  Input channels: 4\n",
      "  Label mode: nyu40\n",
      "  Num classes: 40\n",
      "Training samples: 795\n",
      "Validation samples: 100\n",
      "Total parameters: 3,340,012\n",
      "Trainable parameters: 1,486,284\n",
      "Starting training for 20 epochs (from epoch 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 | Iter 00001] loss=3.6421\n",
      "[Epoch 1 | Iter 00002] loss=3.6410\n",
      "[Epoch 1 | Iter 00003] loss=3.6289\n",
      "[Epoch 1 | Iter 00004] loss=3.6257\n",
      "[Epoch 1 | Iter 00005] loss=3.6202\n",
      "[Epoch 1 | Iter 00006] loss=3.6090\n",
      "[Epoch 1 | Iter 00007] loss=3.6018\n",
      "[Epoch 1 | Iter 00008] loss=3.5929\n",
      "[Epoch 1 | Iter 00009] loss=3.5838\n",
      "[Epoch 1 | Iter 00010] loss=3.5746\n",
      "[Epoch 1 | Iter 00011] loss=3.5640\n",
      "[Epoch 1 | Iter 00012] loss=3.5527\n",
      "[Epoch 1 | Iter 00013] loss=3.5421\n",
      "[Epoch 1 | Iter 00014] loss=3.5325\n",
      "[Epoch 1 | Iter 00015] loss=3.5227\n",
      "[Epoch 1 | Iter 00016] loss=3.5123\n",
      "[Epoch 1 | Iter 00017] loss=3.5014\n",
      "[Epoch 1 | Iter 00018] loss=3.4896\n",
      "[Epoch 1 | Iter 00019] loss=3.4778\n",
      "[Epoch 1 | Iter 00020] loss=3.4671\n",
      "[Epoch 1 | Iter 00021] loss=3.4550\n",
      "[Epoch 1 | Iter 00022] loss=3.4403\n",
      "[Epoch 1 | Iter 00023] loss=3.4268\n",
      "[Epoch 1 | Iter 00024] loss=3.4132\n",
      "[Epoch 1 | Iter 00025] loss=3.4014\n",
      "[Epoch 1] Train: loss=2.9987 mIoU=0.0240 pixacc=0.3300 (50.1s+31.3s, 15.9 smp/s) | Val: loss=2.8708 mIoU=0.0230 pixacc=0.3733 (16.1s, 6.2 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.0230) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.4s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.3s) size(24.4MB) total(0.7s)\n",
      "â±ï¸  Timing: Save(0.7s) | Total(98.1s) | Breakdown: Train(51.0%) Val(16.4%) Save(0.7%)\n",
      "[Epoch 2 | Iter 00001] loss=3.0743\n",
      "[Epoch 2 | Iter 00002] loss=3.0694\n",
      "[Epoch 2 | Iter 00003] loss=3.0414\n",
      "[Epoch 2 | Iter 00004] loss=3.0400\n",
      "[Epoch 2 | Iter 00005] loss=3.0300\n",
      "[Epoch 2 | Iter 00006] loss=3.0125\n",
      "[Epoch 2 | Iter 00007] loss=3.0105\n",
      "[Epoch 2 | Iter 00008] loss=2.9968\n",
      "[Epoch 2 | Iter 00009] loss=2.9852\n",
      "[Epoch 2 | Iter 00010] loss=2.9648\n",
      "[Epoch 2 | Iter 00011] loss=2.9509\n",
      "[Epoch 2 | Iter 00012] loss=2.9387\n",
      "[Epoch 2 | Iter 00013] loss=2.9191\n",
      "[Epoch 2 | Iter 00014] loss=2.9065\n",
      "[Epoch 2 | Iter 00015] loss=2.9015\n",
      "[Epoch 2 | Iter 00016] loss=2.8884\n",
      "[Epoch 2 | Iter 00017] loss=2.8751\n",
      "[Epoch 2 | Iter 00018] loss=2.8670\n",
      "[Epoch 2 | Iter 00019] loss=2.8546\n",
      "[Epoch 2 | Iter 00020] loss=2.8454\n",
      "[Epoch 2 | Iter 00021] loss=2.8313\n",
      "[Epoch 2 | Iter 00022] loss=2.8150\n",
      "[Epoch 2 | Iter 00023] loss=2.8042\n",
      "[Epoch 2 | Iter 00024] loss=2.7948\n",
      "[Epoch 2 | Iter 00025] loss=2.7857\n",
      "[Epoch 2] Train: loss=2.5759 mIoU=0.0306 pixacc=0.3843 (33.6s+26.3s, 23.6 smp/s) | Val: loss=2.4803 mIoU=0.0276 pixacc=0.4059 (14.8s, 6.8 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.0276) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.4s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.5s) size(24.4MB) total(0.9s)\n",
      "â±ï¸  Timing: Save(0.9s) | Total(75.7s) | Breakdown: Train(44.5%) Val(19.5%) Save(1.2%)\n",
      "[Epoch 3 | Iter 00001] loss=2.5339\n",
      "[Epoch 3 | Iter 00002] loss=2.4655\n",
      "[Epoch 3 | Iter 00003] loss=2.4758\n",
      "[Epoch 3 | Iter 00004] loss=2.4982\n",
      "[Epoch 3 | Iter 00005] loss=2.4582\n",
      "[Epoch 3 | Iter 00006] loss=2.4657\n",
      "[Epoch 3 | Iter 00007] loss=2.4451\n",
      "[Epoch 3 | Iter 00008] loss=2.4359\n",
      "[Epoch 3 | Iter 00009] loss=2.4277\n",
      "[Epoch 3 | Iter 00010] loss=2.4241\n",
      "[Epoch 3 | Iter 00011] loss=2.4106\n",
      "[Epoch 3 | Iter 00012] loss=2.4055\n",
      "[Epoch 3 | Iter 00013] loss=2.4053\n",
      "[Epoch 3 | Iter 00014] loss=2.4007\n",
      "[Epoch 3 | Iter 00015] loss=2.3932\n",
      "[Epoch 3 | Iter 00016] loss=2.3843\n",
      "[Epoch 3 | Iter 00017] loss=2.3860\n",
      "[Epoch 3 | Iter 00018] loss=2.3859\n",
      "[Epoch 3 | Iter 00019] loss=2.3849\n",
      "[Epoch 3 | Iter 00020] loss=2.3785\n",
      "[Epoch 3 | Iter 00021] loss=2.3719\n",
      "[Epoch 3 | Iter 00022] loss=2.3720\n",
      "[Epoch 3 | Iter 00023] loss=2.3702\n",
      "[Epoch 3 | Iter 00024] loss=2.3635\n",
      "[Epoch 3 | Iter 00025] loss=2.3648\n",
      "[Epoch 3] Train: loss=2.4127 mIoU=0.0312 pixacc=0.3945 (34.6s+25.2s, 23.0 smp/s) | Val: loss=2.3646 mIoU=0.0279 pixacc=0.4131 (15.5s, 6.5 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.0279) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.4s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.3s) size(24.4MB) total(0.7s)\n",
      "â±ï¸  Timing: Save(0.7s) | Total(76.0s) | Breakdown: Train(45.6%) Val(20.4%) Save(0.9%)\n",
      "[Epoch 4 | Iter 00001] loss=2.2825\n",
      "[Epoch 4 | Iter 00002] loss=2.2593\n",
      "[Epoch 4 | Iter 00003] loss=2.2661\n",
      "[Epoch 4 | Iter 00004] loss=2.2692\n",
      "[Epoch 4 | Iter 00005] loss=2.2629\n",
      "[Epoch 4 | Iter 00006] loss=2.2700\n",
      "[Epoch 4 | Iter 00007] loss=2.2697\n",
      "[Epoch 4 | Iter 00008] loss=2.2555\n",
      "[Epoch 4 | Iter 00009] loss=2.2458\n",
      "[Epoch 4 | Iter 00010] loss=2.2455\n",
      "[Epoch 4 | Iter 00011] loss=2.2472\n",
      "[Epoch 4 | Iter 00012] loss=2.2530\n",
      "[Epoch 4 | Iter 00013] loss=2.2404\n",
      "[Epoch 4 | Iter 00014] loss=2.2252\n",
      "[Epoch 4 | Iter 00015] loss=2.2192\n",
      "[Epoch 4 | Iter 00016] loss=2.2248\n",
      "[Epoch 4 | Iter 00017] loss=2.2183\n",
      "[Epoch 4 | Iter 00018] loss=2.2224\n",
      "[Epoch 4 | Iter 00019] loss=2.2193\n",
      "[Epoch 4 | Iter 00020] loss=2.2153\n",
      "[Epoch 4 | Iter 00021] loss=2.2103\n",
      "[Epoch 4 | Iter 00022] loss=2.2062\n",
      "[Epoch 4 | Iter 00023] loss=2.2083\n",
      "[Epoch 4 | Iter 00024] loss=2.2053\n",
      "[Epoch 4 | Iter 00025] loss=2.2040\n",
      "[Epoch 4] Train: loss=2.3138 mIoU=0.0350 pixacc=0.4213 (32.9s+26.4s, 24.2 smp/s) | Val: loss=2.3403 mIoU=0.0294 pixacc=0.4219 (15.3s, 6.5 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.0294) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.4s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.4s) latest(0.2s) size(24.4MB) total(1.0s)\n",
      "â±ï¸  Timing: Save(1.0s) | Total(75.6s) | Breakdown: Train(43.5%) Val(20.2%) Save(1.4%)\n",
      "[Epoch 5 | Iter 00001] loss=1.9347\n",
      "[Epoch 5 | Iter 00002] loss=2.0627\n",
      "[Epoch 5 | Iter 00003] loss=2.1047\n",
      "[Epoch 5 | Iter 00004] loss=2.1004\n",
      "[Epoch 5 | Iter 00005] loss=2.0985\n",
      "[Epoch 5 | Iter 00006] loss=2.1106\n",
      "[Epoch 5 | Iter 00007] loss=2.1124\n",
      "[Epoch 5 | Iter 00008] loss=2.1206\n",
      "[Epoch 5 | Iter 00009] loss=2.1172\n",
      "[Epoch 5 | Iter 00010] loss=2.1164\n",
      "[Epoch 5 | Iter 00011] loss=2.1335\n",
      "[Epoch 5 | Iter 00012] loss=2.1300\n",
      "[Epoch 5 | Iter 00013] loss=2.1297\n",
      "[Epoch 5 | Iter 00014] loss=2.1237\n",
      "[Epoch 5 | Iter 00015] loss=2.1277\n",
      "[Epoch 5 | Iter 00016] loss=2.1200\n",
      "[Epoch 5 | Iter 00017] loss=2.1098\n",
      "[Epoch 5 | Iter 00018] loss=2.1078\n",
      "[Epoch 5 | Iter 00019] loss=2.1052\n",
      "[Epoch 5 | Iter 00020] loss=2.0959\n",
      "[Epoch 5 | Iter 00021] loss=2.0892\n",
      "[Epoch 5 | Iter 00022] loss=2.0876\n",
      "[Epoch 5 | Iter 00023] loss=2.0842\n",
      "[Epoch 5 | Iter 00024] loss=2.0866\n",
      "[Epoch 5 | Iter 00025] loss=2.0800\n",
      "[Epoch 5] Train: loss=2.1551 mIoU=0.0367 pixacc=0.4340 (33.8s+25.1s, 23.5 smp/s) | Val: loss=2.2016 mIoU=0.0318 pixacc=0.4347 (15.3s, 6.6 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.0318) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.4s)\n",
      "âœ“ Saved periodic checkpoint to checkpoint_epoch_005.pt (0.3s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.5s) size(24.4MB) total(1.2s)\n",
      "â±ï¸  Timing: Save(1.2s) | Total(75.3s) | Breakdown: Train(44.8%) Val(20.3%) Save(1.6%)\n",
      "[Epoch 6 | Iter 00001] loss=1.9473\n",
      "[Epoch 6 | Iter 00002] loss=1.9915\n",
      "[Epoch 6 | Iter 00003] loss=2.0053\n",
      "[Epoch 6 | Iter 00004] loss=2.0154\n",
      "[Epoch 6 | Iter 00005] loss=1.9880\n",
      "[Epoch 6 | Iter 00006] loss=1.9703\n",
      "[Epoch 6 | Iter 00007] loss=1.9557\n",
      "[Epoch 6 | Iter 00008] loss=1.9390\n",
      "[Epoch 6 | Iter 00009] loss=1.9502\n",
      "[Epoch 6 | Iter 00010] loss=1.9582\n",
      "[Epoch 6 | Iter 00011] loss=1.9608\n",
      "[Epoch 6 | Iter 00012] loss=1.9615\n",
      "[Epoch 6 | Iter 00013] loss=1.9663\n",
      "[Epoch 6 | Iter 00014] loss=1.9625\n",
      "[Epoch 6 | Iter 00015] loss=1.9667\n",
      "[Epoch 6 | Iter 00016] loss=1.9729\n",
      "[Epoch 6 | Iter 00017] loss=1.9735\n",
      "[Epoch 6 | Iter 00018] loss=1.9783\n",
      "[Epoch 6 | Iter 00019] loss=1.9732\n",
      "[Epoch 6 | Iter 00020] loss=1.9714\n",
      "[Epoch 6 | Iter 00021] loss=1.9717\n",
      "[Epoch 6 | Iter 00022] loss=1.9687\n",
      "[Epoch 6 | Iter 00023] loss=1.9674\n",
      "[Epoch 6 | Iter 00024] loss=1.9714\n",
      "[Epoch 6 | Iter 00025] loss=1.9694\n",
      "[Epoch 6] Train: loss=2.0791 mIoU=0.0524 pixacc=0.4675 (33.7s+27.1s, 23.6 smp/s) | Val: loss=2.0873 mIoU=0.0441 pixacc=0.4613 (20.9s, 4.8 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.0441) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.8s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.8s) size(24.4MB) total(1.7s)\n",
      "â±ï¸  Timing: Save(1.7s) | Total(83.3s) | Breakdown: Train(40.4%) Val(25.1%) Save(2.0%)\n",
      "[Epoch 7 | Iter 00001] loss=1.9931\n",
      "[Epoch 7 | Iter 00002] loss=1.9636\n",
      "[Epoch 7 | Iter 00003] loss=1.9241\n",
      "[Epoch 7 | Iter 00004] loss=1.8964\n",
      "[Epoch 7 | Iter 00005] loss=1.9175\n",
      "[Epoch 7 | Iter 00006] loss=1.9073\n",
      "[Epoch 7 | Iter 00007] loss=1.9016\n",
      "[Epoch 7 | Iter 00008] loss=1.8949\n",
      "[Epoch 7 | Iter 00009] loss=1.8965\n",
      "[Epoch 7 | Iter 00010] loss=1.9100\n",
      "[Epoch 7 | Iter 00011] loss=1.9028\n",
      "[Epoch 7 | Iter 00012] loss=1.8966\n",
      "[Epoch 7 | Iter 00013] loss=1.8916\n",
      "[Epoch 7 | Iter 00014] loss=1.8905\n",
      "[Epoch 7 | Iter 00015] loss=1.8924\n",
      "[Epoch 7 | Iter 00016] loss=1.8889\n",
      "[Epoch 7 | Iter 00017] loss=1.8876\n",
      "[Epoch 7 | Iter 00018] loss=1.8903\n",
      "[Epoch 7 | Iter 00019] loss=1.8942\n",
      "[Epoch 7 | Iter 00020] loss=1.8897\n",
      "[Epoch 7 | Iter 00021] loss=1.8812\n",
      "[Epoch 7 | Iter 00022] loss=1.8824\n",
      "[Epoch 7 | Iter 00023] loss=1.8818\n",
      "[Epoch 7 | Iter 00024] loss=1.8762\n",
      "[Epoch 7 | Iter 00025] loss=1.8794\n",
      "[Epoch 7] Train: loss=2.0349 mIoU=0.0539 pixacc=0.4777 (73.1s+38.4s, 10.9 smp/s) | Val: loss=2.0741 mIoU=0.0452 pixacc=0.4661 (27.5s, 3.6 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.0452) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.6s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.6s) size(24.4MB) total(1.2s)\n",
      "â±ï¸  Timing: Save(1.2s) | Total(140.3s) | Breakdown: Train(52.1%) Val(19.6%) Save(0.9%)\n",
      "[Epoch 8 | Iter 00001] loss=1.8039\n",
      "[Epoch 8 | Iter 00002] loss=1.8226\n",
      "[Epoch 8 | Iter 00003] loss=1.7986\n",
      "[Epoch 8 | Iter 00004] loss=1.7835\n",
      "[Epoch 8 | Iter 00005] loss=1.7992\n",
      "[Epoch 8 | Iter 00006] loss=1.8118\n",
      "[Epoch 8 | Iter 00007] loss=1.8334\n",
      "[Epoch 8 | Iter 00008] loss=1.8344\n",
      "[Epoch 8 | Iter 00009] loss=1.8285\n",
      "[Epoch 8 | Iter 00010] loss=1.8342\n",
      "[Epoch 8 | Iter 00011] loss=1.8310\n",
      "[Epoch 8 | Iter 00012] loss=1.8362\n",
      "[Epoch 8 | Iter 00013] loss=1.8392\n",
      "[Epoch 8 | Iter 00014] loss=1.8317\n",
      "[Epoch 8 | Iter 00015] loss=1.8271\n",
      "[Epoch 8 | Iter 00016] loss=1.8231\n",
      "[Epoch 8 | Iter 00017] loss=1.8137\n",
      "[Epoch 8 | Iter 00018] loss=1.8135\n",
      "[Epoch 8 | Iter 00019] loss=1.8145\n",
      "[Epoch 8 | Iter 00020] loss=1.8093\n",
      "[Epoch 8 | Iter 00021] loss=1.8163\n",
      "[Epoch 8 | Iter 00022] loss=1.8169\n",
      "[Epoch 8 | Iter 00023] loss=1.8141\n",
      "[Epoch 8 | Iter 00024] loss=1.8150\n",
      "[Epoch 8 | Iter 00025] loss=1.8141\n",
      "[Epoch 8] Train: loss=1.9874 mIoU=0.0563 pixacc=0.4787 (100.2s+45.0s, 7.9 smp/s) | Val: loss=2.0962 mIoU=0.0446 pixacc=0.4560 (46.7s, 2.1 smp/s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.1s) latest(0.8s) size(24.4MB) total(0.9s)\n",
      "â±ï¸  Timing: Save(0.9s) | Total(192.7s) | Breakdown: Train(52.0%) Val(24.2%) Save(0.5%)\n",
      "[Epoch 9 | Iter 00001] loss=1.7433\n",
      "[Epoch 9 | Iter 00002] loss=1.7560\n",
      "[Epoch 9 | Iter 00003] loss=1.7584\n",
      "[Epoch 9 | Iter 00004] loss=1.7341\n",
      "[Epoch 9 | Iter 00005] loss=1.7327\n",
      "[Epoch 9 | Iter 00006] loss=1.7270\n",
      "[Epoch 9 | Iter 00007] loss=1.7226\n",
      "[Epoch 9 | Iter 00008] loss=1.7219\n",
      "[Epoch 9 | Iter 00009] loss=1.7215\n",
      "[Epoch 9 | Iter 00010] loss=1.7433\n",
      "[Epoch 9 | Iter 00011] loss=1.7454\n",
      "[Epoch 9 | Iter 00012] loss=1.7497\n",
      "[Epoch 9 | Iter 00013] loss=1.7563\n",
      "[Epoch 9 | Iter 00014] loss=1.7522\n",
      "[Epoch 9 | Iter 00015] loss=1.7578\n",
      "[Epoch 9 | Iter 00016] loss=1.7477\n",
      "[Epoch 9 | Iter 00017] loss=1.7499\n",
      "[Epoch 9 | Iter 00018] loss=1.7499\n",
      "[Epoch 9 | Iter 00019] loss=1.7481\n",
      "[Epoch 9 | Iter 00020] loss=1.7435\n",
      "[Epoch 9 | Iter 00021] loss=1.7409\n",
      "[Epoch 9 | Iter 00022] loss=1.7434\n",
      "[Epoch 9 | Iter 00023] loss=1.7452\n",
      "[Epoch 9 | Iter 00024] loss=1.7448\n",
      "[Epoch 9 | Iter 00025] loss=1.7514\n",
      "[Epoch 9] Train: loss=1.9471 mIoU=0.0566 pixacc=0.4787 (68.8s+50.0s, 11.6 smp/s) | Val: loss=2.0169 mIoU=0.0452 pixacc=0.4586 (33.7s, 3.0 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.0452) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.6s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.1s) latest(0.6s) size(24.4MB) total(1.2s)\n",
      "â±ï¸  Timing: Save(1.2s) | Total(153.6s) | Breakdown: Train(44.8%) Val(21.9%) Save(0.8%)\n",
      "[Epoch 10 | Iter 00001] loss=1.7110\n",
      "[Epoch 10 | Iter 00002] loss=1.7260\n",
      "[Epoch 10 | Iter 00003] loss=1.7265\n",
      "[Epoch 10 | Iter 00004] loss=1.6727\n",
      "[Epoch 10 | Iter 00005] loss=1.6648\n",
      "[Epoch 10 | Iter 00006] loss=1.6547\n",
      "[Epoch 10 | Iter 00007] loss=1.6610\n",
      "[Epoch 10 | Iter 00008] loss=1.6838\n",
      "[Epoch 10 | Iter 00009] loss=1.6878\n",
      "[Epoch 10 | Iter 00010] loss=1.6963\n",
      "[Epoch 10 | Iter 00011] loss=1.7046\n",
      "[Epoch 10 | Iter 00012] loss=1.7007\n",
      "[Epoch 10 | Iter 00013] loss=1.7031\n",
      "[Epoch 10 | Iter 00014] loss=1.7060\n",
      "[Epoch 10 | Iter 00015] loss=1.6969\n",
      "[Epoch 10 | Iter 00016] loss=1.6926\n",
      "[Epoch 10 | Iter 00017] loss=1.6836\n",
      "[Epoch 10 | Iter 00018] loss=1.6851\n",
      "[Epoch 10 | Iter 00019] loss=1.6872\n",
      "[Epoch 10 | Iter 00020] loss=1.6835\n",
      "[Epoch 10 | Iter 00021] loss=1.6827\n",
      "[Epoch 10 | Iter 00022] loss=1.6832\n",
      "[Epoch 10 | Iter 00023] loss=1.6874\n",
      "[Epoch 10 | Iter 00024] loss=1.6861\n",
      "[Epoch 10 | Iter 00025] loss=1.6806\n",
      "[Epoch 10] Train: loss=1.8741 mIoU=0.0593 pixacc=0.4907 (54.7s+29.2s, 14.5 smp/s) | Val: loss=1.9970 mIoU=0.0451 pixacc=0.4520 (15.9s, 6.3 smp/s)\n",
      "âœ“ Saved periodic checkpoint to checkpoint_epoch_010.pt (0.2s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.5s) size(24.4MB) total(0.7s)\n",
      "â±ï¸  Timing: Save(0.7s) | Total(100.5s) | Breakdown: Train(54.4%) Val(15.9%) Save(0.7%)\n",
      "[Epoch 11 | Iter 00001] loss=1.7777\n",
      "[Epoch 11 | Iter 00002] loss=1.7260\n",
      "[Epoch 11 | Iter 00003] loss=1.6922\n",
      "[Epoch 11 | Iter 00004] loss=1.6573\n",
      "[Epoch 11 | Iter 00005] loss=1.6543\n",
      "[Epoch 11 | Iter 00006] loss=1.6370\n",
      "[Epoch 11 | Iter 00007] loss=1.6389\n",
      "[Epoch 11 | Iter 00008] loss=1.6302\n",
      "[Epoch 11 | Iter 00009] loss=1.6246\n",
      "[Epoch 11 | Iter 00010] loss=1.6252\n",
      "[Epoch 11 | Iter 00011] loss=1.6284\n",
      "[Epoch 11 | Iter 00012] loss=1.6330\n",
      "[Epoch 11 | Iter 00013] loss=1.6389\n",
      "[Epoch 11 | Iter 00014] loss=1.6300\n",
      "[Epoch 11 | Iter 00015] loss=1.6239\n",
      "[Epoch 11 | Iter 00016] loss=1.6244\n",
      "[Epoch 11 | Iter 00017] loss=1.6254\n",
      "[Epoch 11 | Iter 00018] loss=1.6276\n",
      "[Epoch 11 | Iter 00019] loss=1.6255\n",
      "[Epoch 11 | Iter 00020] loss=1.6266\n",
      "[Epoch 11 | Iter 00021] loss=1.6258\n",
      "[Epoch 11 | Iter 00022] loss=1.6292\n",
      "[Epoch 11 | Iter 00023] loss=1.6289\n",
      "[Epoch 11 | Iter 00024] loss=1.6324\n",
      "[Epoch 11 | Iter 00025] loss=1.6310\n",
      "[Epoch 11] Train: loss=1.7842 mIoU=0.0709 pixacc=0.5188 (33.7s+26.9s, 23.6 smp/s) | Val: loss=1.9898 mIoU=0.0521 pixacc=0.4704 (15.3s, 6.5 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.0521) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.4s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.2s) size(24.4MB) total(0.6s)\n",
      "â±ï¸  Timing: Save(0.6s) | Total(76.4s) | Breakdown: Train(44.1%) Val(20.0%) Save(0.8%)\n",
      "[Epoch 12 | Iter 00001] loss=1.5992\n",
      "[Epoch 12 | Iter 00002] loss=1.5617\n",
      "[Epoch 12 | Iter 00003] loss=1.5714\n",
      "[Epoch 12 | Iter 00004] loss=1.5674\n",
      "[Epoch 12 | Iter 00005] loss=1.5689\n",
      "[Epoch 12 | Iter 00006] loss=1.5602\n",
      "[Epoch 12 | Iter 00007] loss=1.5667\n",
      "[Epoch 12 | Iter 00008] loss=1.5764\n",
      "[Epoch 12 | Iter 00009] loss=1.5803\n",
      "[Epoch 12 | Iter 00010] loss=1.5788\n",
      "[Epoch 12 | Iter 00011] loss=1.5894\n",
      "[Epoch 12 | Iter 00012] loss=1.5950\n",
      "[Epoch 12 | Iter 00013] loss=1.5906\n",
      "[Epoch 12 | Iter 00014] loss=1.5837\n",
      "[Epoch 12 | Iter 00015] loss=1.5802\n",
      "[Epoch 12 | Iter 00016] loss=1.5780\n",
      "[Epoch 12 | Iter 00017] loss=1.5805\n",
      "[Epoch 12 | Iter 00018] loss=1.5825\n",
      "[Epoch 12 | Iter 00019] loss=1.5751\n",
      "[Epoch 12 | Iter 00020] loss=1.5786\n",
      "[Epoch 12 | Iter 00021] loss=1.5767\n",
      "[Epoch 12 | Iter 00022] loss=1.5782\n",
      "[Epoch 12 | Iter 00023] loss=1.5815\n",
      "[Epoch 12 | Iter 00024] loss=1.5795\n",
      "[Epoch 12 | Iter 00025] loss=1.5896\n",
      "[Epoch 12] Train: loss=1.7871 mIoU=0.0721 pixacc=0.5069 (34.0s+25.2s, 23.4 smp/s) | Val: loss=2.0184 mIoU=0.0519 pixacc=0.4446 (15.1s, 6.6 smp/s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.5s) size(24.4MB) total(0.5s)\n",
      "â±ï¸  Timing: Save(0.5s) | Total(74.9s) | Breakdown: Train(45.5%) Val(20.2%) Save(0.6%)\n",
      "[Epoch 13 | Iter 00001] loss=1.4864\n",
      "[Epoch 13 | Iter 00002] loss=1.4491\n",
      "[Epoch 13 | Iter 00003] loss=1.4606\n",
      "[Epoch 13 | Iter 00004] loss=1.5076\n",
      "[Epoch 13 | Iter 00005] loss=1.5071\n",
      "[Epoch 13 | Iter 00006] loss=1.5101\n",
      "[Epoch 13 | Iter 00007] loss=1.5088\n",
      "[Epoch 13 | Iter 00008] loss=1.4923\n",
      "[Epoch 13 | Iter 00009] loss=1.5123\n",
      "[Epoch 13 | Iter 00010] loss=1.5108\n",
      "[Epoch 13 | Iter 00011] loss=1.5304\n",
      "[Epoch 13 | Iter 00012] loss=1.5323\n",
      "[Epoch 13 | Iter 00013] loss=1.5324\n",
      "[Epoch 13 | Iter 00014] loss=1.5387\n",
      "[Epoch 13 | Iter 00015] loss=1.5403\n",
      "[Epoch 13 | Iter 00016] loss=1.5417\n",
      "[Epoch 13 | Iter 00017] loss=1.5362\n",
      "[Epoch 13 | Iter 00018] loss=1.5320\n",
      "[Epoch 13 | Iter 00019] loss=1.5351\n",
      "[Epoch 13 | Iter 00020] loss=1.5292\n",
      "[Epoch 13 | Iter 00021] loss=1.5357\n",
      "[Epoch 13 | Iter 00022] loss=1.5387\n",
      "[Epoch 13 | Iter 00023] loss=1.5377\n",
      "[Epoch 13 | Iter 00024] loss=1.5400\n",
      "[Epoch 13 | Iter 00025] loss=1.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(85271) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85272) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85314) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85315) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train: loss=1.7656 mIoU=0.0825 pixacc=0.5184 (34.3s+27.0s, 23.2 smp/s) | Val: loss=1.9835 mIoU=0.0625 pixacc=0.4545 (15.4s, 6.5 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.0625) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.4s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.5s) size(24.4MB) total(0.9s)\n",
      "â±ï¸  Timing: Save(0.9s) | Total(77.6s) | Breakdown: Train(44.2%) Val(19.8%) Save(1.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(85345) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85346) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14 | Iter 00001] loss=1.5193\n",
      "[Epoch 14 | Iter 00002] loss=1.4829\n",
      "[Epoch 14 | Iter 00003] loss=1.4362\n",
      "[Epoch 14 | Iter 00004] loss=1.4693\n",
      "[Epoch 14 | Iter 00005] loss=1.4988\n",
      "[Epoch 14 | Iter 00006] loss=1.5134\n",
      "[Epoch 14 | Iter 00007] loss=1.5306\n",
      "[Epoch 14 | Iter 00008] loss=1.5312\n",
      "[Epoch 14 | Iter 00009] loss=1.5344\n",
      "[Epoch 14 | Iter 00010] loss=1.5223\n",
      "[Epoch 14 | Iter 00011] loss=1.5230\n",
      "[Epoch 14 | Iter 00012] loss=1.5095\n",
      "[Epoch 14 | Iter 00013] loss=1.5014\n",
      "[Epoch 14 | Iter 00014] loss=1.5021\n",
      "[Epoch 14 | Iter 00015] loss=1.5045\n",
      "[Epoch 14 | Iter 00016] loss=1.5026\n",
      "[Epoch 14 | Iter 00017] loss=1.4962\n",
      "[Epoch 14 | Iter 00018] loss=1.4974\n",
      "[Epoch 14 | Iter 00019] loss=1.5019\n",
      "[Epoch 14 | Iter 00020] loss=1.4984\n",
      "[Epoch 14 | Iter 00021] loss=1.4945\n",
      "[Epoch 14 | Iter 00022] loss=1.4936\n",
      "[Epoch 14 | Iter 00023] loss=1.4960\n",
      "[Epoch 14 | Iter 00024] loss=1.4945\n",
      "[Epoch 14 | Iter 00025] loss=1.4976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(85443) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85444) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85493) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85494) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train: loss=1.6746 mIoU=0.0808 pixacc=0.5297 (34.0s+26.4s, 23.4 smp/s) | Val: loss=1.9479 mIoU=0.0582 pixacc=0.4733 (15.6s, 6.4 smp/s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.5s) size(24.4MB) total(0.5s)\n",
      "â±ï¸  Timing: Save(0.5s) | Total(76.5s) | Breakdown: Train(44.5%) Val(20.4%) Save(0.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(85534) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85535) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15 | Iter 00001] loss=1.5065\n",
      "[Epoch 15 | Iter 00002] loss=1.4507\n",
      "[Epoch 15 | Iter 00003] loss=1.4417\n",
      "[Epoch 15 | Iter 00004] loss=1.4257\n",
      "[Epoch 15 | Iter 00005] loss=1.4298\n",
      "[Epoch 15 | Iter 00006] loss=1.4378\n",
      "[Epoch 15 | Iter 00007] loss=1.4485\n",
      "[Epoch 15 | Iter 00008] loss=1.4596\n",
      "[Epoch 15 | Iter 00009] loss=1.4597\n",
      "[Epoch 15 | Iter 00010] loss=1.4585\n",
      "[Epoch 15 | Iter 00011] loss=1.4515\n",
      "[Epoch 15 | Iter 00012] loss=1.4505\n",
      "[Epoch 15 | Iter 00013] loss=1.4380\n",
      "[Epoch 15 | Iter 00014] loss=1.4360\n",
      "[Epoch 15 | Iter 00015] loss=1.4370\n",
      "[Epoch 15 | Iter 00016] loss=1.4350\n",
      "[Epoch 15 | Iter 00017] loss=1.4408\n",
      "[Epoch 15 | Iter 00018] loss=1.4357\n",
      "[Epoch 15 | Iter 00019] loss=1.4357\n",
      "[Epoch 15 | Iter 00020] loss=1.4404\n",
      "[Epoch 15 | Iter 00021] loss=1.4383\n",
      "[Epoch 15 | Iter 00022] loss=1.4379\n",
      "[Epoch 15 | Iter 00023] loss=1.4365\n",
      "[Epoch 15 | Iter 00024] loss=1.4406\n",
      "[Epoch 15 | Iter 00025] loss=1.4443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(85642) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85643) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85701) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85702) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train: loss=1.5745 mIoU=0.0991 pixacc=0.5585 (33.6s+26.9s, 23.7 smp/s) | Val: loss=1.8479 mIoU=0.0735 pixacc=0.4878 (13.8s, 7.2 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.0735) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.4s)\n",
      "âœ“ Saved periodic checkpoint to checkpoint_epoch_015.pt (0.2s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.3s) size(24.4MB) total(0.9s)\n",
      "â±ï¸  Timing: Save(0.9s) | Total(75.2s) | Breakdown: Train(44.7%) Val(18.4%) Save(1.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(85725) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85726) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16 | Iter 00001] loss=1.3325\n",
      "[Epoch 16 | Iter 00002] loss=1.3684\n",
      "[Epoch 16 | Iter 00003] loss=1.3947\n",
      "[Epoch 16 | Iter 00004] loss=1.4047\n",
      "[Epoch 16 | Iter 00005] loss=1.3969\n",
      "[Epoch 16 | Iter 00006] loss=1.3935\n",
      "[Epoch 16 | Iter 00007] loss=1.3876\n",
      "[Epoch 16 | Iter 00008] loss=1.3931\n",
      "[Epoch 16 | Iter 00009] loss=1.4068\n",
      "[Epoch 16 | Iter 00010] loss=1.4159\n",
      "[Epoch 16 | Iter 00011] loss=1.4196\n",
      "[Epoch 16 | Iter 00012] loss=1.4232\n",
      "[Epoch 16 | Iter 00013] loss=1.4193\n",
      "[Epoch 16 | Iter 00014] loss=1.4175\n",
      "[Epoch 16 | Iter 00015] loss=1.4139\n",
      "[Epoch 16 | Iter 00016] loss=1.4118\n",
      "[Epoch 16 | Iter 00017] loss=1.4113\n",
      "[Epoch 16 | Iter 00018] loss=1.4130\n",
      "[Epoch 16 | Iter 00019] loss=1.4129\n",
      "[Epoch 16 | Iter 00020] loss=1.4093\n",
      "[Epoch 16 | Iter 00021] loss=1.4055\n",
      "[Epoch 16 | Iter 00022] loss=1.4061\n",
      "[Epoch 16 | Iter 00023] loss=1.4073\n",
      "[Epoch 16 | Iter 00024] loss=1.4052\n",
      "[Epoch 16 | Iter 00025] loss=1.4104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(85769) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85770) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85805) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85806) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train: loss=1.6496 mIoU=0.1039 pixacc=0.5502 (32.7s+25.8s, 24.3 smp/s) | Val: loss=1.9481 mIoU=0.0807 pixacc=0.4769 (15.2s, 6.6 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.0807) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.5s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.7s) size(24.4MB) total(1.3s)\n",
      "â±ï¸  Timing: Save(1.3s) | Total(74.9s) | Breakdown: Train(43.7%) Val(20.2%) Save(1.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(85851) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85852) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17 | Iter 00001] loss=1.3257\n",
      "[Epoch 17 | Iter 00002] loss=1.3477\n",
      "[Epoch 17 | Iter 00003] loss=1.3278\n",
      "[Epoch 17 | Iter 00004] loss=1.3771\n",
      "[Epoch 17 | Iter 00005] loss=1.3796\n",
      "[Epoch 17 | Iter 00006] loss=1.3841\n",
      "[Epoch 17 | Iter 00007] loss=1.3895\n",
      "[Epoch 17 | Iter 00008] loss=1.3737\n",
      "[Epoch 17 | Iter 00009] loss=1.3751\n",
      "[Epoch 17 | Iter 00010] loss=1.3739\n",
      "[Epoch 17 | Iter 00011] loss=1.3640\n",
      "[Epoch 17 | Iter 00012] loss=1.3589\n",
      "[Epoch 17 | Iter 00013] loss=1.3590\n",
      "[Epoch 17 | Iter 00014] loss=1.3718\n",
      "[Epoch 17 | Iter 00015] loss=1.3721\n",
      "[Epoch 17 | Iter 00016] loss=1.3775\n",
      "[Epoch 17 | Iter 00017] loss=1.3780\n",
      "[Epoch 17 | Iter 00018] loss=1.3858\n",
      "[Epoch 17 | Iter 00019] loss=1.3841\n",
      "[Epoch 17 | Iter 00020] loss=1.3765\n",
      "[Epoch 17 | Iter 00021] loss=1.3789\n",
      "[Epoch 17 | Iter 00022] loss=1.3795\n",
      "[Epoch 17 | Iter 00023] loss=1.3775\n",
      "[Epoch 17 | Iter 00024] loss=1.3763\n",
      "[Epoch 17 | Iter 00025] loss=1.3785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(85953) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85954) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86055) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86056) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train: loss=1.5817 mIoU=0.1100 pixacc=0.5594 (36.2s+28.9s, 22.0 smp/s) | Val: loss=2.0079 mIoU=0.0791 pixacc=0.4860 (16.1s, 6.2 smp/s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.5s) size(24.4MB) total(0.5s)\n",
      "â±ï¸  Timing: Save(0.5s) | Total(81.7s) | Breakdown: Train(44.3%) Val(19.8%) Save(0.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(86129) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86130) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18 | Iter 00001] loss=1.3929\n",
      "[Epoch 18 | Iter 00002] loss=1.3414\n",
      "[Epoch 18 | Iter 00003] loss=1.3379\n",
      "[Epoch 18 | Iter 00004] loss=1.3338\n",
      "[Epoch 18 | Iter 00005] loss=1.3325\n",
      "[Epoch 18 | Iter 00006] loss=1.3226\n",
      "[Epoch 18 | Iter 00007] loss=1.3344\n",
      "[Epoch 18 | Iter 00008] loss=1.3280\n",
      "[Epoch 18 | Iter 00009] loss=1.3308\n",
      "[Epoch 18 | Iter 00010] loss=1.3406\n",
      "[Epoch 18 | Iter 00011] loss=1.3435\n",
      "[Epoch 18 | Iter 00012] loss=1.3437\n",
      "[Epoch 18 | Iter 00013] loss=1.3498\n",
      "[Epoch 18 | Iter 00014] loss=1.3417\n",
      "[Epoch 18 | Iter 00015] loss=1.3509\n",
      "[Epoch 18 | Iter 00016] loss=1.3508\n",
      "[Epoch 18 | Iter 00017] loss=1.3488\n",
      "[Epoch 18 | Iter 00018] loss=1.3515\n",
      "[Epoch 18 | Iter 00019] loss=1.3524\n",
      "[Epoch 18 | Iter 00020] loss=1.3512\n",
      "[Epoch 18 | Iter 00021] loss=1.3513\n",
      "[Epoch 18 | Iter 00022] loss=1.3531\n",
      "[Epoch 18 | Iter 00023] loss=1.3509\n",
      "[Epoch 18 | Iter 00024] loss=1.3545\n",
      "[Epoch 18 | Iter 00025] loss=1.3523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(86245) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86246) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86292) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86293) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train: loss=1.5196 mIoU=0.1206 pixacc=0.5739 (37.2s+26.3s, 21.4 smp/s) | Val: loss=1.8876 mIoU=0.0899 pixacc=0.5067 (15.2s, 6.6 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.0899) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.4s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.7s) size(24.4MB) total(1.1s)\n",
      "â±ï¸  Timing: Save(1.1s) | Total(79.8s) | Breakdown: Train(46.6%) Val(19.0%) Save(1.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(86310) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86311) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19 | Iter 00001] loss=1.2678\n",
      "[Epoch 19 | Iter 00002] loss=1.3586\n",
      "[Epoch 19 | Iter 00003] loss=1.3334\n",
      "[Epoch 19 | Iter 00004] loss=1.3404\n",
      "[Epoch 19 | Iter 00005] loss=1.3800\n",
      "[Epoch 19 | Iter 00006] loss=1.3382\n",
      "[Epoch 19 | Iter 00007] loss=1.3367\n",
      "[Epoch 19 | Iter 00008] loss=1.3181\n",
      "[Epoch 19 | Iter 00009] loss=1.3255\n",
      "[Epoch 19 | Iter 00010] loss=1.3189\n",
      "[Epoch 19 | Iter 00011] loss=1.3238\n",
      "[Epoch 19 | Iter 00012] loss=1.3314\n",
      "[Epoch 19 | Iter 00013] loss=1.3274\n",
      "[Epoch 19 | Iter 00014] loss=1.3156\n",
      "[Epoch 19 | Iter 00015] loss=1.3192\n",
      "[Epoch 19 | Iter 00016] loss=1.3157\n",
      "[Epoch 19 | Iter 00017] loss=1.3135\n",
      "[Epoch 19 | Iter 00018] loss=1.3148\n",
      "[Epoch 19 | Iter 00019] loss=1.3151\n",
      "[Epoch 19 | Iter 00020] loss=1.3118\n",
      "[Epoch 19 | Iter 00021] loss=1.3099\n",
      "[Epoch 19 | Iter 00022] loss=1.3052\n",
      "[Epoch 19 | Iter 00023] loss=1.3049\n",
      "[Epoch 19 | Iter 00024] loss=1.3063\n",
      "[Epoch 19 | Iter 00025] loss=1.3108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(86361) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86362) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86403) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86404) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train: loss=1.4632 mIoU=0.1313 pixacc=0.5891 (35.3s+27.0s, 22.5 smp/s) | Val: loss=1.8111 mIoU=0.0989 pixacc=0.5213 (15.1s, 6.6 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.0989) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.4s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.7s) size(24.4MB) total(1.1s)\n",
      "â±ï¸  Timing: Save(1.1s) | Total(78.5s) | Breakdown: Train(45.0%) Val(19.2%) Save(1.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(86427) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86428) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20 | Iter 00001] loss=1.2248\n",
      "[Epoch 20 | Iter 00002] loss=1.2489\n",
      "[Epoch 20 | Iter 00003] loss=1.2596\n",
      "[Epoch 20 | Iter 00004] loss=1.2491\n",
      "[Epoch 20 | Iter 00005] loss=1.2718\n",
      "[Epoch 20 | Iter 00006] loss=1.2720\n",
      "[Epoch 20 | Iter 00007] loss=1.2583\n",
      "[Epoch 20 | Iter 00008] loss=1.2404\n",
      "[Epoch 20 | Iter 00009] loss=1.2512\n",
      "[Epoch 20 | Iter 00010] loss=1.2510\n",
      "[Epoch 20 | Iter 00011] loss=1.2560\n",
      "[Epoch 20 | Iter 00012] loss=1.2603\n",
      "[Epoch 20 | Iter 00013] loss=1.2579\n",
      "[Epoch 20 | Iter 00014] loss=1.2677\n",
      "[Epoch 20 | Iter 00015] loss=1.2622\n",
      "[Epoch 20 | Iter 00016] loss=1.2601\n",
      "[Epoch 20 | Iter 00017] loss=1.2584\n",
      "[Epoch 20 | Iter 00018] loss=1.2549\n",
      "[Epoch 20 | Iter 00019] loss=1.2692\n",
      "[Epoch 20 | Iter 00020] loss=1.2712\n",
      "[Epoch 20 | Iter 00021] loss=1.2664\n",
      "[Epoch 20 | Iter 00022] loss=1.2610\n",
      "[Epoch 20 | Iter 00023] loss=1.2534\n",
      "[Epoch 20 | Iter 00024] loss=1.2542\n",
      "[Epoch 20 | Iter 00025] loss=1.2596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(86514) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86515) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86582) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86583) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Train: loss=1.3975 mIoU=0.1415 pixacc=0.6029 (35.1s+27.1s, 22.7 smp/s) | Val: loss=1.8501 mIoU=0.1002 pixacc=0.5126 (15.2s, 6.6 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.1002) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.4s)\n",
      "âœ“ Saved periodic checkpoint to checkpoint_epoch_020.pt (0.2s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.5s) size(24.4MB) total(1.1s)\n",
      "â±ï¸  Timing: Save(1.1s) | Total(78.5s) | Breakdown: Train(44.7%) Val(19.4%) Save(1.5%)\n",
      "Training complete!\n",
      "Best mIoU: 0.1002\n",
      "\n",
      "ðŸ”„ Loading best model for final evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(86611) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(86612) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation metrics: loss=1.8501 mIoU=0.1002, PixelAcc=0.5126 (load: 0.2s, eval: 15.0s)\n"
     ]
    }
   ],
   "source": [
    "model.freeze_backbone()\n",
    "trained_model = trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2cf87a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3-small encoder unfrozen: parameters will be updated during training\n",
      "MobileNetV3-small depth encoder unfrozen: parameters will be updated during training\n",
      "Using device: mps\n",
      "EarlyStopping: monitoring 'val_miou' with patience=5 (mode=max)\n",
      "Training configuration:\n",
      "  Use RGB: True\n",
      "  Use Depth: True\n",
      "  Input channels: 4\n",
      "  Label mode: nyu40\n",
      "  Num classes: 40\n",
      "Training samples: 795\n",
      "Validation samples: 100\n",
      "Total parameters: 3,340,012\n",
      "Trainable parameters: 3,340,012\n",
      "Resuming training from: checkpoints/dual_encoder_unet_mobilenet/latest2.pth\n",
      "âœ“ Resumed from epoch 26\n",
      "âœ“ Training history loaded with 26 epochs\n",
      "âœ“ Best mIoU so far: 0.1200\n",
      "âœ“ No optimizer parameter changes needed\n",
      "Starting training for 30 epochs (from epoch 27)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27 | Iter 00001] loss=1.0208\n",
      "[Epoch 27 | Iter 00002] loss=1.0425\n",
      "[Epoch 27 | Iter 00003] loss=1.0765\n",
      "[Epoch 27 | Iter 00004] loss=1.0673\n",
      "[Epoch 27 | Iter 00005] loss=1.0677\n",
      "[Epoch 27 | Iter 00006] loss=1.0720\n",
      "[Epoch 27 | Iter 00007] loss=1.0662\n",
      "[Epoch 27 | Iter 00008] loss=1.0844\n",
      "[Epoch 27 | Iter 00009] loss=1.0850\n",
      "[Epoch 27 | Iter 00010] loss=1.0894\n",
      "[Epoch 27 | Iter 00011] loss=1.0822\n",
      "[Epoch 27 | Iter 00012] loss=1.0850\n",
      "[Epoch 27 | Iter 00013] loss=1.0873\n",
      "[Epoch 27 | Iter 00014] loss=1.0893\n",
      "[Epoch 27 | Iter 00015] loss=1.0844\n",
      "[Epoch 27 | Iter 00016] loss=1.0851\n",
      "[Epoch 27 | Iter 00017] loss=1.0877\n",
      "[Epoch 27 | Iter 00018] loss=1.0853\n",
      "[Epoch 27 | Iter 00019] loss=1.0885\n",
      "[Epoch 27 | Iter 00020] loss=1.0916\n",
      "[Epoch 27 | Iter 00021] loss=1.0924\n",
      "[Epoch 27 | Iter 00022] loss=1.0876\n",
      "[Epoch 27 | Iter 00023] loss=1.0819\n",
      "[Epoch 27 | Iter 00024] loss=1.0839\n",
      "[Epoch 27 | Iter 00025] loss=1.0817\n",
      "[Epoch 27] Train: loss=1.1420 mIoU=0.1814 pixacc=0.6595 (49.8s+31.6s, 16.0 smp/s) | Val: loss=1.7062 mIoU=0.1207 pixacc=0.5408 (16.8s, 6.0 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.1207) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.8s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.5s) size(37.9MB) total(1.3s)\n",
      "â±ï¸  Timing: Save(1.3s) | Total(99.4s) | Breakdown: Train(50.1%) Val(16.9%) Save(1.3%)\n",
      "âš ï¸  Potential overfitting: Val loss (1.7062) >> Train loss (1.1420), gap: 0.5642\n",
      "[Epoch 28 | Iter 00001] loss=1.1430\n",
      "[Epoch 28 | Iter 00002] loss=1.0810\n",
      "[Epoch 28 | Iter 00003] loss=1.0690\n",
      "[Epoch 28 | Iter 00004] loss=1.0996\n",
      "[Epoch 28 | Iter 00005] loss=1.0896\n",
      "[Epoch 28 | Iter 00006] loss=1.0869\n",
      "[Epoch 28 | Iter 00007] loss=1.0887\n",
      "[Epoch 28 | Iter 00008] loss=1.0854\n",
      "[Epoch 28 | Iter 00009] loss=1.0846\n",
      "[Epoch 28 | Iter 00010] loss=1.0782\n",
      "[Epoch 28 | Iter 00011] loss=1.0811\n",
      "[Epoch 28 | Iter 00012] loss=1.0849\n",
      "[Epoch 28 | Iter 00013] loss=1.0804\n",
      "[Epoch 28 | Iter 00014] loss=1.0768\n",
      "[Epoch 28 | Iter 00015] loss=1.0794\n",
      "[Epoch 28 | Iter 00016] loss=1.0757\n",
      "[Epoch 28 | Iter 00017] loss=1.0698\n",
      "[Epoch 28 | Iter 00018] loss=1.0793\n",
      "[Epoch 28 | Iter 00019] loss=1.0788\n",
      "[Epoch 28 | Iter 00020] loss=1.0798\n",
      "[Epoch 28 | Iter 00021] loss=1.0779\n",
      "[Epoch 28 | Iter 00022] loss=1.0747\n",
      "[Epoch 28 | Iter 00023] loss=1.0712\n",
      "[Epoch 28 | Iter 00024] loss=1.0714\n",
      "[Epoch 28 | Iter 00025] loss=1.0721\n",
      "[Epoch 28] Train: loss=1.1094 mIoU=0.1896 pixacc=0.6692 (52.9s+27.8s, 15.0 smp/s) | Val: loss=1.6911 mIoU=0.1240 pixacc=0.5472 (15.3s, 6.5 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.1240) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.8s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.5s) size(37.9MB) total(1.3s)\n",
      "â±ï¸  Timing: Save(1.3s) | Total(97.3s) | Breakdown: Train(54.4%) Val(15.8%) Save(1.3%)\n",
      "âš ï¸  Potential overfitting: Val loss (1.6911) >> Train loss (1.1094), gap: 0.5817\n",
      "[Epoch 29 | Iter 00001] loss=1.0648\n",
      "[Epoch 29 | Iter 00002] loss=1.0253\n",
      "[Epoch 29 | Iter 00003] loss=1.0499\n",
      "[Epoch 29 | Iter 00004] loss=1.0682\n",
      "[Epoch 29 | Iter 00005] loss=1.0486\n",
      "[Epoch 29 | Iter 00006] loss=1.0630\n",
      "[Epoch 29 | Iter 00007] loss=1.0540\n",
      "[Epoch 29 | Iter 00008] loss=1.0551\n",
      "[Epoch 29 | Iter 00009] loss=1.0434\n",
      "[Epoch 29 | Iter 00010] loss=1.0444\n",
      "[Epoch 29 | Iter 00011] loss=1.0450\n",
      "[Epoch 29 | Iter 00012] loss=1.0453\n",
      "[Epoch 29 | Iter 00013] loss=1.0538\n",
      "[Epoch 29 | Iter 00014] loss=1.0560\n",
      "[Epoch 29 | Iter 00015] loss=1.0537\n",
      "[Epoch 29 | Iter 00016] loss=1.0511\n",
      "[Epoch 29 | Iter 00017] loss=1.0458\n",
      "[Epoch 29 | Iter 00018] loss=1.0472\n",
      "[Epoch 29 | Iter 00019] loss=1.0476\n",
      "[Epoch 29 | Iter 00020] loss=1.0484\n",
      "[Epoch 29 | Iter 00021] loss=1.0494\n",
      "[Epoch 29 | Iter 00022] loss=1.0529\n",
      "[Epoch 29 | Iter 00023] loss=1.0533\n",
      "[Epoch 29 | Iter 00024] loss=1.0516\n",
      "[Epoch 29 | Iter 00025] loss=1.0533\n",
      "[Epoch 29] Train: loss=1.1040 mIoU=0.1934 pixacc=0.6723 (46.1s+26.5s, 17.3 smp/s) | Val: loss=1.6991 mIoU=0.1233 pixacc=0.5437 (16.3s, 6.1 smp/s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.5s) size(37.9MB) total(0.5s)\n",
      "â±ï¸  Timing: Save(0.5s) | Total(89.3s) | Breakdown: Train(51.6%) Val(18.2%) Save(0.6%)\n",
      "âš ï¸  Potential overfitting: Val loss (1.6991) >> Train loss (1.1040), gap: 0.5952\n",
      "[Epoch 30 | Iter 00001] loss=1.0454\n",
      "[Epoch 30 | Iter 00002] loss=1.0651\n",
      "[Epoch 30 | Iter 00003] loss=1.1034\n",
      "[Epoch 30 | Iter 00004] loss=1.1000\n",
      "[Epoch 30 | Iter 00005] loss=1.0899\n",
      "[Epoch 30 | Iter 00006] loss=1.0809\n",
      "[Epoch 30 | Iter 00007] loss=1.0806\n",
      "[Epoch 30 | Iter 00008] loss=1.0727\n",
      "[Epoch 30 | Iter 00009] loss=1.0636\n",
      "[Epoch 30 | Iter 00010] loss=1.0630\n",
      "[Epoch 30 | Iter 00011] loss=1.0630\n",
      "[Epoch 30 | Iter 00012] loss=1.0630\n",
      "[Epoch 30 | Iter 00013] loss=1.0563\n",
      "[Epoch 30 | Iter 00014] loss=1.0493\n",
      "[Epoch 30 | Iter 00015] loss=1.0446\n",
      "[Epoch 30 | Iter 00016] loss=1.0442\n",
      "[Epoch 30 | Iter 00017] loss=1.0432\n",
      "[Epoch 30 | Iter 00018] loss=1.0504\n",
      "[Epoch 30 | Iter 00019] loss=1.0509\n",
      "[Epoch 30 | Iter 00020] loss=1.0490\n",
      "[Epoch 30 | Iter 00021] loss=1.0482\n",
      "[Epoch 30 | Iter 00022] loss=1.0458\n",
      "[Epoch 30 | Iter 00023] loss=1.0490\n",
      "[Epoch 30 | Iter 00024] loss=1.0481\n",
      "[Epoch 30 | Iter 00025] loss=1.0514\n",
      "[Epoch 30] Train: loss=1.0782 mIoU=0.1954 pixacc=0.6770 (61.2s+38.0s, 13.0 smp/s) | Val: loss=1.7045 mIoU=0.1240 pixacc=0.5449 (16.2s, 6.2 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.1240) to checkpoints/dual_encoder_unet_mobilenet/best2.pth (0.8s)\n",
      "âœ“ Saved periodic checkpoint to checkpoint_epoch_030.pt (0.4s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.5s) size(37.9MB) total(1.7s)\n",
      "â±ï¸  Timing: Save(1.7s) | Total(117.1s) | Breakdown: Train(52.3%) Val(13.8%) Save(1.4%)\n",
      "âš ï¸  Potential overfitting: Val loss (1.7045) >> Train loss (1.0782), gap: 0.6263\n",
      "Training complete!\n",
      "Best mIoU: 0.1240\n",
      "\n",
      "ðŸ”„ Loading best model for final evaluation...\n",
      "Final validation metrics: loss=1.7045 mIoU=0.1240, PixelAcc=0.5449 (load: 0.7s, eval: 16.3s)\n"
     ]
    }
   ],
   "source": [
    "model.unfreeze_backbone()\n",
    "config\n",
    "config.epochs = 30\n",
    "config.lr = 1e-4 # lower learning rate for fine-tuning\n",
    "trainer = SegmentationTrainer(config)\n",
    "trained_model = trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a54d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3-small encoder unfrozen: parameters will be updated during training\n",
      "Using device: mps\n",
      "Training configuration:\n",
      "  Use RGB: True\n",
      "  Use Depth: False\n",
      "  Input channels: 3\n",
      "  Label mode: nyu40\n",
      "  Num classes: 40\n",
      "Training samples: 795\n",
      "Validation samples: 100\n",
      "Total parameters: 2,361,960\n",
      "Trainable parameters: 2,361,960\n",
      "Resuming training from: checkpoints/unet_mobilenet/latest2.pth\n",
      "âœ“ Resumed from epoch 30\n",
      "âœ“ Training history loaded with 30 epochs\n",
      "âœ“ Best mIoU so far: 0.1367\n",
      "ðŸ”§ Applied config overrides:\n",
      "  learning_rate: 0.001000 â†’ 0.000100\n",
      "Starting training for 40 epochs (from epoch 31)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31 | Iter 00001] loss=0.8898\n",
      "[Epoch 31 | Iter 00002] loss=0.9343\n",
      "[Epoch 31 | Iter 00003] loss=0.9540\n",
      "[Epoch 31 | Iter 00004] loss=0.9425\n",
      "[Epoch 31 | Iter 00005] loss=0.9420\n",
      "[Epoch 31 | Iter 00006] loss=0.9426\n",
      "[Epoch 31 | Iter 00007] loss=0.9390\n",
      "[Epoch 31 | Iter 00008] loss=0.9503\n",
      "[Epoch 31 | Iter 00009] loss=0.9527\n",
      "[Epoch 31 | Iter 00010] loss=0.9474\n",
      "[Epoch 31 | Iter 00011] loss=0.9365\n",
      "[Epoch 31 | Iter 00012] loss=0.9348\n",
      "[Epoch 31 | Iter 00013] loss=0.9351\n",
      "[Epoch 31 | Iter 00014] loss=0.9344\n",
      "[Epoch 31 | Iter 00015] loss=0.9318\n",
      "[Epoch 31 | Iter 00016] loss=0.9307\n",
      "[Epoch 31 | Iter 00017] loss=0.9302\n",
      "[Epoch 31 | Iter 00018] loss=0.9251\n",
      "[Epoch 31 | Iter 00019] loss=0.9281\n",
      "[Epoch 31 | Iter 00020] loss=0.9283\n",
      "[Epoch 31 | Iter 00021] loss=0.9285\n",
      "[Epoch 31 | Iter 00022] loss=0.9248\n",
      "[Epoch 31 | Iter 00023] loss=0.9185\n",
      "[Epoch 31 | Iter 00024] loss=0.9170\n",
      "[Epoch 31 | Iter 00025] loss=0.9135\n",
      "[Epoch 31] Train: loss=0.8756 mIoU=0.3556 pixacc=0.7464 (35.9s+24.4s, 22.2 smp/s) | Val: loss=1.7044 mIoU=0.1571 pixacc=0.5311 (15.4s, 6.5 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.1571) to checkpoints/unet_mobilenet/best2.pth (0.4s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.7s)\n",
      "â±ï¸  Timing: Save(0.7s) | Total(76.4s) | Breakdown: Train(47.0%) Val(20.2%) Save(0.9%)\n",
      "âš ï¸  Potential overfitting: Train mIoU (0.3556) >> Val mIoU (0.1571), gap: 0.1985\n",
      "âš ï¸  Potential overfitting: Val loss (1.7044) >> Train loss (0.8756), gap: 0.8287\n",
      "[Epoch 32 | Iter 00001] loss=0.9209\n",
      "[Epoch 32 | Iter 00002] loss=0.8694\n",
      "[Epoch 32 | Iter 00003] loss=0.8627\n",
      "[Epoch 32 | Iter 00004] loss=0.8857\n",
      "[Epoch 32 | Iter 00005] loss=0.8726\n",
      "[Epoch 32 | Iter 00006] loss=0.8713\n",
      "[Epoch 32 | Iter 00007] loss=0.8740\n",
      "[Epoch 32 | Iter 00008] loss=0.8747\n",
      "[Epoch 32 | Iter 00009] loss=0.8768\n",
      "[Epoch 32 | Iter 00010] loss=0.8754\n",
      "[Epoch 32 | Iter 00011] loss=0.8758\n",
      "[Epoch 32 | Iter 00012] loss=0.8779\n",
      "[Epoch 32 | Iter 00013] loss=0.8737\n",
      "[Epoch 32 | Iter 00014] loss=0.8684\n",
      "[Epoch 32 | Iter 00015] loss=0.8763\n",
      "[Epoch 32 | Iter 00016] loss=0.8734\n",
      "[Epoch 32 | Iter 00017] loss=0.8682\n",
      "[Epoch 32 | Iter 00018] loss=0.8741\n",
      "[Epoch 32 | Iter 00019] loss=0.8736\n",
      "[Epoch 32 | Iter 00020] loss=0.8744\n",
      "[Epoch 32 | Iter 00021] loss=0.8733\n",
      "[Epoch 32 | Iter 00022] loss=0.8719\n",
      "[Epoch 32 | Iter 00023] loss=0.8705\n",
      "[Epoch 32 | Iter 00024] loss=0.8704\n",
      "[Epoch 32 | Iter 00025] loss=0.8724\n",
      "[Epoch 32] Train: loss=0.8350 mIoU=0.3758 pixacc=0.7591 (39.2s+23.3s, 20.3 smp/s) | Val: loss=1.6739 mIoU=0.1627 pixacc=0.5444 (14.9s, 6.7 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.1627) to checkpoints/unet_mobilenet/best2.pth (0.5s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.3s) size(26.9MB) total(0.7s)\n",
      "â±ï¸  Timing: Save(0.7s) | Total(78.1s) | Breakdown: Train(50.2%) Val(19.0%) Save(0.9%)\n",
      "âš ï¸  Potential overfitting: Train mIoU (0.3758) >> Val mIoU (0.1627), gap: 0.2131\n",
      "âš ï¸  Potential overfitting: Val loss (1.6739) >> Train loss (0.8350), gap: 0.8389\n",
      "[Epoch 33 | Iter 00001] loss=0.8792\n",
      "[Epoch 33 | Iter 00002] loss=0.8426\n",
      "[Epoch 33 | Iter 00003] loss=0.8541\n",
      "[Epoch 33 | Iter 00004] loss=0.8610\n",
      "[Epoch 33 | Iter 00005] loss=0.8419\n",
      "[Epoch 33 | Iter 00006] loss=0.8511\n",
      "[Epoch 33 | Iter 00007] loss=0.8413\n",
      "[Epoch 33 | Iter 00008] loss=0.8399\n",
      "[Epoch 33 | Iter 00009] loss=0.8377\n",
      "[Epoch 33 | Iter 00010] loss=0.8379\n",
      "[Epoch 33 | Iter 00011] loss=0.8375\n",
      "[Epoch 33 | Iter 00012] loss=0.8367\n",
      "[Epoch 33 | Iter 00013] loss=0.8420\n",
      "[Epoch 33 | Iter 00014] loss=0.8414\n",
      "[Epoch 33 | Iter 00015] loss=0.8434\n",
      "[Epoch 33 | Iter 00016] loss=0.8420\n",
      "[Epoch 33 | Iter 00017] loss=0.8399\n",
      "[Epoch 33 | Iter 00018] loss=0.8437\n",
      "[Epoch 33 | Iter 00019] loss=0.8446\n",
      "[Epoch 33 | Iter 00020] loss=0.8445\n",
      "[Epoch 33 | Iter 00021] loss=0.8454\n",
      "[Epoch 33 | Iter 00022] loss=0.8484\n",
      "[Epoch 33 | Iter 00023] loss=0.8490\n",
      "[Epoch 33 | Iter 00024] loss=0.8468\n",
      "[Epoch 33 | Iter 00025] loss=0.8477\n",
      "[Epoch 33] Train: loss=0.8084 mIoU=0.3939 pixacc=0.7684 (36.3s+23.1s, 21.9 smp/s) | Val: loss=1.6669 mIoU=0.1645 pixacc=0.5455 (15.1s, 6.6 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.1645) to checkpoints/unet_mobilenet/best2.pth (0.4s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.7s)\n",
      "â±ï¸  Timing: Save(0.7s) | Total(75.2s) | Breakdown: Train(48.3%) Val(20.1%) Save(0.9%)\n",
      "âš ï¸  Potential overfitting: Train mIoU (0.3939) >> Val mIoU (0.1645), gap: 0.2294\n",
      "âš ï¸  Potential overfitting: Val loss (1.6669) >> Train loss (0.8084), gap: 0.8585\n",
      "[Epoch 34 | Iter 00001] loss=0.8354\n",
      "[Epoch 34 | Iter 00002] loss=0.8503\n",
      "[Epoch 34 | Iter 00003] loss=0.8637\n",
      "[Epoch 34 | Iter 00004] loss=0.8654\n",
      "[Epoch 34 | Iter 00005] loss=0.8594\n",
      "[Epoch 34 | Iter 00006] loss=0.8541\n",
      "[Epoch 34 | Iter 00007] loss=0.8514\n",
      "[Epoch 34 | Iter 00008] loss=0.8481\n",
      "[Epoch 34 | Iter 00009] loss=0.8443\n",
      "[Epoch 34 | Iter 00010] loss=0.8429\n",
      "[Epoch 34 | Iter 00011] loss=0.8465\n",
      "[Epoch 34 | Iter 00012] loss=0.8440\n",
      "[Epoch 34 | Iter 00013] loss=0.8388\n",
      "[Epoch 34 | Iter 00014] loss=0.8347\n",
      "[Epoch 34 | Iter 00015] loss=0.8318\n",
      "[Epoch 34 | Iter 00016] loss=0.8323\n",
      "[Epoch 34 | Iter 00017] loss=0.8314\n",
      "[Epoch 34 | Iter 00018] loss=0.8367\n",
      "[Epoch 34 | Iter 00019] loss=0.8358\n",
      "[Epoch 34 | Iter 00020] loss=0.8328\n",
      "[Epoch 34 | Iter 00021] loss=0.8319\n",
      "[Epoch 34 | Iter 00022] loss=0.8306\n",
      "[Epoch 34 | Iter 00023] loss=0.8325\n",
      "[Epoch 34 | Iter 00024] loss=0.8310\n",
      "[Epoch 34 | Iter 00025] loss=0.8345\n",
      "[Epoch 34] Train: loss=0.7987 mIoU=0.3989 pixacc=0.7715 (36.2s+21.9s, 22.0 smp/s) | Val: loss=1.6694 mIoU=0.1650 pixacc=0.5431 (14.5s, 6.9 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.1650) to checkpoints/unet_mobilenet/best2.pth (0.8s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(1.0s)\n",
      "â±ï¸  Timing: Save(1.0s) | Total(73.6s) | Breakdown: Train(49.1%) Val(19.7%) Save(1.4%)\n",
      "âš ï¸  Potential overfitting: Train mIoU (0.3989) >> Val mIoU (0.1650), gap: 0.2339\n",
      "âš ï¸  Potential overfitting: Val loss (1.6694) >> Train loss (0.7987), gap: 0.8706\n",
      "[Epoch 35 | Iter 00001] loss=0.7574\n",
      "[Epoch 35 | Iter 00002] loss=0.7838\n",
      "[Epoch 35 | Iter 00003] loss=0.7948\n",
      "[Epoch 35 | Iter 00004] loss=0.8146\n",
      "[Epoch 35 | Iter 00005] loss=0.8114\n",
      "[Epoch 35 | Iter 00006] loss=0.8197\n",
      "[Epoch 35 | Iter 00007] loss=0.8299\n",
      "[Epoch 35 | Iter 00008] loss=0.8359\n",
      "[Epoch 35 | Iter 00009] loss=0.8294\n",
      "[Epoch 35 | Iter 00010] loss=0.8312\n",
      "[Epoch 35 | Iter 00011] loss=0.8353\n",
      "[Epoch 35 | Iter 00012] loss=0.8343\n",
      "[Epoch 35 | Iter 00013] loss=0.8322\n",
      "[Epoch 35 | Iter 00014] loss=0.8284\n",
      "[Epoch 35 | Iter 00015] loss=0.8273\n",
      "[Epoch 35 | Iter 00016] loss=0.8275\n",
      "[Epoch 35 | Iter 00017] loss=0.8224\n",
      "[Epoch 35 | Iter 00018] loss=0.8256\n",
      "[Epoch 35 | Iter 00019] loss=0.8277\n",
      "[Epoch 35 | Iter 00020] loss=0.8235\n",
      "[Epoch 35 | Iter 00021] loss=0.8240\n",
      "[Epoch 35 | Iter 00022] loss=0.8251\n",
      "[Epoch 35 | Iter 00023] loss=0.8269\n",
      "[Epoch 35 | Iter 00024] loss=0.8295\n",
      "[Epoch 35 | Iter 00025] loss=0.8272\n",
      "[Epoch 35] Train: loss=0.7797 mIoU=0.4100 pixacc=0.7775 (36.7s+24.2s, 21.7 smp/s) | Val: loss=1.6715 mIoU=0.1663 pixacc=0.5424 (15.0s, 6.7 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.1663) to checkpoints/unet_mobilenet/best2.pth (0.4s)\n",
      "âœ“ Saved periodic checkpoint to checkpoint_epoch_035.pt (0.2s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.9s)\n",
      "â±ï¸  Timing: Save(0.9s) | Total(76.7s) | Breakdown: Train(47.8%) Val(19.6%) Save(1.2%)\n",
      "âš ï¸  Potential overfitting: Train mIoU (0.4100) >> Val mIoU (0.1663), gap: 0.2437\n",
      "âš ï¸  Potential overfitting: Val loss (1.6715) >> Train loss (0.7797), gap: 0.8917\n",
      "[Epoch 36 | Iter 00001] loss=0.7863\n",
      "[Epoch 36 | Iter 00002] loss=0.7862\n",
      "[Epoch 36 | Iter 00003] loss=0.8011\n",
      "[Epoch 36 | Iter 00004] loss=0.8002\n",
      "[Epoch 36 | Iter 00005] loss=0.7995\n",
      "[Epoch 36 | Iter 00006] loss=0.7952\n",
      "[Epoch 36 | Iter 00007] loss=0.7878\n",
      "[Epoch 36 | Iter 00008] loss=0.7900\n",
      "[Epoch 36 | Iter 00009] loss=0.7958\n",
      "[Epoch 36 | Iter 00010] loss=0.8006\n",
      "[Epoch 36 | Iter 00011] loss=0.8024\n",
      "[Epoch 36 | Iter 00012] loss=0.8076\n",
      "[Epoch 36 | Iter 00013] loss=0.8107\n",
      "[Epoch 36 | Iter 00014] loss=0.8091\n",
      "[Epoch 36 | Iter 00015] loss=0.8126\n",
      "[Epoch 36 | Iter 00016] loss=0.8175\n",
      "[Epoch 36 | Iter 00017] loss=0.8148\n",
      "[Epoch 36 | Iter 00018] loss=0.8163\n",
      "[Epoch 36 | Iter 00019] loss=0.8136\n",
      "[Epoch 36 | Iter 00020] loss=0.8121\n",
      "[Epoch 36 | Iter 00021] loss=0.8122\n",
      "[Epoch 36 | Iter 00022] loss=0.8143\n",
      "[Epoch 36 | Iter 00023] loss=0.8145\n",
      "[Epoch 36 | Iter 00024] loss=0.8161\n",
      "[Epoch 36 | Iter 00025] loss=0.8149\n",
      "[Epoch 36] Train: loss=0.7635 mIoU=0.4182 pixacc=0.7822 (37.9s+22.6s, 21.0 smp/s) | Val: loss=1.6738 mIoU=0.1678 pixacc=0.5451 (13.4s, 7.5 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.1678) to checkpoints/unet_mobilenet/best2.pth (0.5s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.7s)\n",
      "â±ï¸  Timing: Save(0.7s) | Total(74.6s) | Breakdown: Train(50.9%) Val(17.9%) Save(0.9%)\n",
      "âš ï¸  Potential overfitting: Train mIoU (0.4182) >> Val mIoU (0.1678), gap: 0.2505\n",
      "âš ï¸  Potential overfitting: Val loss (1.6738) >> Train loss (0.7635), gap: 0.9103\n",
      "[Epoch 37 | Iter 00001] loss=0.7794\n",
      "[Epoch 37 | Iter 00002] loss=0.7857\n",
      "[Epoch 37 | Iter 00003] loss=0.7925\n",
      "[Epoch 37 | Iter 00004] loss=0.7924\n",
      "[Epoch 37 | Iter 00005] loss=0.7920\n",
      "[Epoch 37 | Iter 00006] loss=0.7924\n",
      "[Epoch 37 | Iter 00007] loss=0.8004\n",
      "[Epoch 37 | Iter 00008] loss=0.7991\n",
      "[Epoch 37 | Iter 00009] loss=0.7950\n",
      "[Epoch 37 | Iter 00010] loss=0.8000\n",
      "[Epoch 37 | Iter 00011] loss=0.7991\n",
      "[Epoch 37 | Iter 00012] loss=0.8036\n",
      "[Epoch 37 | Iter 00013] loss=0.8038\n",
      "[Epoch 37 | Iter 00014] loss=0.8019\n",
      "[Epoch 37 | Iter 00015] loss=0.8034\n",
      "[Epoch 37 | Iter 00016] loss=0.8036\n",
      "[Epoch 37 | Iter 00017] loss=0.8051\n",
      "[Epoch 37 | Iter 00018] loss=0.8074\n",
      "[Epoch 37 | Iter 00019] loss=0.8080\n",
      "[Epoch 37 | Iter 00020] loss=0.8103\n",
      "[Epoch 37 | Iter 00021] loss=0.8074\n",
      "[Epoch 37 | Iter 00022] loss=0.8075\n",
      "[Epoch 37 | Iter 00023] loss=0.8069\n",
      "[Epoch 37 | Iter 00024] loss=0.8067\n",
      "[Epoch 37 | Iter 00025] loss=0.8082\n",
      "[Epoch 37] Train: loss=0.7666 mIoU=0.4203 pixacc=0.7820 (36.5s+22.7s, 21.8 smp/s) | Val: loss=1.6694 mIoU=0.1693 pixacc=0.5466 (14.6s, 6.8 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.1693) to checkpoints/unet_mobilenet/best2.pth (0.5s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.3s) size(26.9MB) total(0.8s)\n",
      "â±ï¸  Timing: Save(0.8s) | Total(74.6s) | Breakdown: Train(48.9%) Val(19.6%) Save(1.0%)\n",
      "âš ï¸  Potential overfitting: Train mIoU (0.4203) >> Val mIoU (0.1693), gap: 0.2510\n",
      "âš ï¸  Potential overfitting: Val loss (1.6694) >> Train loss (0.7666), gap: 0.9028\n",
      "[Epoch 38 | Iter 00001] loss=0.7970\n",
      "[Epoch 38 | Iter 00002] loss=0.8136\n",
      "[Epoch 38 | Iter 00003] loss=0.7841\n",
      "[Epoch 38 | Iter 00004] loss=0.7683\n",
      "[Epoch 38 | Iter 00005] loss=0.7811\n",
      "[Epoch 38 | Iter 00006] loss=0.8046\n",
      "[Epoch 38 | Iter 00007] loss=0.8116\n",
      "[Epoch 38 | Iter 00008] loss=0.8091\n",
      "[Epoch 38 | Iter 00009] loss=0.8063\n",
      "[Epoch 38 | Iter 00010] loss=0.8044\n",
      "[Epoch 38 | Iter 00011] loss=0.8044\n",
      "[Epoch 38 | Iter 00012] loss=0.8104\n",
      "[Epoch 38 | Iter 00013] loss=0.8148\n",
      "[Epoch 38 | Iter 00014] loss=0.8129\n",
      "[Epoch 38 | Iter 00015] loss=0.8114\n",
      "[Epoch 38 | Iter 00016] loss=0.8059\n",
      "[Epoch 38 | Iter 00017] loss=0.8032\n",
      "[Epoch 38 | Iter 00018] loss=0.8031\n",
      "[Epoch 38 | Iter 00019] loss=0.8054\n",
      "[Epoch 38 | Iter 00020] loss=0.8028\n",
      "[Epoch 38 | Iter 00021] loss=0.8043\n",
      "[Epoch 38 | Iter 00022] loss=0.8062\n",
      "[Epoch 38 | Iter 00023] loss=0.8038\n",
      "[Epoch 38 | Iter 00024] loss=0.8032\n",
      "[Epoch 38 | Iter 00025] loss=0.8031\n",
      "[Epoch 38] Train: loss=0.7530 mIoU=0.4256 pixacc=0.7850 (36.4s+24.3s, 21.8 smp/s) | Val: loss=1.6784 mIoU=0.1706 pixacc=0.5455 (14.5s, 6.9 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.1706) to checkpoints/unet_mobilenet/best2.pth (0.4s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.7s)\n",
      "â±ï¸  Timing: Save(0.7s) | Total(75.9s) | Breakdown: Train(48.0%) Val(19.1%) Save(0.9%)\n",
      "âš ï¸  Potential overfitting: Train mIoU (0.4256) >> Val mIoU (0.1706), gap: 0.2550\n",
      "âš ï¸  Potential overfitting: Val loss (1.6784) >> Train loss (0.7530), gap: 0.9254\n",
      "[Epoch 39 | Iter 00001] loss=0.7904\n",
      "[Epoch 39 | Iter 00002] loss=0.7984\n",
      "[Epoch 39 | Iter 00003] loss=0.7883\n",
      "[Epoch 39 | Iter 00004] loss=0.7916\n",
      "[Epoch 39 | Iter 00005] loss=0.7866\n",
      "[Epoch 39 | Iter 00006] loss=0.7759\n",
      "[Epoch 39 | Iter 00007] loss=0.7733\n",
      "[Epoch 39 | Iter 00008] loss=0.7713\n",
      "[Epoch 39 | Iter 00009] loss=0.7727\n",
      "[Epoch 39 | Iter 00010] loss=0.7856\n",
      "[Epoch 39 | Iter 00011] loss=0.7911\n",
      "[Epoch 39 | Iter 00012] loss=0.7926\n",
      "[Epoch 39 | Iter 00013] loss=0.7972\n",
      "[Epoch 39 | Iter 00014] loss=0.7954\n",
      "[Epoch 39 | Iter 00015] loss=0.7960\n",
      "[Epoch 39 | Iter 00016] loss=0.7930\n",
      "[Epoch 39 | Iter 00017] loss=0.7933\n",
      "[Epoch 39 | Iter 00018] loss=0.7931\n",
      "[Epoch 39 | Iter 00019] loss=0.7916\n",
      "[Epoch 39 | Iter 00020] loss=0.7892\n",
      "[Epoch 39 | Iter 00021] loss=0.7895\n",
      "[Epoch 39 | Iter 00022] loss=0.7925\n",
      "[Epoch 39 | Iter 00023] loss=0.7912\n",
      "[Epoch 39 | Iter 00024] loss=0.7920\n",
      "[Epoch 39 | Iter 00025] loss=0.7937\n",
      "[Epoch 39] Train: loss=0.7467 mIoU=0.4344 pixacc=0.7879 (37.2s+23.0s, 21.4 smp/s) | Val: loss=1.6739 mIoU=0.1732 pixacc=0.5489 (14.6s, 6.9 smp/s)\n",
      "âœ“ Saved best checkpoint (mIoU=0.1732) to checkpoints/unet_mobilenet/best2.pth (0.4s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.6s)\n",
      "â±ï¸  Timing: Save(0.6s) | Total(75.4s) | Breakdown: Train(49.4%) Val(19.4%) Save(0.8%)\n",
      "âš ï¸  Potential overfitting: Train mIoU (0.4344) >> Val mIoU (0.1732), gap: 0.2613\n",
      "âš ï¸  Potential overfitting: Val loss (1.6739) >> Train loss (0.7467), gap: 0.9271\n",
      "[Epoch 40 | Iter 00001] loss=0.7916\n",
      "[Epoch 40 | Iter 00002] loss=0.7853\n",
      "[Epoch 40 | Iter 00003] loss=0.7735\n",
      "[Epoch 40 | Iter 00004] loss=0.7554\n",
      "[Epoch 40 | Iter 00005] loss=0.7595\n",
      "[Epoch 40 | Iter 00006] loss=0.7622\n",
      "[Epoch 40 | Iter 00007] loss=0.7657\n",
      "[Epoch 40 | Iter 00008] loss=0.7765\n",
      "[Epoch 40 | Iter 00009] loss=0.7816\n",
      "[Epoch 40 | Iter 00010] loss=0.7827\n",
      "[Epoch 40 | Iter 00011] loss=0.7865\n",
      "[Epoch 40 | Iter 00012] loss=0.7885\n",
      "[Epoch 40 | Iter 00013] loss=0.7880\n",
      "[Epoch 40 | Iter 00014] loss=0.7882\n",
      "[Epoch 40 | Iter 00015] loss=0.7848\n",
      "[Epoch 40 | Iter 00016] loss=0.7832\n",
      "[Epoch 40 | Iter 00017] loss=0.7781\n",
      "[Epoch 40 | Iter 00018] loss=0.7779\n",
      "[Epoch 40 | Iter 00019] loss=0.7781\n",
      "[Epoch 40 | Iter 00020] loss=0.7747\n",
      "[Epoch 40 | Iter 00021] loss=0.7743\n",
      "[Epoch 40 | Iter 00022] loss=0.7770\n",
      "[Epoch 40 | Iter 00023] loss=0.7762\n",
      "[Epoch 40 | Iter 00024] loss=0.7766\n",
      "[Epoch 40 | Iter 00025] loss=0.7745\n",
      "[Epoch 40] Train: loss=0.7426 mIoU=0.4390 pixacc=0.7911 (35.5s+22.6s, 22.4 smp/s) | Val: loss=1.6835 mIoU=0.1687 pixacc=0.5464 (13.8s, 7.2 smp/s)\n",
      "âœ“ Saved periodic checkpoint to checkpoint_epoch_040.pt (0.2s)\n",
      "ðŸ’¾ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.5s)\n",
      "â±ï¸  Timing: Save(0.5s) | Total(72.3s) | Breakdown: Train(49.0%) Val(19.1%) Save(0.6%)\n",
      "âš ï¸  Potential overfitting: Train mIoU (0.4390) >> Val mIoU (0.1687), gap: 0.2703\n",
      "âš ï¸  Potential overfitting: Val loss (1.6835) >> Train loss (0.7426), gap: 0.9409\n",
      "Training complete!\n",
      "Best mIoU: 0.1732\n",
      "\n",
      "ðŸ”„ Loading best model for final evaluation...\n",
      "Final validation metrics: loss=1.6739 mIoU=0.1732, PixelAcc=0.5489 (load: 0.2s, eval: 14.6s)\n"
     ]
    }
   ],
   "source": [
    "# reload SegmentationTrainer with new config\n",
    "model.unfreeze_backbone()\n",
    "config_stage_3 = config\n",
    "config_stage_3.epochs = 100 # go essentially until early stopping\n",
    "config_stage_3.lr = 1e-4 # lower learning rate for fine-tuning\n",
    "trainer = SegmentationTrainer(config_stage_3)\n",
    "trained_model = trainer.train(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
