{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf04d1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Library/Frameworks/Python.framework/Versions/3.10/lib/python310.zip', '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10', '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload', '', '/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "from src.training import SegmentationTrainer, TrainingConfig\n",
    "from src.models import build_dual_encoder_mobilenet_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07aa5499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageNet pretrained MobileNetV3-Small weights...\n",
      "‚úì Successfully loaded ImageNet pretrained MobileNetV3-Small weights\n",
      "Loading ImageNet pretrained MobileNetV3-Small weights for depth encoder...\n",
      "‚úì Successfully loaded ImageNet pretrained MobileNetV3-Small weights\n",
      "‚úì Adapted first conv layer for depth input using weighted RGB initialization (green-favored)\n",
      "Dual-Encoder UNet-MobileNetV3-SMALL initialized:\n",
      "  Total parameters: 3,321,105\n",
      "  Trainable parameters: 3,321,105\n",
      "  RGB encoder channels: [16, 16, 24, 48, 96]\n",
      "  Depth encoder channels: [16, 16, 24, 48, 96]\n",
      "  Fused channels: [16, 16, 24, 48, 96]\n",
      "Using device: mps\n",
      "EarlyStopping: monitoring 'val_miou' with patience=5 (mode=max)\n"
     ]
    }
   ],
   "source": [
    "config = TrainingConfig(\n",
    "      data_root=\"datasets/NYUDepthv2\",\n",
    "      use_rgb=True,\n",
    "      use_depth=True,\n",
    "      lr=1e-3,\n",
    "      epochs=20,\n",
    "      batch_size=32,\n",
    "      early_stopping_enabled=True,\n",
    "      early_stopping_patience=5,\n",
    "      device=\"auto\",\n",
    "      save_best_path=\"checkpoints/dual_encoder_unet_mobilenet/best.pth\",\n",
    "      save_latest_path=\"checkpoints/dual_encoder_unet_mobilenet/latest.pth\",\n",
    "      num_classes=40,\n",
    ")\n",
    "\n",
    "# Create model and train\n",
    "model = build_dual_encoder_mobilenet_unet(num_classes=config.num_classes, variant='small')\n",
    "\n",
    "trainer = SegmentationTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7b1f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3-small encoder frozen: parameters will not be updated during training\n",
      "MobileNetV3-small depth encoder frozen: parameters will not be updated during training\n",
      "Training configuration:\n",
      "  Use RGB: True\n",
      "  Use Depth: True\n",
      "  Input channels: 4\n",
      "  Label mode: nyu40\n",
      "  Num classes: 40\n",
      "Training samples: 795\n",
      "Validation samples: 100\n",
      "Total parameters: 3,321,105\n",
      "Trainable parameters: 1,467,377\n",
      "Starting training for 20 epochs (from epoch 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 | Iter 00001] loss=3.7611\n",
      "[Epoch 1 | Iter 00002] loss=3.7606\n",
      "[Epoch 1 | Iter 00003] loss=3.7483\n",
      "[Epoch 1 | Iter 00004] loss=3.7390\n",
      "[Epoch 1 | Iter 00005] loss=3.7318\n",
      "[Epoch 1 | Iter 00006] loss=3.7234\n",
      "[Epoch 1 | Iter 00007] loss=3.7167\n",
      "[Epoch 1 | Iter 00008] loss=3.7093\n",
      "[Epoch 1 | Iter 00009] loss=3.6991\n",
      "[Epoch 1 | Iter 00010] loss=3.6907\n",
      "[Epoch 1 | Iter 00011] loss=3.6805\n",
      "[Epoch 1 | Iter 00012] loss=3.6716\n",
      "[Epoch 1 | Iter 00013] loss=3.6625\n",
      "[Epoch 1 | Iter 00014] loss=3.6522\n",
      "[Epoch 1 | Iter 00015] loss=3.6417\n",
      "[Epoch 1 | Iter 00016] loss=3.6308\n",
      "[Epoch 1 | Iter 00017] loss=3.6216\n",
      "[Epoch 1 | Iter 00018] loss=3.6108\n",
      "[Epoch 1 | Iter 00019] loss=3.6003\n",
      "[Epoch 1 | Iter 00020] loss=3.5908\n",
      "[Epoch 1 | Iter 00021] loss=3.5793\n",
      "[Epoch 1 | Iter 00022] loss=3.5671\n",
      "[Epoch 1 | Iter 00023] loss=3.5547\n",
      "[Epoch 1 | Iter 00024] loss=3.5433\n",
      "[Epoch 1 | Iter 00025] loss=3.5317\n",
      "[Epoch 1] Train: loss=2.9916 mIoU=0.0355 pixacc=0.3624 (36.2s+27.5s, 22.0 smp/s) | Val: loss=2.8344 mIoU=0.0317 pixacc=0.3719 (15.4s, 6.5 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0317) to checkpoints/dual_encoder_unet_mobilenet/best.pth (53.1s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(24.2MB) total(53.4s)\n",
      "‚è±Ô∏è  Timing: Save(53.5s) | Total(132.5s) | Breakdown: Train(27.3%) Val(11.6%) Save(40.3%)\n",
      "[Epoch 2 | Iter 00001] loss=3.2351\n",
      "[Epoch 2 | Iter 00002] loss=3.2341\n",
      "[Epoch 2 | Iter 00003] loss=3.2058\n",
      "[Epoch 2 | Iter 00004] loss=3.2061\n",
      "[Epoch 2 | Iter 00005] loss=3.1896\n",
      "[Epoch 2 | Iter 00006] loss=3.1735\n",
      "[Epoch 2 | Iter 00007] loss=3.1691\n",
      "[Epoch 2 | Iter 00008] loss=3.1542\n",
      "[Epoch 2 | Iter 00009] loss=3.1397\n",
      "[Epoch 2 | Iter 00010] loss=3.1205\n",
      "[Epoch 2 | Iter 00011] loss=3.1086\n",
      "[Epoch 2 | Iter 00012] loss=3.0972\n",
      "[Epoch 2 | Iter 00013] loss=3.0792\n",
      "[Epoch 2 | Iter 00014] loss=3.0659\n",
      "[Epoch 2 | Iter 00015] loss=3.0584\n",
      "[Epoch 2 | Iter 00016] loss=3.0441\n",
      "[Epoch 2 | Iter 00017] loss=3.0306\n",
      "[Epoch 2 | Iter 00018] loss=3.0212\n",
      "[Epoch 2 | Iter 00019] loss=3.0089\n",
      "[Epoch 2 | Iter 00020] loss=2.9990\n",
      "[Epoch 2 | Iter 00021] loss=2.9851\n",
      "[Epoch 2 | Iter 00022] loss=2.9680\n",
      "[Epoch 2 | Iter 00023] loss=2.9560\n",
      "[Epoch 2 | Iter 00024] loss=2.9454\n",
      "[Epoch 2 | Iter 00025] loss=2.9339\n",
      "[Epoch 2] Train: loss=2.7478 mIoU=0.0366 pixacc=0.3737 (44.9s+72.7s, 17.7 smp/s) | Val: loss=2.5407 mIoU=0.0331 pixacc=0.3838 (13.9s, 7.2 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0331) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.5s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.5s) size(24.2MB) total(1.0s)\n",
      "‚è±Ô∏è  Timing: Save(1.0s) | Total(132.5s) | Breakdown: Train(33.9%) Val(10.5%) Save(0.8%)\n",
      "[Epoch 3 | Iter 00001] loss=2.6475\n",
      "[Epoch 3 | Iter 00002] loss=2.5759\n",
      "[Epoch 3 | Iter 00003] loss=2.5884\n",
      "[Epoch 3 | Iter 00004] loss=2.6022\n",
      "[Epoch 3 | Iter 00005] loss=2.5637\n",
      "[Epoch 3 | Iter 00006] loss=2.5631\n",
      "[Epoch 3 | Iter 00007] loss=2.5450\n",
      "[Epoch 3 | Iter 00008] loss=2.5391\n",
      "[Epoch 3 | Iter 00009] loss=2.5298\n",
      "[Epoch 3 | Iter 00010] loss=2.5271\n",
      "[Epoch 3 | Iter 00011] loss=2.5167\n",
      "[Epoch 3 | Iter 00012] loss=2.5115\n",
      "[Epoch 3 | Iter 00013] loss=2.5097\n",
      "[Epoch 3 | Iter 00014] loss=2.5040\n",
      "[Epoch 3 | Iter 00015] loss=2.4991\n",
      "[Epoch 3 | Iter 00016] loss=2.4874\n",
      "[Epoch 3 | Iter 00017] loss=2.4877\n",
      "[Epoch 3 | Iter 00018] loss=2.4844\n",
      "[Epoch 3 | Iter 00019] loss=2.4826\n",
      "[Epoch 3 | Iter 00020] loss=2.4775\n",
      "[Epoch 3 | Iter 00021] loss=2.4698\n",
      "[Epoch 3 | Iter 00022] loss=2.4686\n",
      "[Epoch 3 | Iter 00023] loss=2.4661\n",
      "[Epoch 3 | Iter 00024] loss=2.4584\n",
      "[Epoch 3 | Iter 00025] loss=2.4569\n",
      "[Epoch 3] Train: loss=2.3857 mIoU=0.0342 pixacc=0.4171 (87.7s+25.5s, 9.1 smp/s) | Val: loss=2.3136 mIoU=0.0302 pixacc=0.4273 (15.1s, 6.6 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.6s) size(24.2MB) total(0.6s)\n",
      "‚è±Ô∏è  Timing: Save(0.6s) | Total(128.8s) | Breakdown: Train(68.1%) Val(11.7%) Save(0.4%)\n",
      "[Epoch 4 | Iter 00001] loss=2.3812\n",
      "[Epoch 4 | Iter 00002] loss=2.3404\n",
      "[Epoch 4 | Iter 00003] loss=2.3366\n",
      "[Epoch 4 | Iter 00004] loss=2.3359\n",
      "[Epoch 4 | Iter 00005] loss=2.3317\n",
      "[Epoch 4 | Iter 00006] loss=2.3366\n",
      "[Epoch 4 | Iter 00007] loss=2.3362\n",
      "[Epoch 4 | Iter 00008] loss=2.3173\n",
      "[Epoch 4 | Iter 00009] loss=2.3056\n",
      "[Epoch 4 | Iter 00010] loss=2.3043\n",
      "[Epoch 4 | Iter 00011] loss=2.3085\n",
      "[Epoch 4 | Iter 00012] loss=2.3141\n",
      "[Epoch 4 | Iter 00013] loss=2.3036\n",
      "[Epoch 4 | Iter 00014] loss=2.2869\n",
      "[Epoch 4 | Iter 00015] loss=2.2798\n",
      "[Epoch 4 | Iter 00016] loss=2.2857\n",
      "[Epoch 4 | Iter 00017] loss=2.2797\n",
      "[Epoch 4 | Iter 00018] loss=2.2823\n",
      "[Epoch 4 | Iter 00019] loss=2.2792\n",
      "[Epoch 4 | Iter 00020] loss=2.2754\n",
      "[Epoch 4 | Iter 00021] loss=2.2701\n",
      "[Epoch 4 | Iter 00022] loss=2.2660\n",
      "[Epoch 4 | Iter 00023] loss=2.2673\n",
      "[Epoch 4 | Iter 00024] loss=2.2626\n",
      "[Epoch 4 | Iter 00025] loss=2.2628\n",
      "[Epoch 4] Train: loss=2.2686 mIoU=0.0338 pixacc=0.4224 (39.5s+25.9s, 20.1 smp/s) | Val: loss=2.2231 mIoU=0.0297 pixacc=0.4366 (14.1s, 7.1 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(24.2MB) total(0.3s)\n",
      "‚è±Ô∏è  Timing: Save(0.3s) | Total(79.8s) | Breakdown: Train(49.5%) Val(17.7%) Save(0.3%)\n",
      "[Epoch 5 | Iter 00001] loss=1.9791\n",
      "[Epoch 5 | Iter 00002] loss=2.1121\n",
      "[Epoch 5 | Iter 00003] loss=2.1597\n",
      "[Epoch 5 | Iter 00004] loss=2.1615\n",
      "[Epoch 5 | Iter 00005] loss=2.1591\n",
      "[Epoch 5 | Iter 00006] loss=2.1665\n",
      "[Epoch 5 | Iter 00007] loss=2.1753\n",
      "[Epoch 5 | Iter 00008] loss=2.1866\n",
      "[Epoch 5 | Iter 00009] loss=2.1802\n",
      "[Epoch 5 | Iter 00010] loss=2.1808\n",
      "[Epoch 5 | Iter 00011] loss=2.1974\n",
      "[Epoch 5 | Iter 00012] loss=2.1975\n",
      "[Epoch 5 | Iter 00013] loss=2.1974\n",
      "[Epoch 5 | Iter 00014] loss=2.1921\n",
      "[Epoch 5 | Iter 00015] loss=2.1986\n",
      "[Epoch 5 | Iter 00016] loss=2.1931\n",
      "[Epoch 5 | Iter 00017] loss=2.1827\n",
      "[Epoch 5 | Iter 00018] loss=2.1818\n",
      "[Epoch 5 | Iter 00019] loss=2.1786\n",
      "[Epoch 5 | Iter 00020] loss=2.1706\n",
      "[Epoch 5 | Iter 00021] loss=2.1643\n",
      "[Epoch 5 | Iter 00022] loss=2.1644\n",
      "[Epoch 5 | Iter 00023] loss=2.1623\n",
      "[Epoch 5 | Iter 00024] loss=2.1656\n",
      "[Epoch 5 | Iter 00025] loss=2.1588\n",
      "[Epoch 5] Train: loss=2.1939 mIoU=0.0312 pixacc=0.4213 (34.6s+25.4s, 22.9 smp/s) | Val: loss=2.1742 mIoU=0.0294 pixacc=0.4433 (14.6s, 6.9 smp/s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_005.pt (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(24.2MB) total(0.5s)\n",
      "‚è±Ô∏è  Timing: Save(0.5s) | Total(75.1s) | Breakdown: Train(46.1%) Val(19.4%) Save(0.7%)\n",
      "[Epoch 6 | Iter 00001] loss=2.0410\n",
      "[Epoch 6 | Iter 00002] loss=2.1072\n",
      "[Epoch 6 | Iter 00003] loss=2.1216\n",
      "[Epoch 6 | Iter 00004] loss=2.1234\n",
      "[Epoch 6 | Iter 00005] loss=2.0980\n",
      "[Epoch 6 | Iter 00006] loss=2.0801\n",
      "[Epoch 6 | Iter 00007] loss=2.0654\n",
      "[Epoch 6 | Iter 00008] loss=2.0474\n",
      "[Epoch 6 | Iter 00009] loss=2.0549\n",
      "[Epoch 6 | Iter 00010] loss=2.0617\n",
      "[Epoch 6 | Iter 00011] loss=2.0645\n",
      "[Epoch 6 | Iter 00012] loss=2.0622\n",
      "[Epoch 6 | Iter 00013] loss=2.0675\n",
      "[Epoch 6 | Iter 00014] loss=2.0648\n",
      "[Epoch 6 | Iter 00015] loss=2.0701\n",
      "[Epoch 6 | Iter 00016] loss=2.0751\n",
      "[Epoch 6 | Iter 00017] loss=2.0769\n",
      "[Epoch 6 | Iter 00018] loss=2.0803\n",
      "[Epoch 6 | Iter 00019] loss=2.0751\n",
      "[Epoch 6 | Iter 00020] loss=2.0730\n",
      "[Epoch 6 | Iter 00021] loss=2.0729\n",
      "[Epoch 6 | Iter 00022] loss=2.0699\n",
      "[Epoch 6 | Iter 00023] loss=2.0702\n",
      "[Epoch 6 | Iter 00024] loss=2.0751\n",
      "[Epoch 6 | Iter 00025] loss=2.0744\n",
      "[Epoch 6] Train: loss=2.0993 mIoU=0.0374 pixacc=0.4344 (36.0s+24.9s, 22.1 smp/s) | Val: loss=2.0788 mIoU=0.0341 pixacc=0.4454 (15.2s, 6.6 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0341) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.5s) size(24.2MB) total(0.9s)\n",
      "‚è±Ô∏è  Timing: Save(0.9s) | Total(77.0s) | Breakdown: Train(46.7%) Val(19.8%) Save(1.1%)\n",
      "[Epoch 7 | Iter 00001] loss=2.1210\n",
      "[Epoch 7 | Iter 00002] loss=2.0816\n",
      "[Epoch 7 | Iter 00003] loss=2.0629\n",
      "[Epoch 7 | Iter 00004] loss=2.0225\n",
      "[Epoch 7 | Iter 00005] loss=2.0379\n",
      "[Epoch 7 | Iter 00006] loss=2.0259\n",
      "[Epoch 7 | Iter 00007] loss=2.0196\n",
      "[Epoch 7 | Iter 00008] loss=2.0180\n",
      "[Epoch 7 | Iter 00009] loss=2.0247\n",
      "[Epoch 7 | Iter 00010] loss=2.0359\n",
      "[Epoch 7 | Iter 00011] loss=2.0263\n",
      "[Epoch 7 | Iter 00012] loss=2.0187\n",
      "[Epoch 7 | Iter 00013] loss=2.0174\n",
      "[Epoch 7 | Iter 00014] loss=2.0148\n",
      "[Epoch 7 | Iter 00015] loss=2.0180\n",
      "[Epoch 7 | Iter 00016] loss=2.0159\n",
      "[Epoch 7 | Iter 00017] loss=2.0132\n",
      "[Epoch 7 | Iter 00018] loss=2.0143\n",
      "[Epoch 7 | Iter 00019] loss=2.0171\n",
      "[Epoch 7 | Iter 00020] loss=2.0131\n",
      "[Epoch 7 | Iter 00021] loss=2.0074\n",
      "[Epoch 7 | Iter 00022] loss=2.0054\n",
      "[Epoch 7 | Iter 00023] loss=2.0046\n",
      "[Epoch 7 | Iter 00024] loss=1.9995\n",
      "[Epoch 7 | Iter 00025] loss=2.0039\n",
      "[Epoch 7] Train: loss=1.9916 mIoU=0.0469 pixacc=0.4568 (39.3s+26.4s, 20.2 smp/s) | Val: loss=2.0344 mIoU=0.0400 pixacc=0.4512 (15.1s, 6.6 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0400) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(24.2MB) total(0.8s)\n",
      "‚è±Ô∏è  Timing: Save(0.8s) | Total(81.6s) | Breakdown: Train(48.1%) Val(18.5%) Save(1.0%)\n",
      "[Epoch 8 | Iter 00001] loss=1.9671\n",
      "[Epoch 8 | Iter 00002] loss=1.9414\n",
      "[Epoch 8 | Iter 00003] loss=1.9203\n",
      "[Epoch 8 | Iter 00004] loss=1.9121\n",
      "[Epoch 8 | Iter 00005] loss=1.9257\n",
      "[Epoch 8 | Iter 00006] loss=1.9371\n",
      "[Epoch 8 | Iter 00007] loss=1.9582\n",
      "[Epoch 8 | Iter 00008] loss=1.9598\n",
      "[Epoch 8 | Iter 00009] loss=1.9580\n",
      "[Epoch 8 | Iter 00010] loss=1.9628\n",
      "[Epoch 8 | Iter 00011] loss=1.9607\n",
      "[Epoch 8 | Iter 00012] loss=1.9655\n",
      "[Epoch 8 | Iter 00013] loss=1.9712\n",
      "[Epoch 8 | Iter 00014] loss=1.9646\n",
      "[Epoch 8 | Iter 00015] loss=1.9610\n",
      "[Epoch 8 | Iter 00016] loss=1.9556\n",
      "[Epoch 8 | Iter 00017] loss=1.9474\n",
      "[Epoch 8 | Iter 00018] loss=1.9462\n",
      "[Epoch 8 | Iter 00019] loss=1.9455\n",
      "[Epoch 8 | Iter 00020] loss=1.9420\n",
      "[Epoch 8 | Iter 00021] loss=1.9469\n",
      "[Epoch 8 | Iter 00022] loss=1.9483\n",
      "[Epoch 8 | Iter 00023] loss=1.9444\n",
      "[Epoch 8 | Iter 00024] loss=1.9435\n",
      "[Epoch 8 | Iter 00025] loss=1.9424\n",
      "[Epoch 8] Train: loss=1.9520 mIoU=0.0515 pixacc=0.4634 (40.9s+26.6s, 19.5 smp/s) | Val: loss=2.0099 mIoU=0.0427 pixacc=0.4457 (15.3s, 6.5 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0427) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(24.2MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(83.5s) | Breakdown: Train(48.9%) Val(18.4%) Save(0.8%)\n",
      "[Epoch 9 | Iter 00001] loss=1.8929\n",
      "[Epoch 9 | Iter 00002] loss=1.8949\n",
      "[Epoch 9 | Iter 00003] loss=1.8967\n",
      "[Epoch 9 | Iter 00004] loss=1.8757\n",
      "[Epoch 9 | Iter 00005] loss=1.8706\n",
      "[Epoch 9 | Iter 00006] loss=1.8718\n",
      "[Epoch 9 | Iter 00007] loss=1.8658\n",
      "[Epoch 9 | Iter 00008] loss=1.8630\n",
      "[Epoch 9 | Iter 00009] loss=1.8584\n",
      "[Epoch 9 | Iter 00010] loss=1.8811\n",
      "[Epoch 9 | Iter 00011] loss=1.8866\n",
      "[Epoch 9 | Iter 00012] loss=1.8905\n",
      "[Epoch 9 | Iter 00013] loss=1.8973\n",
      "[Epoch 9 | Iter 00014] loss=1.8968\n",
      "[Epoch 9 | Iter 00015] loss=1.9001\n",
      "[Epoch 9 | Iter 00016] loss=1.8897\n",
      "[Epoch 9 | Iter 00017] loss=1.8939\n",
      "[Epoch 9 | Iter 00018] loss=1.8942\n",
      "[Epoch 9 | Iter 00019] loss=1.8925\n",
      "[Epoch 9 | Iter 00020] loss=1.8871\n",
      "[Epoch 9 | Iter 00021] loss=1.8832\n",
      "[Epoch 9 | Iter 00022] loss=1.8843\n",
      "[Epoch 9 | Iter 00023] loss=1.8850\n",
      "[Epoch 9 | Iter 00024] loss=1.8823\n",
      "[Epoch 9 | Iter 00025] loss=1.8880\n",
      "[Epoch 9] Train: loss=1.9356 mIoU=0.0568 pixacc=0.4785 (34.6s+27.2s, 23.0 smp/s) | Val: loss=2.0099 mIoU=0.0480 pixacc=0.4600 (15.6s, 6.4 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0480) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(24.2MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(78.1s) | Breakdown: Train(44.3%) Val(20.0%) Save(0.9%)\n",
      "[Epoch 10 | Iter 00001] loss=1.8458\n",
      "[Epoch 10 | Iter 00002] loss=1.8752\n",
      "[Epoch 10 | Iter 00003] loss=1.8672\n",
      "[Epoch 10 | Iter 00004] loss=1.8116\n",
      "[Epoch 10 | Iter 00005] loss=1.8067\n",
      "[Epoch 10 | Iter 00006] loss=1.7866\n",
      "[Epoch 10 | Iter 00007] loss=1.8004\n",
      "[Epoch 10 | Iter 00008] loss=1.8252\n",
      "[Epoch 10 | Iter 00009] loss=1.8305\n",
      "[Epoch 10 | Iter 00010] loss=1.8394\n",
      "[Epoch 10 | Iter 00011] loss=1.8480\n",
      "[Epoch 10 | Iter 00012] loss=1.8447\n",
      "[Epoch 10 | Iter 00013] loss=1.8470\n",
      "[Epoch 10 | Iter 00014] loss=1.8503\n",
      "[Epoch 10 | Iter 00015] loss=1.8414\n",
      "[Epoch 10 | Iter 00016] loss=1.8381\n",
      "[Epoch 10 | Iter 00017] loss=1.8292\n",
      "[Epoch 10 | Iter 00018] loss=1.8295\n",
      "[Epoch 10 | Iter 00019] loss=1.8312\n",
      "[Epoch 10 | Iter 00020] loss=1.8271\n",
      "[Epoch 10 | Iter 00021] loss=1.8254\n",
      "[Epoch 10 | Iter 00022] loss=1.8280\n",
      "[Epoch 10 | Iter 00023] loss=1.8305\n",
      "[Epoch 10 | Iter 00024] loss=1.8292\n",
      "[Epoch 10 | Iter 00025] loss=1.8241\n",
      "[Epoch 10] Train: loss=1.8247 mIoU=0.0662 pixacc=0.5121 (34.3s+25.5s, 23.2 smp/s) | Val: loss=1.9198 mIoU=0.0528 pixacc=0.4625 (13.8s, 7.3 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0528) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.4s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_010.pt (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(24.2MB) total(0.8s)\n",
      "‚è±Ô∏è  Timing: Save(0.8s) | Total(74.4s) | Breakdown: Train(46.1%) Val(18.5%) Save(1.1%)\n",
      "[Epoch 11 | Iter 00001] loss=1.8786\n",
      "[Epoch 11 | Iter 00002] loss=1.8400\n",
      "[Epoch 11 | Iter 00003] loss=1.8114\n",
      "[Epoch 11 | Iter 00004] loss=1.7962\n",
      "[Epoch 11 | Iter 00005] loss=1.7887\n",
      "[Epoch 11 | Iter 00006] loss=1.7863\n",
      "[Epoch 11 | Iter 00007] loss=1.7841\n",
      "[Epoch 11 | Iter 00008] loss=1.7786\n",
      "[Epoch 11 | Iter 00009] loss=1.7754\n",
      "[Epoch 11 | Iter 00010] loss=1.7738\n",
      "[Epoch 11 | Iter 00011] loss=1.7770\n",
      "[Epoch 11 | Iter 00012] loss=1.7823\n",
      "[Epoch 11 | Iter 00013] loss=1.7847\n",
      "[Epoch 11 | Iter 00014] loss=1.7765\n",
      "[Epoch 11 | Iter 00015] loss=1.7706\n",
      "[Epoch 11 | Iter 00016] loss=1.7720\n",
      "[Epoch 11 | Iter 00017] loss=1.7736\n",
      "[Epoch 11 | Iter 00018] loss=1.7753\n",
      "[Epoch 11 | Iter 00019] loss=1.7735\n",
      "[Epoch 11 | Iter 00020] loss=1.7724\n",
      "[Epoch 11 | Iter 00021] loss=1.7730\n",
      "[Epoch 11 | Iter 00022] loss=1.7761\n",
      "[Epoch 11 | Iter 00023] loss=1.7770\n",
      "[Epoch 11 | Iter 00024] loss=1.7797\n",
      "[Epoch 11 | Iter 00025] loss=1.7781\n",
      "[Epoch 11] Train: loss=1.7512 mIoU=0.0691 pixacc=0.5231 (34.4s+25.3s, 23.1 smp/s) | Val: loss=1.8908 mIoU=0.0543 pixacc=0.4741 (14.7s, 6.8 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0543) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.5s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(24.2MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(75.1s) | Breakdown: Train(45.7%) Val(19.6%) Save(1.0%)\n",
      "[Epoch 12 | Iter 00001] loss=1.8083\n",
      "[Epoch 12 | Iter 00002] loss=1.7636\n",
      "[Epoch 12 | Iter 00003] loss=1.7510\n",
      "[Epoch 12 | Iter 00004] loss=1.7446\n",
      "[Epoch 12 | Iter 00005] loss=1.7529\n",
      "[Epoch 12 | Iter 00006] loss=1.7352\n",
      "[Epoch 12 | Iter 00007] loss=1.7415\n",
      "[Epoch 12 | Iter 00008] loss=1.7433\n",
      "[Epoch 12 | Iter 00009] loss=1.7383\n",
      "[Epoch 12 | Iter 00010] loss=1.7345\n",
      "[Epoch 12 | Iter 00011] loss=1.7400\n",
      "[Epoch 12 | Iter 00012] loss=1.7477\n",
      "[Epoch 12 | Iter 00013] loss=1.7429\n",
      "[Epoch 12 | Iter 00014] loss=1.7356\n",
      "[Epoch 12 | Iter 00015] loss=1.7281\n",
      "[Epoch 12 | Iter 00016] loss=1.7261\n",
      "[Epoch 12 | Iter 00017] loss=1.7304\n",
      "[Epoch 12 | Iter 00018] loss=1.7312\n",
      "[Epoch 12 | Iter 00019] loss=1.7235\n",
      "[Epoch 12 | Iter 00020] loss=1.7227\n",
      "[Epoch 12 | Iter 00021] loss=1.7221\n",
      "[Epoch 12 | Iter 00022] loss=1.7228\n",
      "[Epoch 12 | Iter 00023] loss=1.7274\n",
      "[Epoch 12 | Iter 00024] loss=1.7234\n",
      "[Epoch 12 | Iter 00025] loss=1.7323\n",
      "[Epoch 12] Train: loss=1.7124 mIoU=0.0745 pixacc=0.5289 (35.1s+26.1s, 22.7 smp/s) | Val: loss=1.8734 mIoU=0.0596 pixacc=0.4805 (15.1s, 6.6 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0596) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(24.2MB) total(0.8s)\n",
      "‚è±Ô∏è  Timing: Save(0.8s) | Total(77.1s) | Breakdown: Train(45.5%) Val(19.5%) Save(1.0%)\n",
      "[Epoch 13 | Iter 00001] loss=1.6249\n",
      "[Epoch 13 | Iter 00002] loss=1.5756\n",
      "[Epoch 13 | Iter 00003] loss=1.5917\n",
      "[Epoch 13 | Iter 00004] loss=1.6464\n",
      "[Epoch 13 | Iter 00005] loss=1.6409\n",
      "[Epoch 13 | Iter 00006] loss=1.6443\n",
      "[Epoch 13 | Iter 00007] loss=1.6567\n",
      "[Epoch 13 | Iter 00008] loss=1.6315\n",
      "[Epoch 13 | Iter 00009] loss=1.6532\n",
      "[Epoch 13 | Iter 00010] loss=1.6532\n",
      "[Epoch 13 | Iter 00011] loss=1.6739\n",
      "[Epoch 13 | Iter 00012] loss=1.6734\n",
      "[Epoch 13 | Iter 00013] loss=1.6756\n",
      "[Epoch 13 | Iter 00014] loss=1.6812\n",
      "[Epoch 13 | Iter 00015] loss=1.6853\n",
      "[Epoch 13 | Iter 00016] loss=1.6854\n",
      "[Epoch 13 | Iter 00017] loss=1.6790\n",
      "[Epoch 13 | Iter 00018] loss=1.6734\n",
      "[Epoch 13 | Iter 00019] loss=1.6760\n",
      "[Epoch 13 | Iter 00020] loss=1.6703\n",
      "[Epoch 13 | Iter 00021] loss=1.6768\n",
      "[Epoch 13 | Iter 00022] loss=1.6815\n",
      "[Epoch 13 | Iter 00023] loss=1.6818\n",
      "[Epoch 13 | Iter 00024] loss=1.6833\n",
      "[Epoch 13 | Iter 00025] loss=1.6870\n",
      "[Epoch 13] Train: loss=1.6971 mIoU=0.0819 pixacc=0.5247 (36.9s+25.7s, 21.6 smp/s) | Val: loss=1.8430 mIoU=0.0589 pixacc=0.4609 (14.8s, 6.7 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(24.2MB) total(0.2s)\n",
      "‚è±Ô∏è  Timing: Save(0.2s) | Total(77.6s) | Breakdown: Train(47.5%) Val(19.1%) Save(0.3%)\n",
      "[Epoch 14 | Iter 00001] loss=1.6400\n",
      "[Epoch 14 | Iter 00002] loss=1.6011\n",
      "[Epoch 14 | Iter 00003] loss=1.5583\n",
      "[Epoch 14 | Iter 00004] loss=1.6003\n",
      "[Epoch 14 | Iter 00005] loss=1.6424\n",
      "[Epoch 14 | Iter 00006] loss=1.6552\n",
      "[Epoch 14 | Iter 00007] loss=1.6697\n",
      "[Epoch 14 | Iter 00008] loss=1.6785\n",
      "[Epoch 14 | Iter 00009] loss=1.6859\n",
      "[Epoch 14 | Iter 00010] loss=1.6721\n",
      "[Epoch 14 | Iter 00011] loss=1.6726\n",
      "[Epoch 14 | Iter 00012] loss=1.6553\n",
      "[Epoch 14 | Iter 00013] loss=1.6475\n",
      "[Epoch 14 | Iter 00014] loss=1.6475\n",
      "[Epoch 14 | Iter 00015] loss=1.6483\n",
      "[Epoch 14 | Iter 00016] loss=1.6466\n",
      "[Epoch 14 | Iter 00017] loss=1.6427\n",
      "[Epoch 14 | Iter 00018] loss=1.6423\n",
      "[Epoch 14 | Iter 00019] loss=1.6442\n",
      "[Epoch 14 | Iter 00020] loss=1.6403\n",
      "[Epoch 14 | Iter 00021] loss=1.6358\n",
      "[Epoch 14 | Iter 00022] loss=1.6373\n",
      "[Epoch 14 | Iter 00023] loss=1.6392\n",
      "[Epoch 14 | Iter 00024] loss=1.6366\n",
      "[Epoch 14 | Iter 00025] loss=1.6384\n",
      "[Epoch 14] Train: loss=1.6193 mIoU=0.0863 pixacc=0.5463 (36.9s+26.7s, 21.6 smp/s) | Val: loss=1.8022 mIoU=0.0610 pixacc=0.4859 (14.4s, 6.9 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0610) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(24.2MB) total(0.8s)\n",
      "‚è±Ô∏è  Timing: Save(0.8s) | Total(78.8s) | Breakdown: Train(46.8%) Val(18.3%) Save(1.0%)\n",
      "[Epoch 15 | Iter 00001] loss=1.6546\n",
      "[Epoch 15 | Iter 00002] loss=1.6075\n",
      "[Epoch 15 | Iter 00003] loss=1.5894\n",
      "[Epoch 15 | Iter 00004] loss=1.5649\n",
      "[Epoch 15 | Iter 00005] loss=1.5704\n",
      "[Epoch 15 | Iter 00006] loss=1.5760\n",
      "[Epoch 15 | Iter 00007] loss=1.5902\n",
      "[Epoch 15 | Iter 00008] loss=1.5962\n",
      "[Epoch 15 | Iter 00009] loss=1.5989\n",
      "[Epoch 15 | Iter 00010] loss=1.5892\n",
      "[Epoch 15 | Iter 00011] loss=1.5831\n",
      "[Epoch 15 | Iter 00012] loss=1.5791\n",
      "[Epoch 15 | Iter 00013] loss=1.5675\n",
      "[Epoch 15 | Iter 00014] loss=1.5678\n",
      "[Epoch 15 | Iter 00015] loss=1.5688\n",
      "[Epoch 15 | Iter 00016] loss=1.5674\n",
      "[Epoch 15 | Iter 00017] loss=1.5708\n",
      "[Epoch 15 | Iter 00018] loss=1.5674\n",
      "[Epoch 15 | Iter 00019] loss=1.5683\n",
      "[Epoch 15 | Iter 00020] loss=1.5755\n",
      "[Epoch 15 | Iter 00021] loss=1.5737\n",
      "[Epoch 15 | Iter 00022] loss=1.5716\n",
      "[Epoch 15 | Iter 00023] loss=1.5710\n",
      "[Epoch 15 | Iter 00024] loss=1.5742\n",
      "[Epoch 15 | Iter 00025] loss=1.5782\n",
      "[Epoch 15] Train: loss=1.6121 mIoU=0.1097 pixacc=0.5638 (34.9s+25.7s, 22.8 smp/s) | Val: loss=1.8157 mIoU=0.0832 pixacc=0.5066 (14.7s, 6.8 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0832) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.4s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_015.pt (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(24.2MB) total(0.9s)\n",
      "‚è±Ô∏è  Timing: Save(0.9s) | Total(76.1s) | Breakdown: Train(45.8%) Val(19.3%) Save(1.1%)\n",
      "[Epoch 16 | Iter 00001] loss=1.4672\n",
      "[Epoch 16 | Iter 00002] loss=1.5138\n",
      "[Epoch 16 | Iter 00003] loss=1.5258\n",
      "[Epoch 16 | Iter 00004] loss=1.5366\n",
      "[Epoch 16 | Iter 00005] loss=1.5327\n",
      "[Epoch 16 | Iter 00006] loss=1.5289\n",
      "[Epoch 16 | Iter 00007] loss=1.5216\n",
      "[Epoch 16 | Iter 00008] loss=1.5251\n",
      "[Epoch 16 | Iter 00009] loss=1.5384\n",
      "[Epoch 16 | Iter 00010] loss=1.5496\n",
      "[Epoch 16 | Iter 00011] loss=1.5560\n",
      "[Epoch 16 | Iter 00012] loss=1.5595\n",
      "[Epoch 16 | Iter 00013] loss=1.5572\n",
      "[Epoch 16 | Iter 00014] loss=1.5538\n",
      "[Epoch 16 | Iter 00015] loss=1.5509\n",
      "[Epoch 16 | Iter 00016] loss=1.5468\n",
      "[Epoch 16 | Iter 00017] loss=1.5491\n",
      "[Epoch 16 | Iter 00018] loss=1.5530\n",
      "[Epoch 16 | Iter 00019] loss=1.5508\n",
      "[Epoch 16 | Iter 00020] loss=1.5438\n",
      "[Epoch 16 | Iter 00021] loss=1.5398\n",
      "[Epoch 16 | Iter 00022] loss=1.5397\n",
      "[Epoch 16 | Iter 00023] loss=1.5418\n",
      "[Epoch 16 | Iter 00024] loss=1.5389\n",
      "[Epoch 16 | Iter 00025] loss=1.5440\n",
      "[Epoch 16] Train: loss=1.5473 mIoU=0.1099 pixacc=0.5689 (36.8s+26.7s, 21.6 smp/s) | Val: loss=1.8034 mIoU=0.0813 pixacc=0.5044 (15.1s, 6.6 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.6s) size(24.2MB) total(0.6s)\n",
      "‚è±Ô∏è  Timing: Save(0.6s) | Total(79.2s) | Breakdown: Train(46.5%) Val(19.1%) Save(0.7%)\n",
      "[Epoch 17 | Iter 00001] loss=1.5026\n",
      "[Epoch 17 | Iter 00002] loss=1.5094\n",
      "[Epoch 17 | Iter 00003] loss=1.4880\n",
      "[Epoch 17 | Iter 00004] loss=1.5358\n",
      "[Epoch 17 | Iter 00005] loss=1.5465\n",
      "[Epoch 17 | Iter 00006] loss=1.5456\n",
      "[Epoch 17 | Iter 00007] loss=1.5464\n",
      "[Epoch 17 | Iter 00008] loss=1.5252\n",
      "[Epoch 17 | Iter 00009] loss=1.5277\n",
      "[Epoch 17 | Iter 00010] loss=1.5223\n",
      "[Epoch 17 | Iter 00011] loss=1.5138\n",
      "[Epoch 17 | Iter 00012] loss=1.5070\n",
      "[Epoch 17 | Iter 00013] loss=1.5040\n",
      "[Epoch 17 | Iter 00014] loss=1.5105\n",
      "[Epoch 17 | Iter 00015] loss=1.5096\n",
      "[Epoch 17 | Iter 00016] loss=1.5137\n",
      "[Epoch 17 | Iter 00017] loss=1.5085\n",
      "[Epoch 17 | Iter 00018] loss=1.5189\n",
      "[Epoch 17 | Iter 00019] loss=1.5162\n",
      "[Epoch 17 | Iter 00020] loss=1.5081\n",
      "[Epoch 17 | Iter 00021] loss=1.5102\n",
      "[Epoch 17 | Iter 00022] loss=1.5081\n",
      "[Epoch 17 | Iter 00023] loss=1.5048\n",
      "[Epoch 17 | Iter 00024] loss=1.5024\n",
      "[Epoch 17 | Iter 00025] loss=1.5051\n",
      "[Epoch 17] Train: loss=1.4896 mIoU=0.1221 pixacc=0.5808 (37.0s+25.6s, 21.5 smp/s) | Val: loss=1.7107 mIoU=0.0932 pixacc=0.5252 (15.2s, 6.6 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0932) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(24.2MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(78.4s) | Breakdown: Train(47.2%) Val(19.3%) Save(0.9%)\n",
      "[Epoch 18 | Iter 00001] loss=1.5176\n",
      "[Epoch 18 | Iter 00002] loss=1.4625\n",
      "[Epoch 18 | Iter 00003] loss=1.4729\n",
      "[Epoch 18 | Iter 00004] loss=1.4618\n",
      "[Epoch 18 | Iter 00005] loss=1.4576\n",
      "[Epoch 18 | Iter 00006] loss=1.4452\n",
      "[Epoch 18 | Iter 00007] loss=1.4596\n",
      "[Epoch 18 | Iter 00008] loss=1.4515\n",
      "[Epoch 18 | Iter 00009] loss=1.4517\n",
      "[Epoch 18 | Iter 00010] loss=1.4659\n",
      "[Epoch 18 | Iter 00011] loss=1.4673\n",
      "[Epoch 18 | Iter 00012] loss=1.4652\n",
      "[Epoch 18 | Iter 00013] loss=1.4733\n",
      "[Epoch 18 | Iter 00014] loss=1.4678\n",
      "[Epoch 18 | Iter 00015] loss=1.4770\n",
      "[Epoch 18 | Iter 00016] loss=1.4770\n",
      "[Epoch 18 | Iter 00017] loss=1.4729\n",
      "[Epoch 18 | Iter 00018] loss=1.4745\n",
      "[Epoch 18 | Iter 00019] loss=1.4761\n",
      "[Epoch 18 | Iter 00020] loss=1.4766\n",
      "[Epoch 18 | Iter 00021] loss=1.4777\n",
      "[Epoch 18 | Iter 00022] loss=1.4780\n",
      "[Epoch 18 | Iter 00023] loss=1.4780\n",
      "[Epoch 18 | Iter 00024] loss=1.4790\n",
      "[Epoch 18 | Iter 00025] loss=1.4753\n",
      "[Epoch 18] Train: loss=1.4770 mIoU=0.1226 pixacc=0.5755 (34.5s+25.5s, 23.0 smp/s) | Val: loss=1.7276 mIoU=0.0972 pixacc=0.5120 (14.4s, 7.0 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0972) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(24.2MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(75.2s) | Breakdown: Train(46.0%) Val(19.1%) Save(0.9%)\n",
      "[Epoch 19 | Iter 00001] loss=1.4137\n",
      "[Epoch 19 | Iter 00002] loss=1.4852\n",
      "[Epoch 19 | Iter 00003] loss=1.4534\n",
      "[Epoch 19 | Iter 00004] loss=1.4505\n",
      "[Epoch 19 | Iter 00005] loss=1.5038\n",
      "[Epoch 19 | Iter 00006] loss=1.4658\n",
      "[Epoch 19 | Iter 00007] loss=1.4642\n",
      "[Epoch 19 | Iter 00008] loss=1.4441\n",
      "[Epoch 19 | Iter 00009] loss=1.4494\n",
      "[Epoch 19 | Iter 00010] loss=1.4425\n",
      "[Epoch 19 | Iter 00011] loss=1.4492\n",
      "[Epoch 19 | Iter 00012] loss=1.4582\n",
      "[Epoch 19 | Iter 00013] loss=1.4526\n",
      "[Epoch 19 | Iter 00014] loss=1.4427\n",
      "[Epoch 19 | Iter 00015] loss=1.4432\n",
      "[Epoch 19 | Iter 00016] loss=1.4404\n",
      "[Epoch 19 | Iter 00017] loss=1.4403\n",
      "[Epoch 19 | Iter 00018] loss=1.4407\n",
      "[Epoch 19 | Iter 00019] loss=1.4394\n",
      "[Epoch 19 | Iter 00020] loss=1.4349\n",
      "[Epoch 19 | Iter 00021] loss=1.4327\n",
      "[Epoch 19 | Iter 00022] loss=1.4301\n",
      "[Epoch 19 | Iter 00023] loss=1.4287\n",
      "[Epoch 19 | Iter 00024] loss=1.4294\n",
      "[Epoch 19 | Iter 00025] loss=1.4340\n",
      "[Epoch 19] Train: loss=1.4450 mIoU=0.1319 pixacc=0.5907 (36.3s+25.0s, 21.9 smp/s) | Val: loss=1.7456 mIoU=0.0949 pixacc=0.5108 (14.7s, 6.8 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(24.2MB) total(0.2s)\n",
      "‚è±Ô∏è  Timing: Save(0.2s) | Total(76.2s) | Breakdown: Train(47.6%) Val(19.3%) Save(0.3%)\n",
      "[Epoch 20 | Iter 00001] loss=1.3993\n",
      "[Epoch 20 | Iter 00002] loss=1.4191\n",
      "[Epoch 20 | Iter 00003] loss=1.4123\n",
      "[Epoch 20 | Iter 00004] loss=1.3979\n",
      "[Epoch 20 | Iter 00005] loss=1.4134\n",
      "[Epoch 20 | Iter 00006] loss=1.4112\n",
      "[Epoch 20 | Iter 00007] loss=1.3983\n",
      "[Epoch 20 | Iter 00008] loss=1.3771\n",
      "[Epoch 20 | Iter 00009] loss=1.3828\n",
      "[Epoch 20 | Iter 00010] loss=1.3872\n",
      "[Epoch 20 | Iter 00011] loss=1.3896\n",
      "[Epoch 20 | Iter 00012] loss=1.3922\n",
      "[Epoch 20 | Iter 00013] loss=1.3894\n",
      "[Epoch 20 | Iter 00014] loss=1.4034\n",
      "[Epoch 20 | Iter 00015] loss=1.3960\n",
      "[Epoch 20 | Iter 00016] loss=1.3953\n",
      "[Epoch 20 | Iter 00017] loss=1.3952\n",
      "[Epoch 20 | Iter 00018] loss=1.3914\n",
      "[Epoch 20 | Iter 00019] loss=1.4014\n",
      "[Epoch 20 | Iter 00020] loss=1.4045\n",
      "[Epoch 20 | Iter 00021] loss=1.3994\n",
      "[Epoch 20 | Iter 00022] loss=1.3944\n",
      "[Epoch 20 | Iter 00023] loss=1.3858\n",
      "[Epoch 20 | Iter 00024] loss=1.3869\n",
      "[Epoch 20 | Iter 00025] loss=1.3926\n",
      "[Epoch 20] Train: loss=1.3711 mIoU=0.1468 pixacc=0.6065 (37.9s+27.7s, 21.0 smp/s) | Val: loss=1.7220 mIoU=0.1089 pixacc=0.5295 (15.3s, 6.6 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1089) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.4s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_020.pt (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(24.2MB) total(0.9s)\n",
      "‚è±Ô∏è  Timing: Save(0.9s) | Total(81.6s) | Breakdown: Train(46.4%) Val(18.7%) Save(1.1%)\n",
      "Training complete!\n",
      "Best mIoU: 0.1089\n",
      "\n",
      "üîÑ Loading best model for final evaluation...\n",
      "Final validation metrics: loss=1.7220 mIoU=0.1089, PixelAcc=0.5295 (load: 0.2s, eval: 14.3s)\n"
     ]
    }
   ],
   "source": [
    "model.freeze_backbone()\n",
    "trained_model = trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2cf87a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3-small encoder unfrozen: parameters will be updated during training\n",
      "MobileNetV3-small depth encoder unfrozen: parameters will be updated during training\n",
      "Using device: mps\n",
      "EarlyStopping: monitoring 'val_miou' with patience=5 (mode=max)\n",
      "Training configuration:\n",
      "  Use RGB: True\n",
      "  Use Depth: True\n",
      "  Input channels: 4\n",
      "  Label mode: nyu40\n",
      "  Num classes: 40\n",
      "Training samples: 795\n",
      "Validation samples: 100\n",
      "Total parameters: 3,321,105\n",
      "Trainable parameters: 3,321,105\n",
      "Resuming training from: checkpoints/dual_encoder_unet_mobilenet/latest.pth\n",
      "‚úì Resumed from epoch 20\n",
      "‚úì Training history loaded with 20 epochs\n",
      "‚úì Best mIoU so far: 0.1089\n",
      "üîß Applied config overrides:\n",
      "  learning_rate: 0.001000 ‚Üí 0.000100\n",
      "Starting training for 100 epochs (from epoch 21)...\n",
      "[Epoch 21 | Iter 00001] loss=1.2825\n",
      "[Epoch 21 | Iter 00002] loss=1.2903\n",
      "[Epoch 21 | Iter 00003] loss=1.3282\n",
      "[Epoch 21 | Iter 00004] loss=1.3259\n",
      "[Epoch 21 | Iter 00005] loss=1.3229\n",
      "[Epoch 21 | Iter 00006] loss=1.3274\n",
      "[Epoch 21 | Iter 00007] loss=1.3312\n",
      "[Epoch 21 | Iter 00008] loss=1.3491\n",
      "[Epoch 21 | Iter 00009] loss=1.3467\n",
      "[Epoch 21 | Iter 00010] loss=1.3510\n",
      "[Epoch 21 | Iter 00011] loss=1.3436\n",
      "[Epoch 21 | Iter 00012] loss=1.3435\n",
      "[Epoch 21 | Iter 00013] loss=1.3443\n",
      "[Epoch 21 | Iter 00014] loss=1.3457\n",
      "[Epoch 21 | Iter 00015] loss=1.3391\n",
      "[Epoch 21 | Iter 00016] loss=1.3391\n",
      "[Epoch 21 | Iter 00017] loss=1.3397\n",
      "[Epoch 21 | Iter 00018] loss=1.3348\n",
      "[Epoch 21 | Iter 00019] loss=1.3363\n",
      "[Epoch 21 | Iter 00020] loss=1.3374\n",
      "[Epoch 21 | Iter 00021] loss=1.3386\n",
      "[Epoch 21 | Iter 00022] loss=1.3331\n",
      "[Epoch 21 | Iter 00023] loss=1.3249\n",
      "[Epoch 21 | Iter 00024] loss=1.3252\n",
      "[Epoch 21 | Iter 00025] loss=1.3208\n",
      "[Epoch 21] Train: loss=1.2769 mIoU=0.1631 pixacc=0.6327 (47.1s+25.9s, 16.9 smp/s) | Val: loss=1.6015 mIoU=0.1166 pixacc=0.5485 (15.7s, 6.4 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1166) to checkpoints/dual_encoder_unet_mobilenet/best.pth (1.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(1.2s) size(37.7MB) total(2.4s)\n",
      "‚è±Ô∏è  Timing: Save(2.4s) | Total(91.1s) | Breakdown: Train(51.7%) Val(17.3%) Save(2.6%)\n",
      "[Epoch 22 | Iter 00001] loss=1.3454\n",
      "[Epoch 22 | Iter 00002] loss=1.2776\n",
      "[Epoch 22 | Iter 00003] loss=1.2488\n",
      "[Epoch 22 | Iter 00004] loss=1.2862\n",
      "[Epoch 22 | Iter 00005] loss=1.2706\n",
      "[Epoch 22 | Iter 00006] loss=1.2756\n",
      "[Epoch 22 | Iter 00007] loss=1.2795\n",
      "[Epoch 22 | Iter 00008] loss=1.2789\n",
      "[Epoch 22 | Iter 00009] loss=1.2778\n",
      "[Epoch 22 | Iter 00010] loss=1.2688\n",
      "[Epoch 22 | Iter 00011] loss=1.2702\n",
      "[Epoch 22 | Iter 00012] loss=1.2763\n",
      "[Epoch 22 | Iter 00013] loss=1.2735\n",
      "[Epoch 22 | Iter 00014] loss=1.2691\n",
      "[Epoch 22 | Iter 00015] loss=1.2737\n",
      "[Epoch 22 | Iter 00016] loss=1.2689\n",
      "[Epoch 22 | Iter 00017] loss=1.2643\n",
      "[Epoch 22 | Iter 00018] loss=1.2733\n",
      "[Epoch 22 | Iter 00019] loss=1.2732\n",
      "[Epoch 22 | Iter 00020] loss=1.2777\n",
      "[Epoch 22 | Iter 00021] loss=1.2754\n",
      "[Epoch 22 | Iter 00022] loss=1.2727\n",
      "[Epoch 22 | Iter 00023] loss=1.2691\n",
      "[Epoch 22 | Iter 00024] loss=1.2686\n",
      "[Epoch 22 | Iter 00025] loss=1.2699\n",
      "[Epoch 22] Train: loss=1.2462 mIoU=0.1697 pixacc=0.6410 (50.1s+28.6s, 15.9 smp/s) | Val: loss=1.6038 mIoU=0.1168 pixacc=0.5487 (16.6s, 6.0 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1168) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.8s) size(37.7MB) total(1.6s)\n",
      "‚è±Ô∏è  Timing: Save(1.6s) | Total(96.9s) | Breakdown: Train(51.7%) Val(17.2%) Save(1.6%)\n",
      "[Epoch 23 | Iter 00001] loss=1.2978\n",
      "[Epoch 23 | Iter 00002] loss=1.2371\n",
      "[Epoch 23 | Iter 00003] loss=1.2516\n",
      "[Epoch 23 | Iter 00004] loss=1.2713\n",
      "[Epoch 23 | Iter 00005] loss=1.2436\n",
      "[Epoch 23 | Iter 00006] loss=1.2597\n",
      "[Epoch 23 | Iter 00007] loss=1.2471\n",
      "[Epoch 23 | Iter 00008] loss=1.2479\n",
      "[Epoch 23 | Iter 00009] loss=1.2399\n",
      "[Epoch 23 | Iter 00010] loss=1.2418\n",
      "[Epoch 23 | Iter 00011] loss=1.2400\n",
      "[Epoch 23 | Iter 00012] loss=1.2418\n",
      "[Epoch 23 | Iter 00013] loss=1.2493\n",
      "[Epoch 23 | Iter 00014] loss=1.2496\n",
      "[Epoch 23 | Iter 00015] loss=1.2469\n",
      "[Epoch 23 | Iter 00016] loss=1.2440\n",
      "[Epoch 23 | Iter 00017] loss=1.2404\n",
      "[Epoch 23 | Iter 00018] loss=1.2403\n",
      "[Epoch 23 | Iter 00019] loss=1.2418\n",
      "[Epoch 23 | Iter 00020] loss=1.2410\n",
      "[Epoch 23 | Iter 00021] loss=1.2412\n",
      "[Epoch 23 | Iter 00022] loss=1.2445\n",
      "[Epoch 23 | Iter 00023] loss=1.2442\n",
      "[Epoch 23 | Iter 00024] loss=1.2424\n",
      "[Epoch 23 | Iter 00025] loss=1.2443\n",
      "[Epoch 23] Train: loss=1.2201 mIoU=0.1756 pixacc=0.6476 (43.7s+27.0s, 18.2 smp/s) | Val: loss=1.5986 mIoU=0.1198 pixacc=0.5510 (14.7s, 6.8 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1198) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.9s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.5s) size(37.7MB) total(1.4s)\n",
      "‚è±Ô∏è  Timing: Save(1.4s) | Total(86.9s) | Breakdown: Train(50.3%) Val(16.9%) Save(1.6%)\n",
      "[Epoch 24 | Iter 00001] loss=1.2170\n",
      "[Epoch 24 | Iter 00002] loss=1.2315\n",
      "[Epoch 24 | Iter 00003] loss=1.2753\n",
      "[Epoch 24 | Iter 00004] loss=1.2715\n",
      "[Epoch 24 | Iter 00005] loss=1.2646\n",
      "[Epoch 24 | Iter 00006] loss=1.2531\n",
      "[Epoch 24 | Iter 00007] loss=1.2579\n",
      "[Epoch 24 | Iter 00008] loss=1.2518\n",
      "[Epoch 24 | Iter 00009] loss=1.2426\n",
      "[Epoch 24 | Iter 00010] loss=1.2452\n",
      "[Epoch 24 | Iter 00011] loss=1.2488\n",
      "[Epoch 24 | Iter 00012] loss=1.2468\n",
      "[Epoch 24 | Iter 00013] loss=1.2390\n",
      "[Epoch 24 | Iter 00014] loss=1.2317\n",
      "[Epoch 24 | Iter 00015] loss=1.2271\n",
      "[Epoch 24 | Iter 00016] loss=1.2295\n",
      "[Epoch 24 | Iter 00017] loss=1.2258\n",
      "[Epoch 24 | Iter 00018] loss=1.2326\n",
      "[Epoch 24 | Iter 00019] loss=1.2322\n",
      "[Epoch 24 | Iter 00020] loss=1.2310\n",
      "[Epoch 24 | Iter 00021] loss=1.2298\n",
      "[Epoch 24 | Iter 00022] loss=1.2271\n",
      "[Epoch 24 | Iter 00023] loss=1.2290\n",
      "[Epoch 24 | Iter 00024] loss=1.2282\n",
      "[Epoch 24 | Iter 00025] loss=1.2314\n",
      "[Epoch 24] Train: loss=1.1973 mIoU=0.1807 pixacc=0.6535 (43.6s+26.4s, 18.2 smp/s) | Val: loss=1.6064 mIoU=0.1196 pixacc=0.5483 (14.9s, 6.7 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.5s) size(37.7MB) total(0.5s)\n",
      "‚è±Ô∏è  Timing: Save(0.5s) | Total(85.3s) | Breakdown: Train(51.1%) Val(17.4%) Save(0.6%)\n",
      "[Epoch 25 | Iter 00001] loss=1.0905\n",
      "[Epoch 25 | Iter 00002] loss=1.1781\n",
      "[Epoch 25 | Iter 00003] loss=1.1936\n",
      "[Epoch 25 | Iter 00004] loss=1.2014\n",
      "[Epoch 25 | Iter 00005] loss=1.1933\n",
      "[Epoch 25 | Iter 00006] loss=1.2070\n",
      "[Epoch 25 | Iter 00007] loss=1.2163\n",
      "[Epoch 25 | Iter 00008] loss=1.2298\n",
      "[Epoch 25 | Iter 00009] loss=1.2223\n",
      "[Epoch 25 | Iter 00010] loss=1.2210\n",
      "[Epoch 25 | Iter 00011] loss=1.2275\n",
      "[Epoch 25 | Iter 00012] loss=1.2295\n",
      "[Epoch 25 | Iter 00013] loss=1.2303\n",
      "[Epoch 25 | Iter 00014] loss=1.2243\n",
      "[Epoch 25 | Iter 00015] loss=1.2240\n",
      "[Epoch 25 | Iter 00016] loss=1.2231\n",
      "[Epoch 25 | Iter 00017] loss=1.2177\n",
      "[Epoch 25 | Iter 00018] loss=1.2157\n",
      "[Epoch 25 | Iter 00019] loss=1.2164\n",
      "[Epoch 25 | Iter 00020] loss=1.2112\n",
      "[Epoch 25 | Iter 00021] loss=1.2083\n",
      "[Epoch 25 | Iter 00022] loss=1.2099\n",
      "[Epoch 25 | Iter 00023] loss=1.2128\n",
      "[Epoch 25 | Iter 00024] loss=1.2147\n",
      "[Epoch 25 | Iter 00025] loss=1.2098\n",
      "[Epoch 25] Train: loss=1.1772 mIoU=0.1879 pixacc=0.6602 (44.5s+28.5s, 17.8 smp/s) | Val: loss=1.5774 mIoU=0.1238 pixacc=0.5534 (16.1s, 6.2 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1238) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_025.pt (0.3s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.7s) size(37.7MB) total(1.7s)\n",
      "‚è±Ô∏è  Timing: Save(1.7s) | Total(90.9s) | Breakdown: Train(49.0%) Val(17.8%) Save(1.9%)\n",
      "[Epoch 26 | Iter 00001] loss=1.1681\n",
      "[Epoch 26 | Iter 00002] loss=1.1740\n",
      "[Epoch 26 | Iter 00003] loss=1.1796\n",
      "[Epoch 26 | Iter 00004] loss=1.1833\n",
      "[Epoch 26 | Iter 00005] loss=1.1684\n",
      "[Epoch 26 | Iter 00006] loss=1.1575\n",
      "[Epoch 26 | Iter 00007] loss=1.1529\n",
      "[Epoch 26 | Iter 00008] loss=1.1490\n",
      "[Epoch 26 | Iter 00009] loss=1.1611\n",
      "[Epoch 26 | Iter 00010] loss=1.1691\n",
      "[Epoch 26 | Iter 00011] loss=1.1753\n",
      "[Epoch 26 | Iter 00012] loss=1.1811\n",
      "[Epoch 26 | Iter 00013] loss=1.1860\n",
      "[Epoch 26 | Iter 00014] loss=1.1843\n",
      "[Epoch 26 | Iter 00015] loss=1.1876\n",
      "[Epoch 26 | Iter 00016] loss=1.1946\n",
      "[Epoch 26 | Iter 00017] loss=1.1921\n",
      "[Epoch 26 | Iter 00018] loss=1.1958\n",
      "[Epoch 26 | Iter 00019] loss=1.1928\n",
      "[Epoch 26 | Iter 00020] loss=1.1908\n",
      "[Epoch 26 | Iter 00021] loss=1.1921\n",
      "[Epoch 26 | Iter 00022] loss=1.1915\n",
      "[Epoch 26 | Iter 00023] loss=1.1933\n",
      "[Epoch 26 | Iter 00024] loss=1.1959\n",
      "[Epoch 26 | Iter 00025] loss=1.1935\n",
      "[Epoch 26] Train: loss=1.1618 mIoU=0.1921 pixacc=0.6653 (47.5s+28.5s, 16.7 smp/s) | Val: loss=1.5884 mIoU=0.1252 pixacc=0.5537 (16.6s, 6.0 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1252) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.8s) size(37.7MB) total(1.6s)\n",
      "‚è±Ô∏è  Timing: Save(1.6s) | Total(94.2s) | Breakdown: Train(50.5%) Val(17.6%) Save(1.7%)\n",
      "[Epoch 27 | Iter 00001] loss=1.2032\n",
      "[Epoch 27 | Iter 00002] loss=1.2001\n",
      "[Epoch 27 | Iter 00003] loss=1.1889\n",
      "[Epoch 27 | Iter 00004] loss=1.1813\n",
      "[Epoch 27 | Iter 00005] loss=1.1881\n",
      "[Epoch 27 | Iter 00006] loss=1.1851\n",
      "[Epoch 27 | Iter 00007] loss=1.1858\n",
      "[Epoch 27 | Iter 00008] loss=1.1806\n",
      "[Epoch 27 | Iter 00009] loss=1.1777\n",
      "[Epoch 27 | Iter 00010] loss=1.1852\n",
      "[Epoch 27 | Iter 00011] loss=1.1859\n",
      "[Epoch 27 | Iter 00012] loss=1.1873\n",
      "[Epoch 27 | Iter 00013] loss=1.1847\n",
      "[Epoch 27 | Iter 00014] loss=1.1831\n",
      "[Epoch 27 | Iter 00015] loss=1.1826\n",
      "[Epoch 27 | Iter 00016] loss=1.1822\n",
      "[Epoch 27 | Iter 00017] loss=1.1860\n",
      "[Epoch 27 | Iter 00018] loss=1.1891\n",
      "[Epoch 27 | Iter 00019] loss=1.1890\n",
      "[Epoch 27 | Iter 00020] loss=1.1883\n",
      "[Epoch 27 | Iter 00021] loss=1.1808\n",
      "[Epoch 27 | Iter 00022] loss=1.1822\n",
      "[Epoch 27 | Iter 00023] loss=1.1826\n",
      "[Epoch 27 | Iter 00024] loss=1.1792\n",
      "[Epoch 27 | Iter 00025] loss=1.1815\n",
      "[Epoch 27] Train: loss=1.1492 mIoU=0.1957 pixacc=0.6695 (44.8s+26.7s, 17.7 smp/s) | Val: loss=1.5931 mIoU=0.1270 pixacc=0.5540 (15.7s, 6.4 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1270) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.9s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.7s) size(37.7MB) total(1.7s)\n",
      "‚è±Ô∏è  Timing: Save(1.7s) | Total(88.9s) | Breakdown: Train(50.5%) Val(17.6%) Save(1.9%)\n",
      "[Epoch 28 | Iter 00001] loss=1.1512\n",
      "[Epoch 28 | Iter 00002] loss=1.1734\n",
      "[Epoch 28 | Iter 00003] loss=1.1476\n",
      "[Epoch 28 | Iter 00004] loss=1.1353\n",
      "[Epoch 28 | Iter 00005] loss=1.1562\n",
      "[Epoch 28 | Iter 00006] loss=1.1777\n",
      "[Epoch 28 | Iter 00007] loss=1.1877\n",
      "[Epoch 28 | Iter 00008] loss=1.1835\n",
      "[Epoch 28 | Iter 00009] loss=1.1800\n",
      "[Epoch 28 | Iter 00010] loss=1.1780\n",
      "[Epoch 28 | Iter 00011] loss=1.1735\n",
      "[Epoch 28 | Iter 00012] loss=1.1788\n",
      "[Epoch 28 | Iter 00013] loss=1.1840\n",
      "[Epoch 28 | Iter 00014] loss=1.1807\n",
      "[Epoch 28 | Iter 00015] loss=1.1797\n",
      "[Epoch 28 | Iter 00016] loss=1.1741\n",
      "[Epoch 28 | Iter 00017] loss=1.1679\n",
      "[Epoch 28 | Iter 00018] loss=1.1674\n",
      "[Epoch 28 | Iter 00019] loss=1.1696\n",
      "[Epoch 28 | Iter 00020] loss=1.1648\n",
      "[Epoch 28 | Iter 00021] loss=1.1691\n",
      "[Epoch 28 | Iter 00022] loss=1.1696\n",
      "[Epoch 28 | Iter 00023] loss=1.1665\n",
      "[Epoch 28 | Iter 00024] loss=1.1656\n",
      "[Epoch 28 | Iter 00025] loss=1.1670\n",
      "[Epoch 28] Train: loss=1.1272 mIoU=0.2019 pixacc=0.6743 (47.2s+27.1s, 16.8 smp/s) | Val: loss=1.5671 mIoU=0.1283 pixacc=0.5576 (15.6s, 6.4 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1283) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(1.1s)\n",
      "‚è±Ô∏è  Timing: Save(1.1s) | Total(91.0s) | Breakdown: Train(51.9%) Val(17.2%) Save(1.2%)\n",
      "[Epoch 29 | Iter 00001] loss=1.1688\n",
      "[Epoch 29 | Iter 00002] loss=1.1789\n",
      "[Epoch 29 | Iter 00003] loss=1.1764\n",
      "[Epoch 29 | Iter 00004] loss=1.1763\n",
      "[Epoch 29 | Iter 00005] loss=1.1674\n",
      "[Epoch 29 | Iter 00006] loss=1.1573\n",
      "[Epoch 29 | Iter 00007] loss=1.1431\n",
      "[Epoch 29 | Iter 00008] loss=1.1349\n",
      "[Epoch 29 | Iter 00009] loss=1.1374\n",
      "[Epoch 29 | Iter 00010] loss=1.1522\n",
      "[Epoch 29 | Iter 00011] loss=1.1541\n",
      "[Epoch 29 | Iter 00012] loss=1.1527\n",
      "[Epoch 29 | Iter 00013] loss=1.1568\n",
      "[Epoch 29 | Iter 00014] loss=1.1574\n",
      "[Epoch 29 | Iter 00015] loss=1.1598\n",
      "[Epoch 29 | Iter 00016] loss=1.1540\n",
      "[Epoch 29 | Iter 00017] loss=1.1555\n",
      "[Epoch 29 | Iter 00018] loss=1.1524\n",
      "[Epoch 29 | Iter 00019] loss=1.1497\n",
      "[Epoch 29 | Iter 00020] loss=1.1465\n",
      "[Epoch 29 | Iter 00021] loss=1.1457\n",
      "[Epoch 29 | Iter 00022] loss=1.1503\n",
      "[Epoch 29 | Iter 00023] loss=1.1496\n",
      "[Epoch 29 | Iter 00024] loss=1.1510\n",
      "[Epoch 29 | Iter 00025] loss=1.1550\n",
      "[Epoch 29] Train: loss=1.1170 mIoU=0.2044 pixacc=0.6767 (45.9s+28.3s, 17.3 smp/s) | Val: loss=1.5732 mIoU=0.1286 pixacc=0.5573 (16.8s, 5.9 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1286) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.7s) size(37.7MB) total(1.4s)\n",
      "‚è±Ô∏è  Timing: Save(1.4s) | Total(92.5s) | Breakdown: Train(49.7%) Val(18.2%) Save(1.5%)\n",
      "[Epoch 30 | Iter 00001] loss=1.1350\n",
      "[Epoch 30 | Iter 00002] loss=1.1419\n",
      "[Epoch 30 | Iter 00003] loss=1.1399\n",
      "[Epoch 30 | Iter 00004] loss=1.1141\n",
      "[Epoch 30 | Iter 00005] loss=1.1114\n",
      "[Epoch 30 | Iter 00006] loss=1.1086\n",
      "[Epoch 30 | Iter 00007] loss=1.1138\n",
      "[Epoch 30 | Iter 00008] loss=1.1327\n",
      "[Epoch 30 | Iter 00009] loss=1.1326\n",
      "[Epoch 30 | Iter 00010] loss=1.1375\n",
      "[Epoch 30 | Iter 00011] loss=1.1444\n",
      "[Epoch 30 | Iter 00012] loss=1.1469\n",
      "[Epoch 30 | Iter 00013] loss=1.1468\n",
      "[Epoch 30 | Iter 00014] loss=1.1509\n",
      "[Epoch 30 | Iter 00015] loss=1.1466\n",
      "[Epoch 30 | Iter 00016] loss=1.1439\n",
      "[Epoch 30 | Iter 00017] loss=1.1371\n",
      "[Epoch 30 | Iter 00018] loss=1.1368\n",
      "[Epoch 30 | Iter 00019] loss=1.1382\n",
      "[Epoch 30 | Iter 00020] loss=1.1359\n",
      "[Epoch 30 | Iter 00021] loss=1.1355\n",
      "[Epoch 30 | Iter 00022] loss=1.1385\n",
      "[Epoch 30 | Iter 00023] loss=1.1387\n",
      "[Epoch 30 | Iter 00024] loss=1.1383\n",
      "[Epoch 30 | Iter 00025] loss=1.1347\n",
      "[Epoch 30] Train: loss=1.1034 mIoU=0.2094 pixacc=0.6814 (46.0s+27.1s, 17.3 smp/s) | Val: loss=1.5679 mIoU=0.1295 pixacc=0.5575 (15.6s, 6.4 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1295) to checkpoints/dual_encoder_unet_mobilenet/best.pth (1.1s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_030.pt (0.3s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.5s) size(37.7MB) total(2.0s)\n",
      "‚è±Ô∏è  Timing: Save(2.0s) | Total(90.7s) | Breakdown: Train(50.7%) Val(17.2%) Save(2.2%)\n",
      "[Epoch 31 | Iter 00001] loss=1.1907\n",
      "[Epoch 31 | Iter 00002] loss=1.1907\n",
      "[Epoch 31 | Iter 00003] loss=1.1708\n",
      "[Epoch 31 | Iter 00004] loss=1.1478\n",
      "[Epoch 31 | Iter 00005] loss=1.1387\n",
      "[Epoch 31 | Iter 00006] loss=1.1260\n",
      "[Epoch 31 | Iter 00007] loss=1.1318\n",
      "[Epoch 31 | Iter 00008] loss=1.1248\n",
      "[Epoch 31 | Iter 00009] loss=1.1210\n",
      "[Epoch 31 | Iter 00010] loss=1.1207\n",
      "[Epoch 31 | Iter 00011] loss=1.1233\n",
      "[Epoch 31 | Iter 00012] loss=1.1254\n",
      "[Epoch 31 | Iter 00013] loss=1.1263\n",
      "[Epoch 31 | Iter 00014] loss=1.1217\n",
      "[Epoch 31 | Iter 00015] loss=1.1181\n",
      "[Epoch 31 | Iter 00016] loss=1.1173\n",
      "[Epoch 31 | Iter 00017] loss=1.1191\n",
      "[Epoch 31 | Iter 00018] loss=1.1191\n",
      "[Epoch 31 | Iter 00019] loss=1.1160\n",
      "[Epoch 31 | Iter 00020] loss=1.1186\n",
      "[Epoch 31 | Iter 00021] loss=1.1212\n",
      "[Epoch 31 | Iter 00022] loss=1.1253\n",
      "[Epoch 31 | Iter 00023] loss=1.1261\n",
      "[Epoch 31 | Iter 00024] loss=1.1283\n",
      "[Epoch 31 | Iter 00025] loss=1.1275\n",
      "[Epoch 31] Train: loss=1.0892 mIoU=0.2153 pixacc=0.6866 (44.2s+27.1s, 18.0 smp/s) | Val: loss=1.5809 mIoU=0.1314 pixacc=0.5580 (18.2s, 5.5 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1314) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(1.2s)\n",
      "‚è±Ô∏è  Timing: Save(1.2s) | Total(90.6s) | Breakdown: Train(48.7%) Val(20.1%) Save(1.3%)\n",
      "[Epoch 32 | Iter 00001] loss=1.1593\n",
      "[Epoch 32 | Iter 00002] loss=1.1017\n",
      "[Epoch 32 | Iter 00003] loss=1.1230\n",
      "[Epoch 32 | Iter 00004] loss=1.1082\n",
      "[Epoch 32 | Iter 00005] loss=1.1151\n",
      "[Epoch 32 | Iter 00006] loss=1.1102\n",
      "[Epoch 32 | Iter 00007] loss=1.1135\n",
      "[Epoch 32 | Iter 00008] loss=1.1152\n",
      "[Epoch 32 | Iter 00009] loss=1.1165\n",
      "[Epoch 32 | Iter 00010] loss=1.1158\n",
      "[Epoch 32 | Iter 00011] loss=1.1231\n",
      "[Epoch 32 | Iter 00012] loss=1.1255\n",
      "[Epoch 32 | Iter 00013] loss=1.1233\n",
      "[Epoch 32 | Iter 00014] loss=1.1177\n",
      "[Epoch 32 | Iter 00015] loss=1.1162\n",
      "[Epoch 32 | Iter 00016] loss=1.1135\n",
      "[Epoch 32 | Iter 00017] loss=1.1138\n",
      "[Epoch 32 | Iter 00018] loss=1.1139\n",
      "[Epoch 32 | Iter 00019] loss=1.1111\n",
      "[Epoch 32 | Iter 00020] loss=1.1144\n",
      "[Epoch 32 | Iter 00021] loss=1.1102\n",
      "[Epoch 32 | Iter 00022] loss=1.1105\n",
      "[Epoch 32 | Iter 00023] loss=1.1115\n",
      "[Epoch 32 | Iter 00024] loss=1.1111\n",
      "[Epoch 32 | Iter 00025] loss=1.1191\n",
      "[Epoch 32] Train: loss=1.0755 mIoU=0.2168 pixacc=0.6892 (45.1s+28.9s, 17.6 smp/s) | Val: loss=1.5850 mIoU=0.1292 pixacc=0.5559 (16.7s, 6.0 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.7s) size(37.7MB) total(0.8s)\n",
      "‚è±Ô∏è  Timing: Save(0.8s) | Total(91.5s) | Breakdown: Train(49.3%) Val(18.3%) Save(0.8%)\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5850) >> Train loss (1.0755), gap: 0.5095\n",
      "[Epoch 33 | Iter 00001] loss=1.0484\n",
      "[Epoch 33 | Iter 00002] loss=1.0209\n",
      "[Epoch 33 | Iter 00003] loss=1.0363\n",
      "[Epoch 33 | Iter 00004] loss=1.0735\n",
      "[Epoch 33 | Iter 00005] loss=1.0727\n",
      "[Epoch 33 | Iter 00006] loss=1.0691\n",
      "[Epoch 33 | Iter 00007] loss=1.0734\n",
      "[Epoch 33 | Iter 00008] loss=1.0603\n",
      "[Epoch 33 | Iter 00009] loss=1.0751\n",
      "[Epoch 33 | Iter 00010] loss=1.0753\n",
      "[Epoch 33 | Iter 00011] loss=1.0897\n",
      "[Epoch 33 | Iter 00012] loss=1.0926\n",
      "[Epoch 33 | Iter 00013] loss=1.0912\n",
      "[Epoch 33 | Iter 00014] loss=1.0936\n",
      "[Epoch 33 | Iter 00015] loss=1.0960\n",
      "[Epoch 33 | Iter 00016] loss=1.0953\n",
      "[Epoch 33 | Iter 00017] loss=1.0922\n",
      "[Epoch 33 | Iter 00018] loss=1.0906\n",
      "[Epoch 33 | Iter 00019] loss=1.0925\n",
      "[Epoch 33 | Iter 00020] loss=1.0882\n",
      "[Epoch 33 | Iter 00021] loss=1.0941\n",
      "[Epoch 33 | Iter 00022] loss=1.0979\n",
      "[Epoch 33 | Iter 00023] loss=1.1002\n",
      "[Epoch 33 | Iter 00024] loss=1.1020\n",
      "[Epoch 33 | Iter 00025] loss=1.1066\n",
      "[Epoch 33] Train: loss=1.0655 mIoU=0.2204 pixacc=0.6924 (45.9s+27.1s, 17.3 smp/s) | Val: loss=1.5712 mIoU=0.1317 pixacc=0.5569 (16.0s, 6.2 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1317) to checkpoints/dual_encoder_unet_mobilenet/best.pth (1.1s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.6s) size(37.7MB) total(1.6s)\n",
      "‚è±Ô∏è  Timing: Save(1.7s) | Total(90.7s) | Breakdown: Train(50.7%) Val(17.6%) Save(1.8%)\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5712) >> Train loss (1.0655), gap: 0.5058\n",
      "[Epoch 34 | Iter 00001] loss=1.0707\n",
      "[Epoch 34 | Iter 00002] loss=1.0449\n",
      "[Epoch 34 | Iter 00003] loss=1.0231\n",
      "[Epoch 34 | Iter 00004] loss=1.0627\n",
      "[Epoch 34 | Iter 00005] loss=1.0854\n",
      "[Epoch 34 | Iter 00006] loss=1.0880\n",
      "[Epoch 34 | Iter 00007] loss=1.1059\n",
      "[Epoch 34 | Iter 00008] loss=1.1132\n",
      "[Epoch 34 | Iter 00009] loss=1.1217\n",
      "[Epoch 34 | Iter 00010] loss=1.1121\n",
      "[Epoch 34 | Iter 00011] loss=1.1105\n",
      "[Epoch 34 | Iter 00012] loss=1.0957\n",
      "[Epoch 34 | Iter 00013] loss=1.0892\n",
      "[Epoch 34 | Iter 00014] loss=1.0892\n",
      "[Epoch 34 | Iter 00015] loss=1.0910\n",
      "[Epoch 34 | Iter 00016] loss=1.0934\n",
      "[Epoch 34 | Iter 00017] loss=1.0916\n",
      "[Epoch 34 | Iter 00018] loss=1.0907\n",
      "[Epoch 34 | Iter 00019] loss=1.0941\n",
      "[Epoch 34 | Iter 00020] loss=1.0909\n",
      "[Epoch 34 | Iter 00021] loss=1.0913\n",
      "[Epoch 34 | Iter 00022] loss=1.0914\n",
      "[Epoch 34 | Iter 00023] loss=1.0925\n",
      "[Epoch 34 | Iter 00024] loss=1.0907\n",
      "[Epoch 34 | Iter 00025] loss=1.0921\n",
      "[Epoch 34] Train: loss=1.0543 mIoU=0.2262 pixacc=0.6967 (43.0s+25.9s, 18.5 smp/s) | Val: loss=1.5681 mIoU=0.1318 pixacc=0.5588 (14.4s, 7.0 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1318) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.6s) size(37.7MB) total(1.4s)\n",
      "‚è±Ô∏è  Timing: Save(1.4s) | Total(84.6s) | Breakdown: Train(50.8%) Val(17.0%) Save(1.6%)\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5681) >> Train loss (1.0543), gap: 0.5138\n",
      "[Epoch 35 | Iter 00001] loss=1.1284\n",
      "[Epoch 35 | Iter 00002] loss=1.0913\n",
      "[Epoch 35 | Iter 00003] loss=1.0810\n",
      "[Epoch 35 | Iter 00004] loss=1.0616\n",
      "[Epoch 35 | Iter 00005] loss=1.0662\n",
      "[Epoch 35 | Iter 00006] loss=1.0703\n",
      "[Epoch 35 | Iter 00007] loss=1.0794\n",
      "[Epoch 35 | Iter 00008] loss=1.0813\n",
      "[Epoch 35 | Iter 00009] loss=1.0863\n",
      "[Epoch 35 | Iter 00010] loss=1.0792\n",
      "[Epoch 35 | Iter 00011] loss=1.0728\n",
      "[Epoch 35 | Iter 00012] loss=1.0701\n",
      "[Epoch 35 | Iter 00013] loss=1.0641\n",
      "[Epoch 35 | Iter 00014] loss=1.0629\n",
      "[Epoch 35 | Iter 00015] loss=1.0614\n",
      "[Epoch 35 | Iter 00016] loss=1.0611\n",
      "[Epoch 35 | Iter 00017] loss=1.0634\n",
      "[Epoch 35 | Iter 00018] loss=1.0612\n",
      "[Epoch 35 | Iter 00019] loss=1.0626\n",
      "[Epoch 35 | Iter 00020] loss=1.0672\n",
      "[Epoch 35 | Iter 00021] loss=1.0658\n",
      "[Epoch 35 | Iter 00022] loss=1.0635\n",
      "[Epoch 35 | Iter 00023] loss=1.0638\n",
      "[Epoch 35 | Iter 00024] loss=1.0672\n",
      "[Epoch 35 | Iter 00025] loss=1.0709\n",
      "[Epoch 35] Train: loss=1.0424 mIoU=0.2280 pixacc=0.6989 (45.1s+27.4s, 17.6 smp/s) | Val: loss=1.5686 mIoU=0.1323 pixacc=0.5596 (16.6s, 6.0 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1323) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_035.pt (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.7s) size(37.7MB) total(1.8s)\n",
      "‚è±Ô∏è  Timing: Save(1.8s) | Total(90.8s) | Breakdown: Train(49.7%) Val(18.2%) Save(2.0%)\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5686) >> Train loss (1.0424), gap: 0.5261\n",
      "[Epoch 36 | Iter 00001] loss=0.9788\n",
      "[Epoch 36 | Iter 00002] loss=1.0146\n",
      "[Epoch 36 | Iter 00003] loss=1.0372\n",
      "[Epoch 36 | Iter 00004] loss=1.0498\n",
      "[Epoch 36 | Iter 00005] loss=1.0493\n",
      "[Epoch 36 | Iter 00006] loss=1.0482\n",
      "[Epoch 36 | Iter 00007] loss=1.0443\n",
      "[Epoch 36 | Iter 00008] loss=1.0511\n",
      "[Epoch 36 | Iter 00009] loss=1.0617\n",
      "[Epoch 36 | Iter 00010] loss=1.0741\n",
      "[Epoch 36 | Iter 00011] loss=1.0773\n",
      "[Epoch 36 | Iter 00012] loss=1.0828\n",
      "[Epoch 36 | Iter 00013] loss=1.0816\n",
      "[Epoch 36 | Iter 00014] loss=1.0788\n",
      "[Epoch 36 | Iter 00015] loss=1.0783\n",
      "[Epoch 36 | Iter 00016] loss=1.0747\n",
      "[Epoch 36 | Iter 00017] loss=1.0756\n",
      "[Epoch 36 | Iter 00018] loss=1.0754\n",
      "[Epoch 36 | Iter 00019] loss=1.0750\n",
      "[Epoch 36 | Iter 00020] loss=1.0703\n",
      "[Epoch 36 | Iter 00021] loss=1.0673\n",
      "[Epoch 36 | Iter 00022] loss=1.0661\n",
      "[Epoch 36 | Iter 00023] loss=1.0666\n",
      "[Epoch 36 | Iter 00024] loss=1.0620\n",
      "[Epoch 36 | Iter 00025] loss=1.0664\n",
      "[Epoch 36] Train: loss=1.0224 mIoU=0.2325 pixacc=0.7044 (53.8s+30.7s, 14.8 smp/s) | Val: loss=1.5729 mIoU=0.1335 pixacc=0.5562 (16.9s, 5.9 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1335) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.6s) size(37.7MB) total(1.4s)\n",
      "‚è±Ô∏è  Timing: Save(1.4s) | Total(102.8s) | Breakdown: Train(52.3%) Val(16.4%) Save(1.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5729) >> Train loss (1.0224), gap: 0.5506\n",
      "[Epoch 37 | Iter 00001] loss=1.0498\n",
      "[Epoch 37 | Iter 00002] loss=1.0624\n",
      "[Epoch 37 | Iter 00003] loss=1.0569\n",
      "[Epoch 37 | Iter 00004] loss=1.0855\n",
      "[Epoch 37 | Iter 00005] loss=1.0821\n",
      "[Epoch 37 | Iter 00006] loss=1.0842\n",
      "[Epoch 37 | Iter 00007] loss=1.0852\n",
      "[Epoch 37 | Iter 00008] loss=1.0698\n",
      "[Epoch 37 | Iter 00009] loss=1.0718\n",
      "[Epoch 37 | Iter 00010] loss=1.0712\n",
      "[Epoch 37 | Iter 00011] loss=1.0604\n",
      "[Epoch 37 | Iter 00012] loss=1.0567\n",
      "[Epoch 37 | Iter 00013] loss=1.0528\n",
      "[Epoch 37 | Iter 00014] loss=1.0569\n",
      "[Epoch 37 | Iter 00015] loss=1.0541\n",
      "[Epoch 37 | Iter 00016] loss=1.0560\n",
      "[Epoch 37 | Iter 00017] loss=1.0547\n",
      "[Epoch 37 | Iter 00018] loss=1.0601\n",
      "[Epoch 37 | Iter 00019] loss=1.0595\n",
      "[Epoch 37 | Iter 00020] loss=1.0517\n",
      "[Epoch 37 | Iter 00021] loss=1.0524\n",
      "[Epoch 37 | Iter 00022] loss=1.0510\n",
      "[Epoch 37 | Iter 00023] loss=1.0489\n",
      "[Epoch 37 | Iter 00024] loss=1.0467\n",
      "[Epoch 37 | Iter 00025] loss=1.0489\n",
      "[Epoch 37] Train: loss=1.0147 mIoU=0.2379 pixacc=0.7079 (49.7s+28.7s, 16.0 smp/s) | Val: loss=1.5713 mIoU=0.1334 pixacc=0.5564 (16.3s, 6.1 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.8s) size(37.7MB) total(0.8s)\n",
      "‚è±Ô∏è  Timing: Save(0.8s) | Total(95.5s) | Breakdown: Train(52.0%) Val(17.1%) Save(0.8%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2379) >> Val mIoU (0.1334), gap: 0.1045\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5713) >> Train loss (1.0147), gap: 0.5567\n",
      "[Epoch 38 | Iter 00001] loss=1.0984\n",
      "[Epoch 38 | Iter 00002] loss=1.0825\n",
      "[Epoch 38 | Iter 00003] loss=1.0592\n",
      "[Epoch 38 | Iter 00004] loss=1.0436\n",
      "[Epoch 38 | Iter 00005] loss=1.0360\n",
      "[Epoch 38 | Iter 00006] loss=1.0248\n",
      "[Epoch 38 | Iter 00007] loss=1.0367\n",
      "[Epoch 38 | Iter 00008] loss=1.0324\n",
      "[Epoch 38 | Iter 00009] loss=1.0299\n",
      "[Epoch 38 | Iter 00010] loss=1.0352\n",
      "[Epoch 38 | Iter 00011] loss=1.0353\n",
      "[Epoch 38 | Iter 00012] loss=1.0371\n",
      "[Epoch 38 | Iter 00013] loss=1.0436\n",
      "[Epoch 38 | Iter 00014] loss=1.0386\n",
      "[Epoch 38 | Iter 00015] loss=1.0440\n",
      "[Epoch 38 | Iter 00016] loss=1.0434\n",
      "[Epoch 38 | Iter 00017] loss=1.0403\n",
      "[Epoch 38 | Iter 00018] loss=1.0420\n",
      "[Epoch 38 | Iter 00019] loss=1.0413\n",
      "[Epoch 38 | Iter 00020] loss=1.0399\n",
      "[Epoch 38 | Iter 00021] loss=1.0390\n",
      "[Epoch 38 | Iter 00022] loss=1.0395\n",
      "[Epoch 38 | Iter 00023] loss=1.0395\n",
      "[Epoch 38 | Iter 00024] loss=1.0411\n",
      "[Epoch 38 | Iter 00025] loss=1.0392\n",
      "[Epoch 38] Train: loss=1.0087 mIoU=0.2384 pixacc=0.7076 (56.3s+35.0s, 14.1 smp/s) | Val: loss=1.5909 mIoU=0.1337 pixacc=0.5596 (18.3s, 5.5 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1337) to checkpoints/dual_encoder_unet_mobilenet/best.pth (1.7s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(1.0s) size(37.7MB) total(2.7s)\n",
      "‚è±Ô∏è  Timing: Save(2.7s) | Total(112.3s) | Breakdown: Train(50.1%) Val(16.3%) Save(2.4%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2384) >> Val mIoU (0.1337), gap: 0.1047\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5909) >> Train loss (1.0087), gap: 0.5821\n",
      "[Epoch 39 | Iter 00001] loss=1.0139\n",
      "[Epoch 39 | Iter 00002] loss=1.0680\n",
      "[Epoch 39 | Iter 00003] loss=1.0478\n",
      "[Epoch 39 | Iter 00004] loss=1.0364\n",
      "[Epoch 39 | Iter 00005] loss=1.0731\n",
      "[Epoch 39 | Iter 00006] loss=1.0464\n",
      "[Epoch 39 | Iter 00007] loss=1.0422\n",
      "[Epoch 39 | Iter 00008] loss=1.0297\n",
      "[Epoch 39 | Iter 00009] loss=1.0342\n",
      "[Epoch 39 | Iter 00010] loss=1.0261\n",
      "[Epoch 39 | Iter 00011] loss=1.0362\n",
      "[Epoch 39 | Iter 00012] loss=1.0447\n",
      "[Epoch 39 | Iter 00013] loss=1.0431\n",
      "[Epoch 39 | Iter 00014] loss=1.0371\n",
      "[Epoch 39 | Iter 00015] loss=1.0385\n",
      "[Epoch 39 | Iter 00016] loss=1.0353\n",
      "[Epoch 39 | Iter 00017] loss=1.0334\n",
      "[Epoch 39 | Iter 00018] loss=1.0324\n",
      "[Epoch 39 | Iter 00019] loss=1.0320\n",
      "[Epoch 39 | Iter 00020] loss=1.0297\n",
      "[Epoch 39 | Iter 00021] loss=1.0285\n",
      "[Epoch 39 | Iter 00022] loss=1.0248\n",
      "[Epoch 39 | Iter 00023] loss=1.0243\n",
      "[Epoch 39 | Iter 00024] loss=1.0251\n",
      "[Epoch 39 | Iter 00025] loss=1.0295\n",
      "[Epoch 39] Train: loss=0.9897 mIoU=0.2426 pixacc=0.7141 (54.4s+31.6s, 14.6 smp/s) | Val: loss=1.5975 mIoU=0.1333 pixacc=0.5539 (17.0s, 5.9 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(1.0s) size(37.7MB) total(1.0s)\n",
      "‚è±Ô∏è  Timing: Save(1.1s) | Total(104.0s) | Breakdown: Train(52.3%) Val(16.3%) Save(1.0%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2426) >> Val mIoU (0.1333), gap: 0.1093\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5975) >> Train loss (0.9897), gap: 0.6078\n",
      "[Epoch 40 | Iter 00001] loss=0.9810\n",
      "[Epoch 40 | Iter 00002] loss=1.0166\n",
      "[Epoch 40 | Iter 00003] loss=1.0166\n",
      "[Epoch 40 | Iter 00004] loss=1.0061\n",
      "[Epoch 40 | Iter 00005] loss=1.0197\n",
      "[Epoch 40 | Iter 00006] loss=1.0230\n",
      "[Epoch 40 | Iter 00007] loss=1.0129\n",
      "[Epoch 40 | Iter 00008] loss=0.9971\n",
      "[Epoch 40 | Iter 00009] loss=1.0037\n",
      "[Epoch 40 | Iter 00010] loss=1.0066\n",
      "[Epoch 40 | Iter 00011] loss=1.0078\n",
      "[Epoch 40 | Iter 00012] loss=1.0121\n",
      "[Epoch 40 | Iter 00013] loss=1.0127\n",
      "[Epoch 40 | Iter 00014] loss=1.0202\n",
      "[Epoch 40 | Iter 00015] loss=1.0174\n",
      "[Epoch 40 | Iter 00016] loss=1.0179\n",
      "[Epoch 40 | Iter 00017] loss=1.0175\n",
      "[Epoch 40 | Iter 00018] loss=1.0139\n",
      "[Epoch 40 | Iter 00019] loss=1.0230\n",
      "[Epoch 40 | Iter 00020] loss=1.0264\n",
      "[Epoch 40 | Iter 00021] loss=1.0229\n",
      "[Epoch 40 | Iter 00022] loss=1.0187\n",
      "[Epoch 40 | Iter 00023] loss=1.0143\n",
      "[Epoch 40 | Iter 00024] loss=1.0165\n",
      "[Epoch 40 | Iter 00025] loss=1.0211\n",
      "[Epoch 40] Train: loss=0.9838 mIoU=0.2486 pixacc=0.7169 (49.2s+28.6s, 16.2 smp/s) | Val: loss=1.5875 mIoU=0.1349 pixacc=0.5471 (19.1s, 5.2 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1349) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_040.pt (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.8s) size(37.7MB) total(1.9s)\n",
      "‚è±Ô∏è  Timing: Save(1.9s) | Total(98.8s) | Breakdown: Train(49.8%) Val(19.3%) Save(1.9%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2486) >> Val mIoU (0.1349), gap: 0.1136\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5875) >> Train loss (0.9838), gap: 0.6037\n",
      "[Epoch 41 | Iter 00001] loss=1.0726\n",
      "[Epoch 41 | Iter 00002] loss=1.0158\n",
      "[Epoch 41 | Iter 00003] loss=1.0135\n",
      "[Epoch 41 | Iter 00004] loss=1.0302\n",
      "[Epoch 41 | Iter 00005] loss=1.0399\n",
      "[Epoch 41 | Iter 00006] loss=1.0371\n",
      "[Epoch 41 | Iter 00007] loss=1.0446\n",
      "[Epoch 41 | Iter 00008] loss=1.0496\n",
      "[Epoch 41 | Iter 00009] loss=1.0404\n",
      "[Epoch 41 | Iter 00010] loss=1.0451\n",
      "[Epoch 41 | Iter 00011] loss=1.0413\n",
      "[Epoch 41 | Iter 00012] loss=1.0424\n",
      "[Epoch 41 | Iter 00013] loss=1.0303\n",
      "[Epoch 41 | Iter 00014] loss=1.0301\n",
      "[Epoch 41 | Iter 00015] loss=1.0233\n",
      "[Epoch 41 | Iter 00016] loss=1.0222\n",
      "[Epoch 41 | Iter 00017] loss=1.0167\n",
      "[Epoch 41 | Iter 00018] loss=1.0165\n",
      "[Epoch 41 | Iter 00019] loss=1.0163\n",
      "[Epoch 41 | Iter 00020] loss=1.0145\n",
      "[Epoch 41 | Iter 00021] loss=1.0124\n",
      "[Epoch 41 | Iter 00022] loss=1.0121\n",
      "[Epoch 41 | Iter 00023] loss=1.0124\n",
      "[Epoch 41 | Iter 00024] loss=1.0123\n",
      "[Epoch 41 | Iter 00025] loss=1.0128\n",
      "[Epoch 41] Train: loss=0.9725 mIoU=0.2485 pixacc=0.7174 (47.5s+28.1s, 16.8 smp/s) | Val: loss=1.5829 mIoU=0.1341 pixacc=0.5532 (16.4s, 6.1 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.7s) size(37.7MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(92.6s) | Breakdown: Train(51.2%) Val(17.7%) Save(0.8%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2485) >> Val mIoU (0.1341), gap: 0.1144\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5829) >> Train loss (0.9725), gap: 0.6103\n",
      "[Epoch 42 | Iter 00001] loss=1.0961\n",
      "[Epoch 42 | Iter 00002] loss=1.0214\n",
      "[Epoch 42 | Iter 00003] loss=1.0276\n",
      "[Epoch 42 | Iter 00004] loss=1.0180\n",
      "[Epoch 42 | Iter 00005] loss=1.0278\n",
      "[Epoch 42 | Iter 00006] loss=1.0263\n",
      "[Epoch 42 | Iter 00007] loss=1.0264\n",
      "[Epoch 42 | Iter 00008] loss=1.0235\n",
      "[Epoch 42 | Iter 00009] loss=1.0336\n",
      "[Epoch 42 | Iter 00010] loss=1.0200\n",
      "[Epoch 42 | Iter 00011] loss=1.0100\n",
      "[Epoch 42 | Iter 00012] loss=1.0024\n",
      "[Epoch 42 | Iter 00013] loss=1.0006\n",
      "[Epoch 42 | Iter 00014] loss=1.0088\n",
      "[Epoch 42 | Iter 00015] loss=1.0061\n",
      "[Epoch 42 | Iter 00016] loss=1.0089\n",
      "[Epoch 42 | Iter 00017] loss=1.0112\n",
      "[Epoch 42 | Iter 00018] loss=1.0092\n",
      "[Epoch 42 | Iter 00019] loss=1.0070\n",
      "[Epoch 42 | Iter 00020] loss=1.0051\n",
      "[Epoch 42 | Iter 00021] loss=1.0069\n",
      "[Epoch 42 | Iter 00022] loss=1.0056\n",
      "[Epoch 42 | Iter 00023] loss=1.0034\n",
      "[Epoch 42 | Iter 00024] loss=1.0037\n",
      "[Epoch 42 | Iter 00025] loss=1.0034\n",
      "[Epoch 42] Train: loss=0.9609 mIoU=0.2532 pixacc=0.7218 (47.3s+27.5s, 16.8 smp/s) | Val: loss=1.5816 mIoU=0.1354 pixacc=0.5559 (16.2s, 6.2 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1354) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.9s) size(37.7MB) total(1.6s)\n",
      "‚è±Ô∏è  Timing: Save(1.6s) | Total(92.6s) | Breakdown: Train(51.1%) Val(17.5%) Save(1.8%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2532) >> Val mIoU (0.1354), gap: 0.1179\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5816) >> Train loss (0.9609), gap: 0.6207\n",
      "[Epoch 43 | Iter 00001] loss=1.0177\n",
      "[Epoch 43 | Iter 00002] loss=1.0136\n",
      "[Epoch 43 | Iter 00003] loss=1.0401\n",
      "[Epoch 43 | Iter 00004] loss=1.0298\n",
      "[Epoch 43 | Iter 00005] loss=1.0308\n",
      "[Epoch 43 | Iter 00006] loss=1.0159\n",
      "[Epoch 43 | Iter 00007] loss=1.0039\n",
      "[Epoch 43 | Iter 00008] loss=1.0099\n",
      "[Epoch 43 | Iter 00009] loss=1.0067\n",
      "[Epoch 43 | Iter 00010] loss=1.0097\n",
      "[Epoch 43 | Iter 00011] loss=1.0104\n",
      "[Epoch 43 | Iter 00012] loss=1.0047\n",
      "[Epoch 43 | Iter 00013] loss=1.0028\n",
      "[Epoch 43 | Iter 00014] loss=1.0023\n",
      "[Epoch 43 | Iter 00015] loss=1.0045\n",
      "[Epoch 43 | Iter 00016] loss=0.9999\n",
      "[Epoch 43 | Iter 00017] loss=0.9965\n",
      "[Epoch 43 | Iter 00018] loss=0.9969\n",
      "[Epoch 43 | Iter 00019] loss=0.9938\n",
      "[Epoch 43 | Iter 00020] loss=0.9926\n",
      "[Epoch 43 | Iter 00021] loss=0.9906\n",
      "[Epoch 43 | Iter 00022] loss=0.9954\n",
      "[Epoch 43 | Iter 00023] loss=0.9928\n",
      "[Epoch 43 | Iter 00024] loss=0.9951\n",
      "[Epoch 43 | Iter 00025] loss=0.9934\n",
      "[Epoch 43] Train: loss=0.9481 mIoU=0.2591 pixacc=0.7258 (47.2s+27.2s, 16.8 smp/s) | Val: loss=1.5993 mIoU=0.1341 pixacc=0.5521 (16.3s, 6.1 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.7s) size(37.7MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(91.4s) | Breakdown: Train(51.7%) Val(17.8%) Save(0.7%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2591) >> Val mIoU (0.1341), gap: 0.1251\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5993) >> Train loss (0.9481), gap: 0.6511\n",
      "[Epoch 44 | Iter 00001] loss=1.0956\n",
      "[Epoch 44 | Iter 00002] loss=1.0059\n",
      "[Epoch 44 | Iter 00003] loss=0.9855\n",
      "[Epoch 44 | Iter 00004] loss=1.0066\n",
      "[Epoch 44 | Iter 00005] loss=0.9960\n",
      "[Epoch 44 | Iter 00006] loss=0.9787\n",
      "[Epoch 44 | Iter 00007] loss=0.9829\n",
      "[Epoch 44 | Iter 00008] loss=0.9744\n",
      "[Epoch 44 | Iter 00009] loss=0.9716\n",
      "[Epoch 44 | Iter 00010] loss=0.9774\n",
      "[Epoch 44 | Iter 00011] loss=0.9743\n",
      "[Epoch 44 | Iter 00012] loss=0.9755\n",
      "[Epoch 44 | Iter 00013] loss=0.9760\n",
      "[Epoch 44 | Iter 00014] loss=0.9753\n",
      "[Epoch 44 | Iter 00015] loss=0.9888\n",
      "[Epoch 44 | Iter 00016] loss=0.9895\n",
      "[Epoch 44 | Iter 00017] loss=0.9897\n",
      "[Epoch 44 | Iter 00018] loss=0.9867\n",
      "[Epoch 44 | Iter 00019] loss=0.9866\n",
      "[Epoch 44 | Iter 00020] loss=0.9876\n",
      "[Epoch 44 | Iter 00021] loss=0.9849\n",
      "[Epoch 44 | Iter 00022] loss=0.9810\n",
      "[Epoch 44 | Iter 00023] loss=0.9827\n",
      "[Epoch 44 | Iter 00024] loss=0.9828\n",
      "[Epoch 44 | Iter 00025] loss=0.9804\n",
      "[Epoch 44] Train: loss=0.9405 mIoU=0.2617 pixacc=0.7282 (43.9s+26.9s, 18.1 smp/s) | Val: loss=1.6096 mIoU=0.1359 pixacc=0.5556 (16.5s, 6.1 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1359) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.9s) size(37.7MB) total(1.6s)\n",
      "‚è±Ô∏è  Timing: Save(1.6s) | Total(88.8s) | Breakdown: Train(49.4%) Val(18.6%) Save(1.8%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2617) >> Val mIoU (0.1359), gap: 0.1258\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.6096) >> Train loss (0.9405), gap: 0.6691\n",
      "[Epoch 45 | Iter 00001] loss=0.9121\n",
      "[Epoch 45 | Iter 00002] loss=0.9528\n",
      "[Epoch 45 | Iter 00003] loss=0.9732\n",
      "[Epoch 45 | Iter 00004] loss=0.9809\n",
      "[Epoch 45 | Iter 00005] loss=0.9860\n",
      "[Epoch 45 | Iter 00006] loss=0.9735\n",
      "[Epoch 45 | Iter 00007] loss=0.9644\n",
      "[Epoch 45 | Iter 00008] loss=0.9682\n",
      "[Epoch 45 | Iter 00009] loss=0.9634\n",
      "[Epoch 45 | Iter 00010] loss=0.9707\n",
      "[Epoch 45 | Iter 00011] loss=0.9721\n",
      "[Epoch 45 | Iter 00012] loss=0.9738\n",
      "[Epoch 45 | Iter 00013] loss=0.9719\n",
      "[Epoch 45 | Iter 00014] loss=0.9786\n",
      "[Epoch 45 | Iter 00015] loss=0.9775\n",
      "[Epoch 45 | Iter 00016] loss=0.9820\n",
      "[Epoch 45 | Iter 00017] loss=0.9845\n",
      "[Epoch 45 | Iter 00018] loss=0.9837\n",
      "[Epoch 45 | Iter 00019] loss=0.9830\n",
      "[Epoch 45 | Iter 00020] loss=0.9843\n",
      "[Epoch 45 | Iter 00021] loss=0.9820\n",
      "[Epoch 45 | Iter 00022] loss=0.9813\n",
      "[Epoch 45 | Iter 00023] loss=0.9802\n",
      "[Epoch 45 | Iter 00024] loss=0.9780\n",
      "[Epoch 45 | Iter 00025] loss=0.9768\n",
      "[Epoch 45] Train: loss=0.9265 mIoU=0.2657 pixacc=0.7320 (55.5s+31.0s, 14.3 smp/s) | Val: loss=1.5971 mIoU=0.1356 pixacc=0.5519 (16.5s, 6.1 smp/s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_045.pt (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.9s) size(37.7MB) total(1.3s)\n",
      "‚è±Ô∏è  Timing: Save(1.3s) | Total(104.2s) | Breakdown: Train(53.2%) Val(15.8%) Save(1.2%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2657) >> Val mIoU (0.1356), gap: 0.1302\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5971) >> Train loss (0.9265), gap: 0.6706\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/src/datasets/nyu_depth.py\", line 95, in __getitem__\n    sample = self.transform(sample)\n  File \"/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/src/datasets/transforms.py\", line 295, in __call__\n    rgb, depth, mask = self._apply_spatial_augmentations(rgb, depth, mask)\n  File \"/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/src/datasets/transforms.py\", line 238, in _apply_spatial_augmentations\n    if random.random() < self.crop_zoom_p:\nAttributeError: 'SegTrainTransform' object has no attribute 'crop_zoom_p'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m config\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m \u001b[38;5;66;03m# lower learning rate for fine-tuning\u001b[39;00m\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SegmentationTrainer(config)\n\u001b[0;32m----> 6\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/src/training/trainer.py:338\u001b[0m, in \u001b[0;36mSegmentationTrainer.train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    335\u001b[0m epoch_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    336\u001b[0m train_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# Extract input based on modality configuration\u001b[39;00m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;66;03m# Extract targets and move to device\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     targets \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;66;03m# Move batch data to device\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    740\u001b[0m ):\n",
      "File \u001b[0;32m~/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1516\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1514\u001b[0m worker_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info\u001b[38;5;241m.\u001b[39mpop(idx)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1551\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data, worker_idx)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1551\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/_utils.py:769\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 769\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/src/datasets/nyu_depth.py\", line 95, in __getitem__\n    sample = self.transform(sample)\n  File \"/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/src/datasets/transforms.py\", line 295, in __call__\n    rgb, depth, mask = self._apply_spatial_augmentations(rgb, depth, mask)\n  File \"/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/src/datasets/transforms.py\", line 238, in _apply_spatial_augmentations\n    if random.random() < self.crop_zoom_p:\nAttributeError: 'SegTrainTransform' object has no attribute 'crop_zoom_p'\n"
     ]
    }
   ],
   "source": [
    "model.unfreeze_backbone()\n",
    "config\n",
    "config.epochs = 100\n",
    "config.lr = 1e-4 # lower learning rate for fine-tuning\n",
    "trainer = SegmentationTrainer(config)\n",
    "trained_model = trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a54d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3-small encoder unfrozen: parameters will be updated during training\n",
      "MobileNetV3-small depth encoder unfrozen: parameters will be updated during training\n",
      "Using device: mps\n",
      "EarlyStopping: monitoring 'val_miou' with patience=5 (mode=max)\n",
      "Training configuration:\n",
      "  Use RGB: True\n",
      "  Use Depth: True\n",
      "  Input channels: 4\n",
      "  Label mode: nyu40\n",
      "  Num classes: 40\n",
      "Training samples: 795\n",
      "Validation samples: 100\n",
      "Total parameters: 3,321,105\n",
      "Trainable parameters: 3,321,105\n",
      "Resuming training from: checkpoints/dual_encoder_unet_mobilenet/latest.pth\n",
      "‚úì Resumed from epoch 45\n",
      "‚úì Training history loaded with 45 epochs\n",
      "‚úì Best mIoU so far: 0.1359\n",
      "‚úì No optimizer parameter changes needed\n",
      "Starting training for 100 epochs (from epoch 46)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 46 | Iter 00001] loss=1.1985\n",
      "[Epoch 46 | Iter 00002] loss=1.2136\n",
      "[Epoch 46 | Iter 00003] loss=1.2265\n",
      "[Epoch 46 | Iter 00004] loss=1.2176\n",
      "[Epoch 46 | Iter 00005] loss=1.2083\n",
      "[Epoch 46 | Iter 00006] loss=1.2112\n",
      "[Epoch 46 | Iter 00007] loss=1.2165\n",
      "[Epoch 46 | Iter 00008] loss=1.2360\n",
      "[Epoch 46 | Iter 00009] loss=1.2357\n",
      "[Epoch 46 | Iter 00010] loss=1.2374\n",
      "[Epoch 46 | Iter 00011] loss=1.2276\n",
      "[Epoch 46 | Iter 00012] loss=1.2227\n",
      "[Epoch 46 | Iter 00013] loss=1.2247\n",
      "[Epoch 46 | Iter 00014] loss=1.2258\n",
      "[Epoch 46 | Iter 00015] loss=1.2149\n",
      "[Epoch 46 | Iter 00016] loss=1.2179\n",
      "[Epoch 46 | Iter 00017] loss=1.2190\n",
      "[Epoch 46 | Iter 00018] loss=1.2135\n",
      "[Epoch 46 | Iter 00019] loss=1.2198\n",
      "[Epoch 46 | Iter 00020] loss=1.2190\n",
      "[Epoch 46 | Iter 00021] loss=1.2193\n",
      "[Epoch 46 | Iter 00022] loss=1.2137\n",
      "[Epoch 46 | Iter 00023] loss=1.2094\n",
      "[Epoch 46 | Iter 00024] loss=1.2112\n",
      "[Epoch 46 | Iter 00025] loss=1.2050\n",
      "[Epoch 46] Train: loss=1.1421 mIoU=0.2226 pixacc=0.6693 (48.8s+26.7s, 16.3 smp/s) | Val: loss=1.6238 mIoU=0.1359 pixacc=0.5531 (15.0s, 6.7 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.5s) size(37.7MB) total(0.5s)\n",
      "‚è±Ô∏è  Timing: Save(0.5s) | Total(90.9s) | Breakdown: Train(53.7%) Val(16.5%) Save(0.5%)\n",
      "[Epoch 47 | Iter 00001] loss=1.2881\n",
      "[Epoch 47 | Iter 00002] loss=1.1835\n",
      "[Epoch 47 | Iter 00003] loss=1.1690\n",
      "[Epoch 47 | Iter 00004] loss=1.1983\n",
      "[Epoch 47 | Iter 00005] loss=1.1812\n",
      "[Epoch 47 | Iter 00006] loss=1.1728\n",
      "[Epoch 47 | Iter 00007] loss=1.1717\n",
      "[Epoch 47 | Iter 00008] loss=1.1769\n",
      "[Epoch 47 | Iter 00009] loss=1.1732\n",
      "[Epoch 47 | Iter 00010] loss=1.1752\n",
      "[Epoch 47 | Iter 00011] loss=1.1777\n",
      "[Epoch 47 | Iter 00012] loss=1.1850\n",
      "[Epoch 47 | Iter 00013] loss=1.1832\n",
      "[Epoch 47 | Iter 00014] loss=1.1763\n",
      "[Epoch 47 | Iter 00015] loss=1.1816\n",
      "[Epoch 47 | Iter 00016] loss=1.1718\n",
      "[Epoch 47 | Iter 00017] loss=1.1647\n",
      "[Epoch 47 | Iter 00018] loss=1.1711\n",
      "[Epoch 47 | Iter 00019] loss=1.1730\n",
      "[Epoch 47 | Iter 00020] loss=1.1719\n",
      "[Epoch 47 | Iter 00021] loss=1.1706\n",
      "[Epoch 47 | Iter 00022] loss=1.1685\n",
      "[Epoch 47 | Iter 00023] loss=1.1648\n",
      "[Epoch 47 | Iter 00024] loss=1.1639\n",
      "[Epoch 47 | Iter 00025] loss=1.1643\n",
      "[Epoch 47] Train: loss=1.1113 mIoU=0.2284 pixacc=0.6758 (52.9s+26.7s, 15.0 smp/s) | Val: loss=1.5731 mIoU=0.1412 pixacc=0.5614 (15.4s, 6.5 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1412) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.6s) size(37.7MB) total(1.4s)\n",
      "‚è±Ô∏è  Timing: Save(1.4s) | Total(96.4s) | Breakdown: Train(54.8%) Val(16.0%) Save(1.5%)\n",
      "[Epoch 48 | Iter 00001] loss=1.1683\n",
      "[Epoch 48 | Iter 00002] loss=1.1110\n",
      "[Epoch 48 | Iter 00003] loss=1.1280\n",
      "[Epoch 48 | Iter 00004] loss=1.1352\n",
      "[Epoch 48 | Iter 00005] loss=1.1171\n",
      "[Epoch 48 | Iter 00006] loss=1.1397\n",
      "[Epoch 48 | Iter 00007] loss=1.1290\n",
      "[Epoch 48 | Iter 00008] loss=1.1285\n",
      "[Epoch 48 | Iter 00009] loss=1.1216\n",
      "[Epoch 48 | Iter 00010] loss=1.1222\n",
      "[Epoch 48 | Iter 00011] loss=1.1230\n",
      "[Epoch 48 | Iter 00012] loss=1.1239\n",
      "[Epoch 48 | Iter 00013] loss=1.1291\n",
      "[Epoch 48 | Iter 00014] loss=1.1298\n",
      "[Epoch 48 | Iter 00015] loss=1.1286\n",
      "[Epoch 48 | Iter 00016] loss=1.1267\n",
      "[Epoch 48 | Iter 00017] loss=1.1246\n",
      "[Epoch 48 | Iter 00018] loss=1.1254\n",
      "[Epoch 48 | Iter 00019] loss=1.1280\n",
      "[Epoch 48 | Iter 00020] loss=1.1313\n",
      "[Epoch 48 | Iter 00021] loss=1.1321\n",
      "[Epoch 48 | Iter 00022] loss=1.1338\n",
      "[Epoch 48 | Iter 00023] loss=1.1334\n",
      "[Epoch 48 | Iter 00024] loss=1.1326\n",
      "[Epoch 48 | Iter 00025] loss=1.1356\n",
      "[Epoch 48] Train: loss=1.0927 mIoU=0.2341 pixacc=0.6828 (48.5s+25.5s, 16.4 smp/s) | Val: loss=1.5768 mIoU=0.1386 pixacc=0.5632 (13.9s, 7.2 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(88.4s) | Breakdown: Train(54.9%) Val(15.8%) Save(0.5%)\n",
      "[Epoch 49 | Iter 00001] loss=1.0961\n",
      "[Epoch 49 | Iter 00002] loss=1.1531\n",
      "[Epoch 49 | Iter 00003] loss=1.2070\n",
      "[Epoch 49 | Iter 00004] loss=1.1905\n",
      "[Epoch 49 | Iter 00005] loss=1.1708\n",
      "[Epoch 49 | Iter 00006] loss=1.1568\n",
      "[Epoch 49 | Iter 00007] loss=1.1499\n",
      "[Epoch 49 | Iter 00008] loss=1.1474\n",
      "[Epoch 49 | Iter 00009] loss=1.1380\n",
      "[Epoch 49 | Iter 00010] loss=1.1405\n",
      "[Epoch 49 | Iter 00011] loss=1.1477\n",
      "[Epoch 49 | Iter 00012] loss=1.1440\n",
      "[Epoch 49 | Iter 00013] loss=1.1396\n",
      "[Epoch 49 | Iter 00014] loss=1.1323\n",
      "[Epoch 49 | Iter 00015] loss=1.1276\n",
      "[Epoch 49 | Iter 00016] loss=1.1288\n",
      "[Epoch 49 | Iter 00017] loss=1.1264\n",
      "[Epoch 49 | Iter 00018] loss=1.1345\n",
      "[Epoch 49 | Iter 00019] loss=1.1332\n",
      "[Epoch 49 | Iter 00020] loss=1.1299\n",
      "[Epoch 49 | Iter 00021] loss=1.1282\n",
      "[Epoch 49 | Iter 00022] loss=1.1269\n",
      "[Epoch 49 | Iter 00023] loss=1.1290\n",
      "[Epoch 49 | Iter 00024] loss=1.1273\n",
      "[Epoch 49 | Iter 00025] loss=1.1303\n",
      "[Epoch 49] Train: loss=1.0731 mIoU=0.2380 pixacc=0.6862 (47.6s+27.9s, 16.7 smp/s) | Val: loss=1.5413 mIoU=0.1445 pixacc=0.5676 (15.5s, 6.4 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1445) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(1.2s)\n",
      "‚è±Ô∏è  Timing: Save(1.2s) | Total(92.2s) | Breakdown: Train(51.6%) Val(16.9%) Save(1.3%)\n",
      "[Epoch 50 | Iter 00001] loss=0.9911\n",
      "[Epoch 50 | Iter 00002] loss=1.0757\n",
      "[Epoch 50 | Iter 00003] loss=1.0679\n",
      "[Epoch 50 | Iter 00004] loss=1.0978\n",
      "[Epoch 50 | Iter 00005] loss=1.0913\n",
      "[Epoch 50 | Iter 00006] loss=1.1099\n",
      "[Epoch 50 | Iter 00007] loss=1.1130\n",
      "[Epoch 50 | Iter 00008] loss=1.1237\n",
      "[Epoch 50 | Iter 00009] loss=1.1169\n",
      "[Epoch 50 | Iter 00010] loss=1.1126\n",
      "[Epoch 50 | Iter 00011] loss=1.1152\n",
      "[Epoch 50 | Iter 00012] loss=1.1186\n",
      "[Epoch 50 | Iter 00013] loss=1.1186\n",
      "[Epoch 50 | Iter 00014] loss=1.1118\n",
      "[Epoch 50 | Iter 00015] loss=1.1108\n",
      "[Epoch 50 | Iter 00016] loss=1.1078\n",
      "[Epoch 50 | Iter 00017] loss=1.1011\n",
      "[Epoch 50 | Iter 00018] loss=1.0995\n",
      "[Epoch 50 | Iter 00019] loss=1.1017\n",
      "[Epoch 50 | Iter 00020] loss=1.0959\n",
      "[Epoch 50 | Iter 00021] loss=1.0976\n",
      "[Epoch 50 | Iter 00022] loss=1.1008\n",
      "[Epoch 50 | Iter 00023] loss=1.1034\n",
      "[Epoch 50 | Iter 00024] loss=1.1061\n",
      "[Epoch 50 | Iter 00025] loss=1.1031\n",
      "[Epoch 50] Train: loss=1.0503 mIoU=0.2437 pixacc=0.6925 (50.5s+27.0s, 15.7 smp/s) | Val: loss=1.5483 mIoU=0.1446 pixacc=0.5695 (15.1s, 6.6 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1446) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_050.pt (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(1.6s)\n",
      "‚è±Ô∏è  Timing: Save(1.6s) | Total(94.3s) | Breakdown: Train(53.6%) Val(16.0%) Save(1.7%)\n",
      "[Epoch 51 | Iter 00001] loss=1.0275\n",
      "[Epoch 51 | Iter 00002] loss=1.0258\n",
      "[Epoch 51 | Iter 00003] loss=1.0499\n",
      "[Epoch 51 | Iter 00004] loss=1.0506\n",
      "[Epoch 51 | Iter 00005] loss=1.0490\n",
      "[Epoch 51 | Iter 00006] loss=1.0311\n",
      "[Epoch 51 | Iter 00007] loss=1.0295\n",
      "[Epoch 51 | Iter 00008] loss=1.0306\n",
      "[Epoch 51 | Iter 00009] loss=1.0496\n",
      "[Epoch 51 | Iter 00010] loss=1.0597\n",
      "[Epoch 51 | Iter 00011] loss=1.0683\n",
      "[Epoch 51 | Iter 00012] loss=1.0731\n",
      "[Epoch 51 | Iter 00013] loss=1.0769\n",
      "[Epoch 51 | Iter 00014] loss=1.0749\n",
      "[Epoch 51 | Iter 00015] loss=1.0776\n",
      "[Epoch 51 | Iter 00016] loss=1.0867\n",
      "[Epoch 51 | Iter 00017] loss=1.0834\n",
      "[Epoch 51 | Iter 00018] loss=1.0866\n",
      "[Epoch 51 | Iter 00019] loss=1.0838\n",
      "[Epoch 51 | Iter 00020] loss=1.0808\n",
      "[Epoch 51 | Iter 00021] loss=1.0810\n",
      "[Epoch 51 | Iter 00022] loss=1.0799\n",
      "[Epoch 51 | Iter 00023] loss=1.0816\n",
      "[Epoch 51 | Iter 00024] loss=1.0838\n",
      "[Epoch 51 | Iter 00025] loss=1.0808\n",
      "[Epoch 51] Train: loss=1.0559 mIoU=0.2479 pixacc=0.6922 (47.6s+25.3s, 16.7 smp/s) | Val: loss=1.5451 mIoU=0.1461 pixacc=0.5673 (13.7s, 7.3 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1461) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(1.1s)\n",
      "‚è±Ô∏è  Timing: Save(1.1s) | Total(87.6s) | Breakdown: Train(54.3%) Val(15.6%) Save(1.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2479) >> Val mIoU (0.1461), gap: 0.1018\n",
      "[Epoch 52 | Iter 00001] loss=1.0518\n",
      "[Epoch 52 | Iter 00002] loss=1.0904\n",
      "[Epoch 52 | Iter 00003] loss=1.0728\n",
      "[Epoch 52 | Iter 00004] loss=1.0722\n",
      "[Epoch 52 | Iter 00005] loss=1.0728\n",
      "[Epoch 52 | Iter 00006] loss=1.0726\n",
      "[Epoch 52 | Iter 00007] loss=1.0843\n",
      "[Epoch 52 | Iter 00008] loss=1.0803\n",
      "[Epoch 52 | Iter 00009] loss=1.0723\n",
      "[Epoch 52 | Iter 00010] loss=1.0830\n",
      "[Epoch 52 | Iter 00011] loss=1.0883\n",
      "[Epoch 52 | Iter 00012] loss=1.0879\n",
      "[Epoch 52 | Iter 00013] loss=1.0850\n",
      "[Epoch 52 | Iter 00014] loss=1.0832\n",
      "[Epoch 52 | Iter 00015] loss=1.0864\n",
      "[Epoch 52 | Iter 00016] loss=1.0869\n",
      "[Epoch 52 | Iter 00017] loss=1.0901\n",
      "[Epoch 52 | Iter 00018] loss=1.0927\n",
      "[Epoch 52 | Iter 00019] loss=1.0939\n",
      "[Epoch 52 | Iter 00020] loss=1.0939\n",
      "[Epoch 52 | Iter 00021] loss=1.0844\n",
      "[Epoch 52 | Iter 00022] loss=1.0862\n",
      "[Epoch 52 | Iter 00023] loss=1.0852\n",
      "[Epoch 52 | Iter 00024] loss=1.0826\n",
      "[Epoch 52 | Iter 00025] loss=1.0844\n",
      "[Epoch 52] Train: loss=1.0517 mIoU=0.2480 pixacc=0.6943 (46.7s+27.2s, 17.0 smp/s) | Val: loss=1.5710 mIoU=0.1441 pixacc=0.5655 (15.3s, 6.6 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(89.6s) | Breakdown: Train(52.2%) Val(17.0%) Save(0.5%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2480) >> Val mIoU (0.1441), gap: 0.1039\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5710) >> Train loss (1.0517), gap: 0.5193\n",
      "[Epoch 53 | Iter 00001] loss=1.0545\n",
      "[Epoch 53 | Iter 00002] loss=1.1034\n",
      "[Epoch 53 | Iter 00003] loss=1.0697\n",
      "[Epoch 53 | Iter 00004] loss=1.0482\n",
      "[Epoch 53 | Iter 00005] loss=1.0729\n",
      "[Epoch 53 | Iter 00006] loss=1.0918\n",
      "[Epoch 53 | Iter 00007] loss=1.1040\n",
      "[Epoch 53 | Iter 00008] loss=1.0951\n",
      "[Epoch 53 | Iter 00009] loss=1.0905\n",
      "[Epoch 53 | Iter 00010] loss=1.0866\n",
      "[Epoch 53 | Iter 00011] loss=1.0853\n",
      "[Epoch 53 | Iter 00012] loss=1.0883\n",
      "[Epoch 53 | Iter 00013] loss=1.0935\n",
      "[Epoch 53 | Iter 00014] loss=1.0925\n",
      "[Epoch 53 | Iter 00015] loss=1.0903\n",
      "[Epoch 53 | Iter 00016] loss=1.0864\n",
      "[Epoch 53 | Iter 00017] loss=1.0828\n",
      "[Epoch 53 | Iter 00018] loss=1.0815\n",
      "[Epoch 53 | Iter 00019] loss=1.0864\n",
      "[Epoch 53 | Iter 00020] loss=1.0818\n",
      "[Epoch 53 | Iter 00021] loss=1.0855\n",
      "[Epoch 53 | Iter 00022] loss=1.0857\n",
      "[Epoch 53 | Iter 00023] loss=1.0826\n",
      "[Epoch 53 | Iter 00024] loss=1.0824\n",
      "[Epoch 53 | Iter 00025] loss=1.0831\n",
      "[Epoch 53] Train: loss=1.0383 mIoU=0.2520 pixacc=0.6966 (46.4s+25.0s, 17.1 smp/s) | Val: loss=1.5433 mIoU=0.1460 pixacc=0.5670 (14.7s, 6.8 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(86.6s) | Breakdown: Train(53.6%) Val(17.0%) Save(0.4%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2520) >> Val mIoU (0.1460), gap: 0.1060\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5433) >> Train loss (1.0383), gap: 0.5051\n",
      "[Epoch 54 | Iter 00001] loss=1.0348\n",
      "[Epoch 54 | Iter 00002] loss=1.0484\n",
      "[Epoch 54 | Iter 00003] loss=1.0443\n",
      "[Epoch 54 | Iter 00004] loss=1.0572\n",
      "[Epoch 54 | Iter 00005] loss=1.0527\n",
      "[Epoch 54 | Iter 00006] loss=1.0444\n",
      "[Epoch 54 | Iter 00007] loss=1.0339\n",
      "[Epoch 54 | Iter 00008] loss=1.0288\n",
      "[Epoch 54 | Iter 00009] loss=1.0351\n",
      "[Epoch 54 | Iter 00010] loss=1.0503\n",
      "[Epoch 54 | Iter 00011] loss=1.0549\n",
      "[Epoch 54 | Iter 00012] loss=1.0586\n",
      "[Epoch 54 | Iter 00013] loss=1.0631\n",
      "[Epoch 54 | Iter 00014] loss=1.0622\n",
      "[Epoch 54 | Iter 00015] loss=1.0630\n",
      "[Epoch 54 | Iter 00016] loss=1.0602\n",
      "[Epoch 54 | Iter 00017] loss=1.0650\n",
      "[Epoch 54 | Iter 00018] loss=1.0631\n",
      "[Epoch 54 | Iter 00019] loss=1.0611\n",
      "[Epoch 54 | Iter 00020] loss=1.0586\n",
      "[Epoch 54 | Iter 00021] loss=1.0566\n",
      "[Epoch 54 | Iter 00022] loss=1.0616\n",
      "[Epoch 54 | Iter 00023] loss=1.0607\n",
      "[Epoch 54 | Iter 00024] loss=1.0618\n",
      "[Epoch 54 | Iter 00025] loss=1.0656\n",
      "[Epoch 54] Train: loss=1.0218 mIoU=0.2542 pixacc=0.6996 (46.2s+25.0s, 17.2 smp/s) | Val: loss=1.5545 mIoU=0.1472 pixacc=0.5663 (13.6s, 7.3 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1472) to checkpoints/dual_encoder_unet_mobilenet/best.pth (1.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(1.7s)\n",
      "‚è±Ô∏è  Timing: Save(1.7s) | Total(86.5s) | Breakdown: Train(53.4%) Val(15.8%) Save(1.9%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2542) >> Val mIoU (0.1472), gap: 0.1070\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5545) >> Train loss (1.0218), gap: 0.5327\n",
      "[Epoch 55 | Iter 00001] loss=1.0549\n",
      "[Epoch 55 | Iter 00002] loss=1.0619\n",
      "[Epoch 55 | Iter 00003] loss=1.0560\n",
      "[Epoch 55 | Iter 00004] loss=1.0448\n",
      "[Epoch 55 | Iter 00005] loss=1.0398\n",
      "[Epoch 55 | Iter 00006] loss=1.0416\n",
      "[Epoch 55 | Iter 00007] loss=1.0500\n",
      "[Epoch 55 | Iter 00008] loss=1.0631\n",
      "[Epoch 55 | Iter 00009] loss=1.0591\n",
      "[Epoch 55 | Iter 00010] loss=1.0600\n",
      "[Epoch 55 | Iter 00011] loss=1.0637\n",
      "[Epoch 55 | Iter 00012] loss=1.0698\n",
      "[Epoch 55 | Iter 00013] loss=1.0675\n",
      "[Epoch 55 | Iter 00014] loss=1.0723\n",
      "[Epoch 55 | Iter 00015] loss=1.0701\n",
      "[Epoch 55 | Iter 00016] loss=1.0664\n",
      "[Epoch 55 | Iter 00017] loss=1.0589\n",
      "[Epoch 55 | Iter 00018] loss=1.0563\n",
      "[Epoch 55 | Iter 00019] loss=1.0563\n",
      "[Epoch 55 | Iter 00020] loss=1.0542\n",
      "[Epoch 55 | Iter 00021] loss=1.0532\n",
      "[Epoch 55 | Iter 00022] loss=1.0561\n",
      "[Epoch 55 | Iter 00023] loss=1.0558\n",
      "[Epoch 55 | Iter 00024] loss=1.0548\n",
      "[Epoch 55 | Iter 00025] loss=1.0530\n",
      "[Epoch 55] Train: loss=1.0050 mIoU=0.2598 pixacc=0.7040 (46.4s+24.8s, 17.1 smp/s) | Val: loss=1.5335 mIoU=0.1502 pixacc=0.5718 (14.0s, 7.1 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1502) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_055.pt (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(1.5s)\n",
      "‚è±Ô∏è  Timing: Save(1.5s) | Total(86.7s) | Breakdown: Train(53.5%) Val(16.2%) Save(1.7%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2598) >> Val mIoU (0.1502), gap: 0.1096\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5335) >> Train loss (1.0050), gap: 0.5285\n",
      "[Epoch 56 | Iter 00001] loss=1.0540\n",
      "[Epoch 56 | Iter 00002] loss=1.0403\n",
      "[Epoch 56 | Iter 00003] loss=1.0357\n",
      "[Epoch 56 | Iter 00004] loss=1.0212\n",
      "[Epoch 56 | Iter 00005] loss=1.0284\n",
      "[Epoch 56 | Iter 00006] loss=1.0236\n",
      "[Epoch 56 | Iter 00007] loss=1.0270\n",
      "[Epoch 56 | Iter 00008] loss=1.0234\n",
      "[Epoch 56 | Iter 00009] loss=1.0208\n",
      "[Epoch 56 | Iter 00010] loss=1.0274\n",
      "[Epoch 56 | Iter 00011] loss=1.0326\n",
      "[Epoch 56 | Iter 00012] loss=1.0364\n",
      "[Epoch 56 | Iter 00013] loss=1.0360\n",
      "[Epoch 56 | Iter 00014] loss=1.0316\n",
      "[Epoch 56 | Iter 00015] loss=1.0265\n",
      "[Epoch 56 | Iter 00016] loss=1.0274\n",
      "[Epoch 56 | Iter 00017] loss=1.0307\n",
      "[Epoch 56 | Iter 00018] loss=1.0335\n",
      "[Epoch 56 | Iter 00019] loss=1.0307\n",
      "[Epoch 56 | Iter 00020] loss=1.0327\n",
      "[Epoch 56 | Iter 00021] loss=1.0333\n",
      "[Epoch 56 | Iter 00022] loss=1.0394\n",
      "[Epoch 56 | Iter 00023] loss=1.0408\n",
      "[Epoch 56 | Iter 00024] loss=1.0432\n",
      "[Epoch 56 | Iter 00025] loss=1.0442\n",
      "[Epoch 56] Train: loss=0.9944 mIoU=0.2662 pixacc=0.7085 (59.6s+26.9s, 13.3 smp/s) | Val: loss=1.5369 mIoU=0.1534 pixacc=0.5725 (15.1s, 6.6 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1534) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(1.3s)\n",
      "‚è±Ô∏è  Timing: Save(1.3s) | Total(102.8s) | Breakdown: Train(58.0%) Val(14.7%) Save(1.2%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2662) >> Val mIoU (0.1534), gap: 0.1128\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5369) >> Train loss (0.9944), gap: 0.5425\n",
      "[Epoch 57 | Iter 00001] loss=1.0919\n",
      "[Epoch 57 | Iter 00002] loss=1.0213\n",
      "[Epoch 57 | Iter 00003] loss=1.0466\n",
      "[Epoch 57 | Iter 00004] loss=1.0350\n",
      "[Epoch 57 | Iter 00005] loss=1.0424\n",
      "[Epoch 57 | Iter 00006] loss=1.0352\n",
      "[Epoch 57 | Iter 00007] loss=1.0332\n",
      "[Epoch 57 | Iter 00008] loss=1.0302\n",
      "[Epoch 57 | Iter 00009] loss=1.0382\n",
      "[Epoch 57 | Iter 00010] loss=1.0355\n",
      "[Epoch 57 | Iter 00011] loss=1.0457\n",
      "[Epoch 57 | Iter 00012] loss=1.0482\n",
      "[Epoch 57 | Iter 00013] loss=1.0489\n",
      "[Epoch 57 | Iter 00014] loss=1.0400\n",
      "[Epoch 57 | Iter 00015] loss=1.0401\n",
      "[Epoch 57 | Iter 00016] loss=1.0396\n",
      "[Epoch 57 | Iter 00017] loss=1.0371\n",
      "[Epoch 57 | Iter 00018] loss=1.0371\n",
      "[Epoch 57 | Iter 00019] loss=1.0359\n",
      "[Epoch 57 | Iter 00020] loss=1.0387\n",
      "[Epoch 57 | Iter 00021] loss=1.0346\n",
      "[Epoch 57 | Iter 00022] loss=1.0335\n",
      "[Epoch 57 | Iter 00023] loss=1.0341\n",
      "[Epoch 57 | Iter 00024] loss=1.0343\n",
      "[Epoch 57 | Iter 00025] loss=1.0382\n",
      "[Epoch 57] Train: loss=0.9969 mIoU=0.2700 pixacc=0.7092 (54.7s+27.3s, 14.5 smp/s) | Val: loss=1.5330 mIoU=0.1525 pixacc=0.5759 (15.7s, 6.4 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(98.0s) | Breakdown: Train(55.7%) Val(16.0%) Save(0.4%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2700) >> Val mIoU (0.1525), gap: 0.1175\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5330) >> Train loss (0.9969), gap: 0.5362\n",
      "[Epoch 58 | Iter 00001] loss=0.9990\n",
      "[Epoch 58 | Iter 00002] loss=0.9812\n",
      "[Epoch 58 | Iter 00003] loss=0.9981\n",
      "[Epoch 58 | Iter 00004] loss=1.0197\n",
      "[Epoch 58 | Iter 00005] loss=1.0203\n",
      "[Epoch 58 | Iter 00006] loss=1.0147\n",
      "[Epoch 58 | Iter 00007] loss=1.0145\n",
      "[Epoch 58 | Iter 00008] loss=1.0012\n",
      "[Epoch 58 | Iter 00009] loss=1.0150\n",
      "[Epoch 58 | Iter 00010] loss=1.0133\n",
      "[Epoch 58 | Iter 00011] loss=1.0270\n",
      "[Epoch 58 | Iter 00012] loss=1.0274\n",
      "[Epoch 58 | Iter 00013] loss=1.0248\n",
      "[Epoch 58 | Iter 00014] loss=1.0259\n",
      "[Epoch 58 | Iter 00015] loss=1.0252\n",
      "[Epoch 58 | Iter 00016] loss=1.0284\n",
      "[Epoch 58 | Iter 00017] loss=1.0282\n",
      "[Epoch 58 | Iter 00018] loss=1.0260\n",
      "[Epoch 58 | Iter 00019] loss=1.0251\n",
      "[Epoch 58 | Iter 00020] loss=1.0212\n",
      "[Epoch 58 | Iter 00021] loss=1.0260\n",
      "[Epoch 58 | Iter 00022] loss=1.0288\n",
      "[Epoch 58 | Iter 00023] loss=1.0303\n",
      "[Epoch 58 | Iter 00024] loss=1.0303\n",
      "[Epoch 58 | Iter 00025] loss=1.0335\n",
      "[Epoch 58] Train: loss=0.9782 mIoU=0.2766 pixacc=0.7141 (53.7s+26.7s, 14.8 smp/s) | Val: loss=1.5287 mIoU=0.1547 pixacc=0.5730 (18.0s, 5.6 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1547) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(1.2s)\n",
      "‚è±Ô∏è  Timing: Save(1.2s) | Total(99.5s) | Breakdown: Train(53.9%) Val(18.0%) Save(1.2%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2766) >> Val mIoU (0.1547), gap: 0.1219\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5287) >> Train loss (0.9782), gap: 0.5505\n",
      "[Epoch 59 | Iter 00001] loss=1.0092\n",
      "[Epoch 59 | Iter 00002] loss=0.9697\n",
      "[Epoch 59 | Iter 00003] loss=0.9480\n",
      "[Epoch 59 | Iter 00004] loss=0.9925\n",
      "[Epoch 59 | Iter 00005] loss=1.0154\n",
      "[Epoch 59 | Iter 00006] loss=1.0147\n",
      "[Epoch 59 | Iter 00007] loss=1.0243\n",
      "[Epoch 59 | Iter 00008] loss=1.0270\n",
      "[Epoch 59 | Iter 00009] loss=1.0356\n",
      "[Epoch 59 | Iter 00010] loss=1.0303\n",
      "[Epoch 59 | Iter 00011] loss=1.0332\n",
      "[Epoch 59 | Iter 00012] loss=1.0193\n",
      "[Epoch 59 | Iter 00013] loss=1.0151\n",
      "[Epoch 59 | Iter 00014] loss=1.0146\n",
      "[Epoch 59 | Iter 00015] loss=1.0156\n",
      "[Epoch 59 | Iter 00016] loss=1.0193\n",
      "[Epoch 59 | Iter 00017] loss=1.0164\n",
      "[Epoch 59 | Iter 00018] loss=1.0168\n",
      "[Epoch 59 | Iter 00019] loss=1.0172\n",
      "[Epoch 59 | Iter 00020] loss=1.0171\n",
      "[Epoch 59 | Iter 00021] loss=1.0173\n",
      "[Epoch 59 | Iter 00022] loss=1.0183\n",
      "[Epoch 59 | Iter 00023] loss=1.0171\n",
      "[Epoch 59 | Iter 00024] loss=1.0159\n",
      "[Epoch 59 | Iter 00025] loss=1.0175\n",
      "[Epoch 59] Train: loss=0.9661 mIoU=0.2861 pixacc=0.7197 (798.0s+97.6s, 1.0 smp/s) | Val: loss=1.5320 mIoU=0.1578 pixacc=0.5742 (16.9s, 5.9 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1578) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(1.2s)\n",
      "‚è±Ô∏è  Timing: Save(1.2s) | Total(913.7s) | Breakdown: Train(87.3%) Val(1.8%) Save(0.1%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2861) >> Val mIoU (0.1578), gap: 0.1283\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5320) >> Train loss (0.9661), gap: 0.5659\n",
      "[Epoch 60 | Iter 00001] loss=1.0379\n",
      "[Epoch 60 | Iter 00002] loss=1.0211\n",
      "[Epoch 60 | Iter 00003] loss=1.0038\n",
      "[Epoch 60 | Iter 00004] loss=0.9816\n",
      "[Epoch 60 | Iter 00005] loss=0.9866\n",
      "[Epoch 60 | Iter 00006] loss=0.9954\n",
      "[Epoch 60 | Iter 00007] loss=1.0063\n",
      "[Epoch 60 | Iter 00008] loss=1.0098\n",
      "[Epoch 60 | Iter 00009] loss=1.0156\n",
      "[Epoch 60 | Iter 00010] loss=1.0091\n",
      "[Epoch 60 | Iter 00011] loss=1.0065\n",
      "[Epoch 60 | Iter 00012] loss=1.0039\n",
      "[Epoch 60 | Iter 00013] loss=0.9987\n",
      "[Epoch 60 | Iter 00014] loss=0.9973\n",
      "[Epoch 60 | Iter 00015] loss=0.9995\n",
      "[Epoch 60 | Iter 00016] loss=0.9989\n",
      "[Epoch 60 | Iter 00017] loss=1.0010\n",
      "[Epoch 60 | Iter 00018] loss=1.0010\n",
      "[Epoch 60 | Iter 00019] loss=1.0017\n",
      "[Epoch 60 | Iter 00020] loss=1.0054\n",
      "[Epoch 60 | Iter 00021] loss=1.0028\n",
      "[Epoch 60 | Iter 00022] loss=0.9995\n",
      "[Epoch 60 | Iter 00023] loss=0.9993\n",
      "[Epoch 60 | Iter 00024] loss=1.0008\n",
      "[Epoch 60 | Iter 00025] loss=1.0035\n",
      "[Epoch 60] Train: loss=0.9645 mIoU=0.2861 pixacc=0.7188 (54.9s+26.2s, 14.5 smp/s) | Val: loss=1.5268 mIoU=0.1569 pixacc=0.5737 (14.5s, 6.9 smp/s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_060.pt (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(0.9s)\n",
      "‚è±Ô∏è  Timing: Save(0.9s) | Total(96.5s) | Breakdown: Train(56.9%) Val(15.0%) Save(0.9%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2861) >> Val mIoU (0.1569), gap: 0.1292\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5268) >> Train loss (0.9645), gap: 0.5623\n",
      "[Epoch 61 | Iter 00001] loss=0.9043\n",
      "[Epoch 61 | Iter 00002] loss=0.9431\n",
      "[Epoch 61 | Iter 00003] loss=0.9717\n",
      "[Epoch 61 | Iter 00004] loss=0.9894\n",
      "[Epoch 61 | Iter 00005] loss=0.9924\n",
      "[Epoch 61 | Iter 00006] loss=0.9885\n",
      "[Epoch 61 | Iter 00007] loss=0.9810\n",
      "[Epoch 61 | Iter 00008] loss=0.9853\n",
      "[Epoch 61 | Iter 00009] loss=0.9933\n",
      "[Epoch 61 | Iter 00010] loss=1.0086\n",
      "[Epoch 61 | Iter 00011] loss=1.0136\n",
      "[Epoch 61 | Iter 00012] loss=1.0180\n",
      "[Epoch 61 | Iter 00013] loss=1.0124\n",
      "[Epoch 61 | Iter 00014] loss=1.0083\n",
      "[Epoch 61 | Iter 00015] loss=1.0106\n",
      "[Epoch 61 | Iter 00016] loss=1.0057\n",
      "[Epoch 61 | Iter 00017] loss=1.0042\n",
      "[Epoch 61 | Iter 00018] loss=1.0021\n",
      "[Epoch 61 | Iter 00019] loss=1.0023\n",
      "[Epoch 61 | Iter 00020] loss=0.9984\n",
      "[Epoch 61 | Iter 00021] loss=0.9970\n",
      "[Epoch 61 | Iter 00022] loss=0.9967\n",
      "[Epoch 61 | Iter 00023] loss=0.9991\n",
      "[Epoch 61 | Iter 00024] loss=0.9958\n",
      "[Epoch 61 | Iter 00025] loss=1.0004\n",
      "[Epoch 61] Train: loss=0.9523 mIoU=0.2861 pixacc=0.7208 (46.4s+24.8s, 17.1 smp/s) | Val: loss=1.5316 mIoU=0.1603 pixacc=0.5712 (14.7s, 6.8 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1603) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.7s) size(37.7MB) total(1.4s)\n",
      "‚è±Ô∏è  Timing: Save(1.4s) | Total(87.3s) | Breakdown: Train(53.1%) Val(16.8%) Save(1.6%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2861) >> Val mIoU (0.1603), gap: 0.1258\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5316) >> Train loss (0.9523), gap: 0.5792\n",
      "[Epoch 62 | Iter 00001] loss=0.9826\n",
      "[Epoch 62 | Iter 00002] loss=1.0074\n",
      "[Epoch 62 | Iter 00003] loss=1.0138\n",
      "[Epoch 62 | Iter 00004] loss=1.0405\n",
      "[Epoch 62 | Iter 00005] loss=1.0305\n",
      "[Epoch 62 | Iter 00006] loss=1.0276\n",
      "[Epoch 62 | Iter 00007] loss=1.0245\n",
      "[Epoch 62 | Iter 00008] loss=1.0096\n",
      "[Epoch 62 | Iter 00009] loss=1.0111\n",
      "[Epoch 62 | Iter 00010] loss=1.0104\n",
      "[Epoch 62 | Iter 00011] loss=0.9994\n",
      "[Epoch 62 | Iter 00012] loss=0.9941\n",
      "[Epoch 62 | Iter 00013] loss=0.9909\n",
      "[Epoch 62 | Iter 00014] loss=0.9988\n",
      "[Epoch 62 | Iter 00015] loss=0.9974\n",
      "[Epoch 62 | Iter 00016] loss=0.9982\n",
      "[Epoch 62 | Iter 00017] loss=0.9976\n",
      "[Epoch 62 | Iter 00018] loss=1.0019\n",
      "[Epoch 62 | Iter 00019] loss=0.9996\n",
      "[Epoch 62 | Iter 00020] loss=0.9914\n",
      "[Epoch 62 | Iter 00021] loss=0.9942\n",
      "[Epoch 62 | Iter 00022] loss=0.9918\n",
      "[Epoch 62 | Iter 00023] loss=0.9906\n",
      "[Epoch 62 | Iter 00024] loss=0.9882\n",
      "[Epoch 62 | Iter 00025] loss=0.9900\n",
      "[Epoch 62] Train: loss=0.9370 mIoU=0.2955 pixacc=0.7271 (66.1s+50.4s, 12.0 smp/s) | Val: loss=1.5329 mIoU=0.1593 pixacc=0.5755 (14.4s, 6.9 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(131.3s) | Breakdown: Train(50.3%) Val(11.0%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2955) >> Val mIoU (0.1593), gap: 0.1362\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5329) >> Train loss (0.9370), gap: 0.5959\n",
      "[Epoch 63 | Iter 00001] loss=1.0704\n",
      "[Epoch 63 | Iter 00002] loss=1.0367\n",
      "[Epoch 63 | Iter 00003] loss=0.9977\n",
      "[Epoch 63 | Iter 00004] loss=0.9834\n",
      "[Epoch 63 | Iter 00005] loss=0.9757\n",
      "[Epoch 63 | Iter 00006] loss=0.9719\n",
      "[Epoch 63 | Iter 00007] loss=0.9843\n",
      "[Epoch 63 | Iter 00008] loss=0.9799\n",
      "[Epoch 63 | Iter 00009] loss=0.9765\n",
      "[Epoch 63 | Iter 00010] loss=0.9835\n",
      "[Epoch 63 | Iter 00011] loss=0.9801\n",
      "[Epoch 63 | Iter 00012] loss=0.9840\n",
      "[Epoch 63 | Iter 00013] loss=0.9890\n",
      "[Epoch 63 | Iter 00014] loss=0.9849\n",
      "[Epoch 63 | Iter 00015] loss=0.9915\n",
      "[Epoch 63 | Iter 00016] loss=0.9893\n",
      "[Epoch 63 | Iter 00017] loss=0.9879\n",
      "[Epoch 63 | Iter 00018] loss=0.9895\n",
      "[Epoch 63 | Iter 00019] loss=0.9902\n",
      "[Epoch 63 | Iter 00020] loss=0.9896\n",
      "[Epoch 63 | Iter 00021] loss=0.9875\n",
      "[Epoch 63 | Iter 00022] loss=0.9883\n",
      "[Epoch 63 | Iter 00023] loss=0.9883\n",
      "[Epoch 63 | Iter 00024] loss=0.9903\n",
      "[Epoch 63 | Iter 00025] loss=0.9889\n",
      "[Epoch 63] Train: loss=0.9452 mIoU=0.2984 pixacc=0.7246 (98.8s+37.1s, 8.0 smp/s) | Val: loss=1.5636 mIoU=0.1623 pixacc=0.5780 (13.8s, 7.3 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1623) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.8s) size(37.7MB) total(1.6s)\n",
      "‚è±Ô∏è  Timing: Save(1.6s) | Total(151.2s) | Breakdown: Train(65.3%) Val(9.1%) Save(1.0%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.2984) >> Val mIoU (0.1623), gap: 0.1361\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5636) >> Train loss (0.9452), gap: 0.6184\n",
      "[Epoch 64 | Iter 00001] loss=0.9607\n",
      "[Epoch 64 | Iter 00002] loss=1.0109\n",
      "[Epoch 64 | Iter 00003] loss=0.9904\n",
      "[Epoch 64 | Iter 00004] loss=0.9866\n",
      "[Epoch 64 | Iter 00005] loss=1.0242\n",
      "[Epoch 64 | Iter 00006] loss=0.9957\n",
      "[Epoch 64 | Iter 00007] loss=1.0005\n",
      "[Epoch 64 | Iter 00008] loss=0.9862\n",
      "[Epoch 64 | Iter 00009] loss=0.9869\n",
      "[Epoch 64 | Iter 00010] loss=0.9789\n",
      "[Epoch 64 | Iter 00011] loss=0.9863\n",
      "[Epoch 64 | Iter 00012] loss=0.9933\n",
      "[Epoch 64 | Iter 00013] loss=0.9902\n",
      "[Epoch 64 | Iter 00014] loss=0.9857\n",
      "[Epoch 64 | Iter 00015] loss=0.9895\n",
      "[Epoch 64 | Iter 00016] loss=0.9860\n",
      "[Epoch 64 | Iter 00017] loss=0.9831\n",
      "[Epoch 64 | Iter 00018] loss=0.9791\n",
      "[Epoch 64 | Iter 00019] loss=0.9784\n",
      "[Epoch 64 | Iter 00020] loss=0.9764\n",
      "[Epoch 64 | Iter 00021] loss=0.9764\n",
      "[Epoch 64 | Iter 00022] loss=0.9722\n",
      "[Epoch 64 | Iter 00023] loss=0.9733\n",
      "[Epoch 64 | Iter 00024] loss=0.9747\n",
      "[Epoch 64 | Iter 00025] loss=0.9786\n",
      "[Epoch 64] Train: loss=0.9322 mIoU=0.3039 pixacc=0.7301 (66.2s+36.2s, 12.0 smp/s) | Val: loss=1.5471 mIoU=0.1634 pixacc=0.5748 (13.6s, 7.3 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1634) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(1.2s)\n",
      "‚è±Ô∏è  Timing: Save(1.2s) | Total(117.3s) | Breakdown: Train(56.4%) Val(11.6%) Save(1.0%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3039) >> Val mIoU (0.1634), gap: 0.1405\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5471) >> Train loss (0.9322), gap: 0.6149\n",
      "[Epoch 65 | Iter 00001] loss=0.9731\n",
      "[Epoch 65 | Iter 00002] loss=1.0136\n",
      "[Epoch 65 | Iter 00003] loss=0.9937\n",
      "[Epoch 65 | Iter 00004] loss=0.9925\n",
      "[Epoch 65 | Iter 00005] loss=0.9919\n",
      "[Epoch 65 | Iter 00006] loss=0.9897\n",
      "[Epoch 65 | Iter 00007] loss=0.9758\n",
      "[Epoch 65 | Iter 00008] loss=0.9614\n",
      "[Epoch 65 | Iter 00009] loss=0.9662\n",
      "[Epoch 65 | Iter 00010] loss=0.9717\n",
      "[Epoch 65 | Iter 00011] loss=0.9702\n",
      "[Epoch 65 | Iter 00012] loss=0.9734\n",
      "[Epoch 65 | Iter 00013] loss=0.9725\n",
      "[Epoch 65 | Iter 00014] loss=0.9774\n",
      "[Epoch 65 | Iter 00015] loss=0.9736\n",
      "[Epoch 65 | Iter 00016] loss=0.9738\n",
      "[Epoch 65 | Iter 00017] loss=0.9755\n",
      "[Epoch 65 | Iter 00018] loss=0.9715\n",
      "[Epoch 65 | Iter 00019] loss=0.9783\n",
      "[Epoch 65 | Iter 00020] loss=0.9797\n",
      "[Epoch 65 | Iter 00021] loss=0.9758\n",
      "[Epoch 65 | Iter 00022] loss=0.9720\n",
      "[Epoch 65 | Iter 00023] loss=0.9694\n",
      "[Epoch 65 | Iter 00024] loss=0.9698\n",
      "[Epoch 65 | Iter 00025] loss=0.9730\n",
      "[Epoch 65] Train: loss=0.9357 mIoU=0.3075 pixacc=0.7287 (87.3s+42.5s, 9.1 smp/s) | Val: loss=1.5369 mIoU=0.1657 pixacc=0.5757 (15.3s, 6.5 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1657) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.9s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_065.pt (0.5s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(1.9s)\n",
      "‚è±Ô∏è  Timing: Save(1.9s) | Total(146.9s) | Breakdown: Train(59.4%) Val(10.4%) Save(1.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3075) >> Val mIoU (0.1657), gap: 0.1418\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5369) >> Train loss (0.9357), gap: 0.6012\n",
      "[Epoch 66 | Iter 00001] loss=0.9750\n",
      "[Epoch 66 | Iter 00002] loss=0.9314\n",
      "[Epoch 66 | Iter 00003] loss=0.9530\n",
      "[Epoch 66 | Iter 00004] loss=0.9602\n",
      "[Epoch 66 | Iter 00005] loss=0.9669\n",
      "[Epoch 66 | Iter 00006] loss=0.9641\n",
      "[Epoch 66 | Iter 00007] loss=0.9683\n",
      "[Epoch 66 | Iter 00008] loss=0.9763\n",
      "[Epoch 66 | Iter 00009] loss=0.9746\n",
      "[Epoch 66 | Iter 00010] loss=0.9808\n",
      "[Epoch 66 | Iter 00011] loss=0.9758\n",
      "[Epoch 66 | Iter 00012] loss=0.9745\n",
      "[Epoch 66 | Iter 00013] loss=0.9660\n",
      "[Epoch 66 | Iter 00014] loss=0.9658\n",
      "[Epoch 66 | Iter 00015] loss=0.9628\n",
      "[Epoch 66 | Iter 00016] loss=0.9633\n",
      "[Epoch 66 | Iter 00017] loss=0.9575\n",
      "[Epoch 66 | Iter 00018] loss=0.9594\n",
      "[Epoch 66 | Iter 00019] loss=0.9576\n",
      "[Epoch 66 | Iter 00020] loss=0.9556\n",
      "[Epoch 66 | Iter 00021] loss=0.9528\n",
      "[Epoch 66 | Iter 00022] loss=0.9525\n",
      "[Epoch 66 | Iter 00023] loss=0.9527\n",
      "[Epoch 66 | Iter 00024] loss=0.9530\n",
      "[Epoch 66 | Iter 00025] loss=0.9532\n",
      "[Epoch 66] Train: loss=0.9133 mIoU=0.3146 pixacc=0.7361 (82.0s+37.5s, 9.7 smp/s) | Val: loss=1.5432 mIoU=0.1634 pixacc=0.5736 (13.5s, 7.4 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.5s) size(37.7MB) total(0.5s)\n",
      "‚è±Ô∏è  Timing: Save(0.5s) | Total(133.6s) | Breakdown: Train(61.4%) Val(10.1%) Save(0.4%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3146) >> Val mIoU (0.1634), gap: 0.1512\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5432) >> Train loss (0.9133), gap: 0.6299\n",
      "[Epoch 67 | Iter 00001] loss=0.9874\n",
      "[Epoch 67 | Iter 00002] loss=0.9521\n",
      "[Epoch 67 | Iter 00003] loss=0.9747\n",
      "[Epoch 67 | Iter 00004] loss=0.9700\n",
      "[Epoch 67 | Iter 00005] loss=0.9781\n",
      "[Epoch 67 | Iter 00006] loss=0.9789\n",
      "[Epoch 67 | Iter 00007] loss=0.9758\n",
      "[Epoch 67 | Iter 00008] loss=0.9739\n",
      "[Epoch 67 | Iter 00009] loss=0.9810\n",
      "[Epoch 67 | Iter 00010] loss=0.9698\n",
      "[Epoch 67 | Iter 00011] loss=0.9601\n",
      "[Epoch 67 | Iter 00012] loss=0.9519\n",
      "[Epoch 67 | Iter 00013] loss=0.9497\n",
      "[Epoch 67 | Iter 00014] loss=0.9592\n",
      "[Epoch 67 | Iter 00015] loss=0.9587\n",
      "[Epoch 67 | Iter 00016] loss=0.9616\n",
      "[Epoch 67 | Iter 00017] loss=0.9638\n",
      "[Epoch 67 | Iter 00018] loss=0.9630\n",
      "[Epoch 67 | Iter 00019] loss=0.9597\n",
      "[Epoch 67 | Iter 00020] loss=0.9578\n",
      "[Epoch 67 | Iter 00021] loss=0.9594\n",
      "[Epoch 67 | Iter 00022] loss=0.9571\n",
      "[Epoch 67 | Iter 00023] loss=0.9548\n",
      "[Epoch 67 | Iter 00024] loss=0.9551\n",
      "[Epoch 67 | Iter 00025] loss=0.9545\n",
      "[Epoch 67] Train: loss=0.9117 mIoU=0.3133 pixacc=0.7352 (75.3s+40.7s, 10.6 smp/s) | Val: loss=1.5464 mIoU=0.1679 pixacc=0.5817 (13.6s, 7.4 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1679) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(1.1s)\n",
      "‚è±Ô∏è  Timing: Save(1.1s) | Total(130.8s) | Breakdown: Train(57.6%) Val(10.4%) Save(0.9%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3133) >> Val mIoU (0.1679), gap: 0.1454\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5464) >> Train loss (0.9117), gap: 0.6347\n",
      "[Epoch 68 | Iter 00001] loss=0.9411\n",
      "[Epoch 68 | Iter 00002] loss=0.9472\n",
      "[Epoch 68 | Iter 00003] loss=0.9733\n",
      "[Epoch 68 | Iter 00004] loss=0.9720\n",
      "[Epoch 68 | Iter 00005] loss=0.9757\n",
      "[Epoch 68 | Iter 00006] loss=0.9588\n",
      "[Epoch 68 | Iter 00007] loss=0.9470\n",
      "[Epoch 68 | Iter 00008] loss=0.9525\n",
      "[Epoch 68 | Iter 00009] loss=0.9497\n",
      "[Epoch 68 | Iter 00010] loss=0.9538\n",
      "[Epoch 68 | Iter 00011] loss=0.9578\n",
      "[Epoch 68 | Iter 00012] loss=0.9521\n",
      "[Epoch 68 | Iter 00013] loss=0.9529\n",
      "[Epoch 68 | Iter 00014] loss=0.9499\n",
      "[Epoch 68 | Iter 00015] loss=0.9507\n",
      "[Epoch 68 | Iter 00016] loss=0.9493\n",
      "[Epoch 68 | Iter 00017] loss=0.9468\n",
      "[Epoch 68 | Iter 00018] loss=0.9477\n",
      "[Epoch 68 | Iter 00019] loss=0.9456\n",
      "[Epoch 68 | Iter 00020] loss=0.9430\n",
      "[Epoch 68 | Iter 00021] loss=0.9411\n",
      "[Epoch 68 | Iter 00022] loss=0.9477\n",
      "[Epoch 68 | Iter 00023] loss=0.9457\n",
      "[Epoch 68 | Iter 00024] loss=0.9476\n",
      "[Epoch 68 | Iter 00025] loss=0.9467\n",
      "[Epoch 68] Train: loss=0.9077 mIoU=0.3171 pixacc=0.7366 (78.9s+44.7s, 10.1 smp/s) | Val: loss=1.5486 mIoU=0.1688 pixacc=0.5765 (13.8s, 7.2 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1688) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(1.1s)\n",
      "‚è±Ô∏è  Timing: Save(1.1s) | Total(138.5s) | Breakdown: Train(57.0%) Val(10.0%) Save(0.8%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3171) >> Val mIoU (0.1688), gap: 0.1483\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5486) >> Train loss (0.9077), gap: 0.6409\n",
      "[Epoch 69 | Iter 00001] loss=1.0303\n",
      "[Epoch 69 | Iter 00002] loss=0.9632\n",
      "[Epoch 69 | Iter 00003] loss=0.9420\n",
      "[Epoch 69 | Iter 00004] loss=0.9577\n",
      "[Epoch 69 | Iter 00005] loss=0.9492\n",
      "[Epoch 69 | Iter 00006] loss=0.9356\n",
      "[Epoch 69 | Iter 00007] loss=0.9412\n",
      "[Epoch 69 | Iter 00008] loss=0.9306\n",
      "[Epoch 69 | Iter 00009] loss=0.9299\n",
      "[Epoch 69 | Iter 00010] loss=0.9345\n",
      "[Epoch 69 | Iter 00011] loss=0.9298\n",
      "[Epoch 69 | Iter 00012] loss=0.9319\n",
      "[Epoch 69 | Iter 00013] loss=0.9314\n",
      "[Epoch 69 | Iter 00014] loss=0.9299\n",
      "[Epoch 69 | Iter 00015] loss=0.9428\n",
      "[Epoch 69 | Iter 00016] loss=0.9426\n",
      "[Epoch 69 | Iter 00017] loss=0.9433\n",
      "[Epoch 69 | Iter 00018] loss=0.9387\n",
      "[Epoch 69 | Iter 00019] loss=0.9391\n",
      "[Epoch 69 | Iter 00020] loss=0.9405\n",
      "[Epoch 69 | Iter 00021] loss=0.9392\n",
      "[Epoch 69 | Iter 00022] loss=0.9374\n",
      "[Epoch 69 | Iter 00023] loss=0.9385\n",
      "[Epoch 69 | Iter 00024] loss=0.9388\n",
      "[Epoch 69 | Iter 00025] loss=0.9357\n",
      "[Epoch 69] Train: loss=0.9041 mIoU=0.3237 pixacc=0.7398 (74.2s+36.2s, 10.7 smp/s) | Val: loss=1.5823 mIoU=0.1672 pixacc=0.5779 (13.8s, 7.3 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.7MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(124.6s) | Breakdown: Train(59.6%) Val(11.0%) Save(0.4%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3237) >> Val mIoU (0.1672), gap: 0.1565\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5823) >> Train loss (0.9041), gap: 0.6781\n",
      "[Epoch 70 | Iter 00001] loss=0.8863\n",
      "[Epoch 70 | Iter 00002] loss=0.9039\n",
      "[Epoch 70 | Iter 00003] loss=0.9319\n",
      "[Epoch 70 | Iter 00004] loss=0.9389\n",
      "[Epoch 70 | Iter 00005] loss=0.9399\n",
      "[Epoch 70 | Iter 00006] loss=0.9246\n",
      "[Epoch 70 | Iter 00007] loss=0.9199\n",
      "[Epoch 70 | Iter 00008] loss=0.9255\n",
      "[Epoch 70 | Iter 00009] loss=0.9241\n",
      "[Epoch 70 | Iter 00010] loss=0.9317\n",
      "[Epoch 70 | Iter 00011] loss=0.9321\n",
      "[Epoch 70 | Iter 00012] loss=0.9366\n",
      "[Epoch 70 | Iter 00013] loss=0.9331\n",
      "[Epoch 70 | Iter 00014] loss=0.9397\n",
      "[Epoch 70 | Iter 00015] loss=0.9404\n",
      "[Epoch 70 | Iter 00016] loss=0.9478\n",
      "[Epoch 70 | Iter 00017] loss=0.9517\n",
      "[Epoch 70 | Iter 00018] loss=0.9516\n",
      "[Epoch 70 | Iter 00019] loss=0.9499\n",
      "[Epoch 70 | Iter 00020] loss=0.9516\n",
      "[Epoch 70 | Iter 00021] loss=0.9506\n",
      "[Epoch 70 | Iter 00022] loss=0.9490\n",
      "[Epoch 70 | Iter 00023] loss=0.9475\n",
      "[Epoch 70 | Iter 00024] loss=0.9440\n",
      "[Epoch 70 | Iter 00025] loss=0.9428\n",
      "[Epoch 70] Train: loss=0.8916 mIoU=0.3290 pixacc=0.7428 (76.3s+44.0s, 10.4 smp/s) | Val: loss=1.5486 mIoU=0.1674 pixacc=0.5783 (15.2s, 6.6 smp/s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_070.pt (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(0.8s)\n",
      "‚è±Ô∏è  Timing: Save(0.8s) | Total(136.2s) | Breakdown: Train(56.0%) Val(11.1%) Save(0.6%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3290) >> Val mIoU (0.1674), gap: 0.1616\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5486) >> Train loss (0.8916), gap: 0.6570\n",
      "[Epoch 71 | Iter 00001] loss=0.9699\n",
      "[Epoch 71 | Iter 00002] loss=0.9471\n",
      "[Epoch 71 | Iter 00003] loss=0.9538\n",
      "[Epoch 71 | Iter 00004] loss=0.9600\n",
      "[Epoch 71 | Iter 00005] loss=0.9494\n",
      "[Epoch 71 | Iter 00006] loss=0.9462\n",
      "[Epoch 71 | Iter 00007] loss=0.9375\n",
      "[Epoch 71 | Iter 00008] loss=0.9414\n",
      "[Epoch 71 | Iter 00009] loss=0.9359\n",
      "[Epoch 71 | Iter 00010] loss=0.9414\n",
      "[Epoch 71 | Iter 00011] loss=0.9308\n",
      "[Epoch 71 | Iter 00012] loss=0.9314\n",
      "[Epoch 71 | Iter 00013] loss=0.9276\n",
      "[Epoch 71 | Iter 00014] loss=0.9213\n",
      "[Epoch 71 | Iter 00015] loss=0.9286\n",
      "[Epoch 71 | Iter 00016] loss=0.9293\n",
      "[Epoch 71 | Iter 00017] loss=0.9268\n",
      "[Epoch 71 | Iter 00018] loss=0.9296\n",
      "[Epoch 71 | Iter 00019] loss=0.9272\n",
      "[Epoch 71 | Iter 00020] loss=0.9247\n",
      "[Epoch 71 | Iter 00021] loss=0.9279\n",
      "[Epoch 71 | Iter 00022] loss=0.9248\n",
      "[Epoch 71 | Iter 00023] loss=0.9247\n",
      "[Epoch 71 | Iter 00024] loss=0.9266\n",
      "[Epoch 71 | Iter 00025] loss=0.9269\n",
      "[Epoch 71] Train: loss=0.8811 mIoU=0.3386 pixacc=0.7480 (88.6s+41.8s, 9.0 smp/s) | Val: loss=1.5452 mIoU=0.1707 pixacc=0.5825 (13.6s, 7.4 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1707) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.7s) size(37.8MB) total(1.4s)\n",
      "‚è±Ô∏è  Timing: Save(1.4s) | Total(145.4s) | Breakdown: Train(60.9%) Val(9.3%) Save(1.0%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3386) >> Val mIoU (0.1707), gap: 0.1679\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5452) >> Train loss (0.8811), gap: 0.6641\n",
      "[Epoch 72 | Iter 00001] loss=0.9650\n",
      "[Epoch 72 | Iter 00002] loss=0.9677\n",
      "[Epoch 72 | Iter 00003] loss=0.9335\n",
      "[Epoch 72 | Iter 00004] loss=0.9320\n",
      "[Epoch 72 | Iter 00005] loss=0.9170\n",
      "[Epoch 72 | Iter 00006] loss=0.9029\n",
      "[Epoch 72 | Iter 00007] loss=0.9187\n",
      "[Epoch 72 | Iter 00008] loss=0.9152\n",
      "[Epoch 72 | Iter 00009] loss=0.9130\n",
      "[Epoch 72 | Iter 00010] loss=0.9128\n",
      "[Epoch 72 | Iter 00011] loss=0.9142\n",
      "[Epoch 72 | Iter 00012] loss=0.9149\n",
      "[Epoch 72 | Iter 00013] loss=0.9152\n",
      "[Epoch 72 | Iter 00014] loss=0.9130\n",
      "[Epoch 72 | Iter 00015] loss=0.9160\n",
      "[Epoch 72 | Iter 00016] loss=0.9168\n",
      "[Epoch 72 | Iter 00017] loss=0.9141\n",
      "[Epoch 72 | Iter 00018] loss=0.9147\n",
      "[Epoch 72 | Iter 00019] loss=0.9177\n",
      "[Epoch 72 | Iter 00020] loss=0.9216\n",
      "[Epoch 72 | Iter 00021] loss=0.9202\n",
      "[Epoch 72 | Iter 00022] loss=0.9208\n",
      "[Epoch 72 | Iter 00023] loss=0.9213\n",
      "[Epoch 72 | Iter 00024] loss=0.9234\n",
      "[Epoch 72 | Iter 00025] loss=0.9191\n",
      "[Epoch 72] Train: loss=0.8777 mIoU=0.3370 pixacc=0.7466 (78.7s+38.7s, 10.1 smp/s) | Val: loss=1.5291 mIoU=0.1706 pixacc=0.5805 (17.5s, 5.7 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(135.4s) | Breakdown: Train(58.2%) Val(12.9%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3370) >> Val mIoU (0.1706), gap: 0.1664\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5291) >> Train loss (0.8777), gap: 0.6514\n",
      "[Epoch 73 | Iter 00001] loss=0.8150\n",
      "[Epoch 73 | Iter 00002] loss=0.8462\n",
      "[Epoch 73 | Iter 00003] loss=0.8584\n",
      "[Epoch 73 | Iter 00004] loss=0.8749\n",
      "[Epoch 73 | Iter 00005] loss=0.8912\n",
      "[Epoch 73 | Iter 00006] loss=0.8876\n",
      "[Epoch 73 | Iter 00007] loss=0.8855\n",
      "[Epoch 73 | Iter 00008] loss=0.8903\n",
      "[Epoch 73 | Iter 00009] loss=0.8921\n",
      "[Epoch 73 | Iter 00010] loss=0.9010\n",
      "[Epoch 73 | Iter 00011] loss=0.9005\n",
      "[Epoch 73 | Iter 00012] loss=0.9110\n",
      "[Epoch 73 | Iter 00013] loss=0.9167\n",
      "[Epoch 73 | Iter 00014] loss=0.9162\n",
      "[Epoch 73 | Iter 00015] loss=0.9172\n",
      "[Epoch 73 | Iter 00016] loss=0.9168\n",
      "[Epoch 73 | Iter 00017] loss=0.9142\n",
      "[Epoch 73 | Iter 00018] loss=0.9092\n",
      "[Epoch 73 | Iter 00019] loss=0.9114\n",
      "[Epoch 73 | Iter 00020] loss=0.9174\n",
      "[Epoch 73 | Iter 00021] loss=0.9198\n",
      "[Epoch 73 | Iter 00022] loss=0.9222\n",
      "[Epoch 73 | Iter 00023] loss=0.9221\n",
      "[Epoch 73 | Iter 00024] loss=0.9214\n",
      "[Epoch 73 | Iter 00025] loss=0.9227\n",
      "[Epoch 73] Train: loss=0.8720 mIoU=0.3367 pixacc=0.7478 (77.6s+42.5s, 10.2 smp/s) | Val: loss=1.5645 mIoU=0.1706 pixacc=0.5811 (15.8s, 6.3 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(136.4s) | Breakdown: Train(56.9%) Val(11.6%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3367) >> Val mIoU (0.1706), gap: 0.1661\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5645) >> Train loss (0.8720), gap: 0.6925\n",
      "[Epoch 74 | Iter 00001] loss=0.9621\n",
      "[Epoch 74 | Iter 00002] loss=0.9532\n",
      "[Epoch 74 | Iter 00003] loss=0.9538\n",
      "[Epoch 74 | Iter 00004] loss=0.9582\n",
      "[Epoch 74 | Iter 00005] loss=0.9437\n",
      "[Epoch 74 | Iter 00006] loss=0.9432\n",
      "[Epoch 74 | Iter 00007] loss=0.9335\n",
      "[Epoch 74 | Iter 00008] loss=0.9363\n",
      "[Epoch 74 | Iter 00009] loss=0.9264\n",
      "[Epoch 74 | Iter 00010] loss=0.9224\n",
      "[Epoch 74 | Iter 00011] loss=0.9221\n",
      "[Epoch 74 | Iter 00012] loss=0.9147\n",
      "[Epoch 74 | Iter 00013] loss=0.9144\n",
      "[Epoch 74 | Iter 00014] loss=0.9184\n",
      "[Epoch 74 | Iter 00015] loss=0.9182\n",
      "[Epoch 74 | Iter 00016] loss=0.9197\n",
      "[Epoch 74 | Iter 00017] loss=0.9146\n",
      "[Epoch 74 | Iter 00018] loss=0.9102\n",
      "[Epoch 74 | Iter 00019] loss=0.9101\n",
      "[Epoch 74 | Iter 00020] loss=0.9086\n",
      "[Epoch 74 | Iter 00021] loss=0.9081\n",
      "[Epoch 74 | Iter 00022] loss=0.9085\n",
      "[Epoch 74 | Iter 00023] loss=0.9099\n",
      "[Epoch 74 | Iter 00024] loss=0.9098\n",
      "[Epoch 74 | Iter 00025] loss=0.9128\n",
      "[Epoch 74] Train: loss=0.8659 mIoU=0.3427 pixacc=0.7502 (89.7s+47.2s, 8.9 smp/s) | Val: loss=1.5438 mIoU=0.1701 pixacc=0.5785 (14.8s, 6.8 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(152.1s) | Breakdown: Train(59.0%) Val(9.7%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3427) >> Val mIoU (0.1701), gap: 0.1727\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5438) >> Train loss (0.8659), gap: 0.6779\n",
      "[Epoch 75 | Iter 00001] loss=0.9320\n",
      "[Epoch 75 | Iter 00002] loss=0.9003\n",
      "[Epoch 75 | Iter 00003] loss=0.8997\n",
      "[Epoch 75 | Iter 00004] loss=0.8991\n",
      "[Epoch 75 | Iter 00005] loss=0.8892\n",
      "[Epoch 75 | Iter 00006] loss=0.8962\n",
      "[Epoch 75 | Iter 00007] loss=0.8848\n",
      "[Epoch 75 | Iter 00008] loss=0.8723\n",
      "[Epoch 75 | Iter 00009] loss=0.8896\n",
      "[Epoch 75 | Iter 00010] loss=0.8897\n",
      "[Epoch 75 | Iter 00011] loss=0.8847\n",
      "[Epoch 75 | Iter 00012] loss=0.8892\n",
      "[Epoch 75 | Iter 00013] loss=0.9044\n",
      "[Epoch 75 | Iter 00014] loss=0.9043\n",
      "[Epoch 75 | Iter 00015] loss=0.9073\n",
      "[Epoch 75 | Iter 00016] loss=0.9084\n",
      "[Epoch 75 | Iter 00017] loss=0.9098\n",
      "[Epoch 75 | Iter 00018] loss=0.9075\n",
      "[Epoch 75 | Iter 00019] loss=0.9014\n",
      "[Epoch 75 | Iter 00020] loss=0.9002\n",
      "[Epoch 75 | Iter 00021] loss=0.8969\n",
      "[Epoch 75 | Iter 00022] loss=0.8958\n",
      "[Epoch 75 | Iter 00023] loss=0.8958\n",
      "[Epoch 75 | Iter 00024] loss=0.8993\n",
      "[Epoch 75 | Iter 00025] loss=0.9009\n",
      "[Epoch 75] Train: loss=0.8593 mIoU=0.3548 pixacc=0.7572 (75.8s+40.1s, 10.5 smp/s) | Val: loss=1.5598 mIoU=0.1732 pixacc=0.5817 (13.6s, 7.4 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1732) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_075.pt (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(1.5s)\n",
      "‚è±Ô∏è  Timing: Save(1.5s) | Total(131.0s) | Breakdown: Train(57.9%) Val(10.4%) Save(1.2%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3548) >> Val mIoU (0.1732), gap: 0.1817\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5598) >> Train loss (0.8593), gap: 0.7005\n",
      "[Epoch 76 | Iter 00001] loss=0.9107\n",
      "[Epoch 76 | Iter 00002] loss=0.8682\n",
      "[Epoch 76 | Iter 00003] loss=0.8818\n",
      "[Epoch 76 | Iter 00004] loss=0.8962\n",
      "[Epoch 76 | Iter 00005] loss=0.8839\n",
      "[Epoch 76 | Iter 00006] loss=0.8901\n",
      "[Epoch 76 | Iter 00007] loss=0.8917\n",
      "[Epoch 76 | Iter 00008] loss=0.9012\n",
      "[Epoch 76 | Iter 00009] loss=0.8948\n",
      "[Epoch 76 | Iter 00010] loss=0.8903\n",
      "[Epoch 76 | Iter 00011] loss=0.8915\n",
      "[Epoch 76 | Iter 00012] loss=0.8883\n",
      "[Epoch 76 | Iter 00013] loss=0.8923\n",
      "[Epoch 76 | Iter 00014] loss=0.8962\n",
      "[Epoch 76 | Iter 00015] loss=0.8959\n",
      "[Epoch 76 | Iter 00016] loss=0.8962\n",
      "[Epoch 76 | Iter 00017] loss=0.8950\n",
      "[Epoch 76 | Iter 00018] loss=0.8974\n",
      "[Epoch 76 | Iter 00019] loss=0.8958\n",
      "[Epoch 76 | Iter 00020] loss=0.8958\n",
      "[Epoch 76 | Iter 00021] loss=0.8916\n",
      "[Epoch 76 | Iter 00022] loss=0.8908\n",
      "[Epoch 76 | Iter 00023] loss=0.8875\n",
      "[Epoch 76 | Iter 00024] loss=0.8862\n",
      "[Epoch 76 | Iter 00025] loss=0.8897\n",
      "[Epoch 76] Train: loss=0.8486 mIoU=0.3498 pixacc=0.7545 (68.9s+38.7s, 11.5 smp/s) | Val: loss=1.5569 mIoU=0.1724 pixacc=0.5785 (13.8s, 7.2 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(121.8s) | Breakdown: Train(56.6%) Val(11.3%) Save(0.4%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3498) >> Val mIoU (0.1724), gap: 0.1775\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5569) >> Train loss (0.8486), gap: 0.7083\n",
      "[Epoch 77 | Iter 00001] loss=0.8798\n",
      "[Epoch 77 | Iter 00002] loss=0.8974\n",
      "[Epoch 77 | Iter 00003] loss=0.8994\n",
      "[Epoch 77 | Iter 00004] loss=0.9019\n",
      "[Epoch 77 | Iter 00005] loss=0.8920\n",
      "[Epoch 77 | Iter 00006] loss=0.8955\n",
      "[Epoch 77 | Iter 00007] loss=0.9001\n",
      "[Epoch 77 | Iter 00008] loss=0.9014\n",
      "[Epoch 77 | Iter 00009] loss=0.9005\n",
      "[Epoch 77 | Iter 00010] loss=0.8985\n",
      "[Epoch 77 | Iter 00011] loss=0.8944\n",
      "[Epoch 77 | Iter 00012] loss=0.8952\n",
      "[Epoch 77 | Iter 00013] loss=0.8945\n",
      "[Epoch 77 | Iter 00014] loss=0.8932\n",
      "[Epoch 77 | Iter 00015] loss=0.9015\n",
      "[Epoch 77 | Iter 00016] loss=0.9057\n",
      "[Epoch 77 | Iter 00017] loss=0.9015\n",
      "[Epoch 77 | Iter 00018] loss=0.8990\n",
      "[Epoch 77 | Iter 00019] loss=0.8941\n",
      "[Epoch 77 | Iter 00020] loss=0.8910\n",
      "[Epoch 77 | Iter 00021] loss=0.8894\n",
      "[Epoch 77 | Iter 00022] loss=0.8886\n",
      "[Epoch 77 | Iter 00023] loss=0.8896\n",
      "[Epoch 77 | Iter 00024] loss=0.8934\n",
      "[Epoch 77 | Iter 00025] loss=0.8927\n",
      "[Epoch 77] Train: loss=0.8461 mIoU=0.3593 pixacc=0.7585 (71.8s+36.8s, 11.1 smp/s) | Val: loss=1.5476 mIoU=0.1739 pixacc=0.5840 (13.6s, 7.4 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1739) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(1.1s)\n",
      "‚è±Ô∏è  Timing: Save(1.1s) | Total(123.3s) | Breakdown: Train(58.2%) Val(11.0%) Save(0.9%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3593) >> Val mIoU (0.1739), gap: 0.1853\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5476) >> Train loss (0.8461), gap: 0.7015\n",
      "[Epoch 78 | Iter 00001] loss=0.9149\n",
      "[Epoch 78 | Iter 00002] loss=0.9149\n",
      "[Epoch 78 | Iter 00003] loss=0.8873\n",
      "[Epoch 78 | Iter 00004] loss=0.8794\n",
      "[Epoch 78 | Iter 00005] loss=0.8730\n",
      "[Epoch 78 | Iter 00006] loss=0.8753\n",
      "[Epoch 78 | Iter 00007] loss=0.8740\n",
      "[Epoch 78 | Iter 00008] loss=0.8776\n",
      "[Epoch 78 | Iter 00009] loss=0.8796\n",
      "[Epoch 78 | Iter 00010] loss=0.8859\n",
      "[Epoch 78 | Iter 00011] loss=0.8793\n",
      "[Epoch 78 | Iter 00012] loss=0.8782\n",
      "[Epoch 78 | Iter 00013] loss=0.8755\n",
      "[Epoch 78 | Iter 00014] loss=0.8797\n",
      "[Epoch 78 | Iter 00015] loss=0.8847\n",
      "[Epoch 78 | Iter 00016] loss=0.8838\n",
      "[Epoch 78 | Iter 00017] loss=0.8834\n",
      "[Epoch 78 | Iter 00018] loss=0.8809\n",
      "[Epoch 78 | Iter 00019] loss=0.8819\n",
      "[Epoch 78 | Iter 00020] loss=0.8840\n",
      "[Epoch 78 | Iter 00021] loss=0.8870\n",
      "[Epoch 78 | Iter 00022] loss=0.8856\n",
      "[Epoch 78 | Iter 00023] loss=0.8829\n",
      "[Epoch 78 | Iter 00024] loss=0.8797\n",
      "[Epoch 78 | Iter 00025] loss=0.8820\n",
      "[Epoch 78] Train: loss=0.8395 mIoU=0.3585 pixacc=0.7598 (75.7s+40.8s, 10.5 smp/s) | Val: loss=1.5547 mIoU=0.1726 pixacc=0.5786 (14.8s, 6.7 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(131.7s) | Breakdown: Train(57.5%) Val(11.3%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3585) >> Val mIoU (0.1726), gap: 0.1859\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5547) >> Train loss (0.8395), gap: 0.7153\n",
      "[Epoch 79 | Iter 00001] loss=0.8702\n",
      "[Epoch 79 | Iter 00002] loss=0.8374\n",
      "[Epoch 79 | Iter 00003] loss=0.8269\n",
      "[Epoch 79 | Iter 00004] loss=0.8612\n",
      "[Epoch 79 | Iter 00005] loss=0.8945\n",
      "[Epoch 79 | Iter 00006] loss=0.8882\n",
      "[Epoch 79 | Iter 00007] loss=0.9023\n",
      "[Epoch 79 | Iter 00008] loss=0.8988\n",
      "[Epoch 79 | Iter 00009] loss=0.8942\n",
      "[Epoch 79 | Iter 00010] loss=0.8948\n",
      "[Epoch 79 | Iter 00011] loss=0.8914\n",
      "[Epoch 79 | Iter 00012] loss=0.8875\n",
      "[Epoch 79 | Iter 00013] loss=0.8875\n",
      "[Epoch 79 | Iter 00014] loss=0.8856\n",
      "[Epoch 79 | Iter 00015] loss=0.8891\n",
      "[Epoch 79 | Iter 00016] loss=0.8856\n",
      "[Epoch 79 | Iter 00017] loss=0.8872\n",
      "[Epoch 79 | Iter 00018] loss=0.8877\n",
      "[Epoch 79 | Iter 00019] loss=0.8843\n",
      "[Epoch 79 | Iter 00020] loss=0.8851\n",
      "[Epoch 79 | Iter 00021] loss=0.8858\n",
      "[Epoch 79 | Iter 00022] loss=0.8835\n",
      "[Epoch 79 | Iter 00023] loss=0.8770\n",
      "[Epoch 79 | Iter 00024] loss=0.8748\n",
      "[Epoch 79 | Iter 00025] loss=0.8762\n",
      "[Epoch 79] Train: loss=0.8294 mIoU=0.3700 pixacc=0.7629 (94.3s+41.7s, 8.4 smp/s) | Val: loss=1.5647 mIoU=0.1740 pixacc=0.5745 (13.9s, 7.2 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1740) to checkpoints/dual_encoder_unet_mobilenet/best.pth (1.1s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(1.5s)\n",
      "‚è±Ô∏è  Timing: Save(1.5s) | Total(151.4s) | Breakdown: Train(62.3%) Val(9.2%) Save(1.0%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3700) >> Val mIoU (0.1740), gap: 0.1960\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5647) >> Train loss (0.8294), gap: 0.7353\n",
      "[Epoch 80 | Iter 00001] loss=0.8753\n",
      "[Epoch 80 | Iter 00002] loss=0.8879\n",
      "[Epoch 80 | Iter 00003] loss=0.8984\n",
      "[Epoch 80 | Iter 00004] loss=0.9157\n",
      "[Epoch 80 | Iter 00005] loss=0.9004\n",
      "[Epoch 80 | Iter 00006] loss=0.9161\n",
      "[Epoch 80 | Iter 00007] loss=0.8977\n",
      "[Epoch 80 | Iter 00008] loss=0.8920\n",
      "[Epoch 80 | Iter 00009] loss=0.8916\n",
      "[Epoch 80 | Iter 00010] loss=0.8829\n",
      "[Epoch 80 | Iter 00011] loss=0.8825\n",
      "[Epoch 80 | Iter 00012] loss=0.8845\n",
      "[Epoch 80 | Iter 00013] loss=0.8858\n",
      "[Epoch 80 | Iter 00014] loss=0.8836\n",
      "[Epoch 80 | Iter 00015] loss=0.8846\n",
      "[Epoch 80 | Iter 00016] loss=0.8831\n",
      "[Epoch 80 | Iter 00017] loss=0.8824\n",
      "[Epoch 80 | Iter 00018] loss=0.8818\n",
      "[Epoch 80 | Iter 00019] loss=0.8804\n",
      "[Epoch 80 | Iter 00020] loss=0.8781\n",
      "[Epoch 80 | Iter 00021] loss=0.8788\n",
      "[Epoch 80 | Iter 00022] loss=0.8761\n",
      "[Epoch 80 | Iter 00023] loss=0.8817\n",
      "[Epoch 80 | Iter 00024] loss=0.8821\n",
      "[Epoch 80 | Iter 00025] loss=0.8855\n",
      "[Epoch 80] Train: loss=0.8199 mIoU=0.3703 pixacc=0.7638 (75.3s+35.6s, 10.6 smp/s) | Val: loss=1.5467 mIoU=0.1738 pixacc=0.5820 (14.9s, 6.7 smp/s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_080.pt (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(0.8s)\n",
      "‚è±Ô∏è  Timing: Save(0.8s) | Total(126.6s) | Breakdown: Train(59.5%) Val(11.8%) Save(0.6%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3703) >> Val mIoU (0.1738), gap: 0.1965\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5467) >> Train loss (0.8199), gap: 0.7268\n",
      "[Epoch 81 | Iter 00001] loss=0.8921\n",
      "[Epoch 81 | Iter 00002] loss=0.8652\n",
      "[Epoch 81 | Iter 00003] loss=0.8638\n",
      "[Epoch 81 | Iter 00004] loss=0.8719\n",
      "[Epoch 81 | Iter 00005] loss=0.8780\n",
      "[Epoch 81 | Iter 00006] loss=0.8620\n",
      "[Epoch 81 | Iter 00007] loss=0.8654\n",
      "[Epoch 81 | Iter 00008] loss=0.8613\n",
      "[Epoch 81 | Iter 00009] loss=0.8646\n",
      "[Epoch 81 | Iter 00010] loss=0.8780\n",
      "[Epoch 81 | Iter 00011] loss=0.8716\n",
      "[Epoch 81 | Iter 00012] loss=0.8720\n",
      "[Epoch 81 | Iter 00013] loss=0.8767\n",
      "[Epoch 81 | Iter 00014] loss=0.8832\n",
      "[Epoch 81 | Iter 00015] loss=0.8878\n",
      "[Epoch 81 | Iter 00016] loss=0.8853\n",
      "[Epoch 81 | Iter 00017] loss=0.8815\n",
      "[Epoch 81 | Iter 00018] loss=0.8808\n",
      "[Epoch 81 | Iter 00019] loss=0.8807\n",
      "[Epoch 81 | Iter 00020] loss=0.8831\n",
      "[Epoch 81 | Iter 00021] loss=0.8872\n",
      "[Epoch 81 | Iter 00022] loss=0.8852\n",
      "[Epoch 81 | Iter 00023] loss=0.8876\n",
      "[Epoch 81 | Iter 00024] loss=0.8841\n",
      "[Epoch 81 | Iter 00025] loss=0.8802\n",
      "[Epoch 81] Train: loss=0.8165 mIoU=0.3719 pixacc=0.7659 (70.2s+42.4s, 11.3 smp/s) | Val: loss=1.5453 mIoU=0.1768 pixacc=0.5852 (13.8s, 7.3 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1768) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(1.2s)\n",
      "‚è±Ô∏è  Timing: Save(1.2s) | Total(127.6s) | Breakdown: Train(55.0%) Val(10.8%) Save(0.9%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3719) >> Val mIoU (0.1768), gap: 0.1950\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5453) >> Train loss (0.8165), gap: 0.7288\n",
      "[Epoch 82 | Iter 00001] loss=0.8583\n",
      "[Epoch 82 | Iter 00002] loss=0.8194\n",
      "[Epoch 82 | Iter 00003] loss=0.8326\n",
      "[Epoch 82 | Iter 00004] loss=0.8162\n",
      "[Epoch 82 | Iter 00005] loss=0.8310\n",
      "[Epoch 82 | Iter 00006] loss=0.8388\n",
      "[Epoch 82 | Iter 00007] loss=0.8263\n",
      "[Epoch 82 | Iter 00008] loss=0.8281\n",
      "[Epoch 82 | Iter 00009] loss=0.8323\n",
      "[Epoch 82 | Iter 00010] loss=0.8276\n",
      "[Epoch 82 | Iter 00011] loss=0.8373\n",
      "[Epoch 82 | Iter 00012] loss=0.8450\n",
      "[Epoch 82 | Iter 00013] loss=0.8418\n",
      "[Epoch 82 | Iter 00014] loss=0.8483\n",
      "[Epoch 82 | Iter 00015] loss=0.8494\n",
      "[Epoch 82 | Iter 00016] loss=0.8537\n",
      "[Epoch 82 | Iter 00017] loss=0.8517\n",
      "[Epoch 82 | Iter 00018] loss=0.8533\n",
      "[Epoch 82 | Iter 00019] loss=0.8560\n",
      "[Epoch 82 | Iter 00020] loss=0.8621\n",
      "[Epoch 82 | Iter 00021] loss=0.8674\n",
      "[Epoch 82 | Iter 00022] loss=0.8659\n",
      "[Epoch 82 | Iter 00023] loss=0.8674\n",
      "[Epoch 82 | Iter 00024] loss=0.8667\n",
      "[Epoch 82 | Iter 00025] loss=0.8682\n",
      "[Epoch 82] Train: loss=0.8164 mIoU=0.3777 pixacc=0.7688 (74.8s+39.9s, 10.6 smp/s) | Val: loss=1.5621 mIoU=0.1763 pixacc=0.5800 (13.9s, 7.2 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(129.1s) | Breakdown: Train(58.0%) Val(10.8%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3777) >> Val mIoU (0.1763), gap: 0.2014\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5621) >> Train loss (0.8164), gap: 0.7458\n",
      "[Epoch 83 | Iter 00001] loss=0.8448\n",
      "[Epoch 83 | Iter 00002] loss=0.8591\n",
      "[Epoch 83 | Iter 00003] loss=0.8513\n",
      "[Epoch 83 | Iter 00004] loss=0.8710\n",
      "[Epoch 83 | Iter 00005] loss=0.8555\n",
      "[Epoch 83 | Iter 00006] loss=0.8555\n",
      "[Epoch 83 | Iter 00007] loss=0.8433\n",
      "[Epoch 83 | Iter 00008] loss=0.8511\n",
      "[Epoch 83 | Iter 00009] loss=0.8452\n",
      "[Epoch 83 | Iter 00010] loss=0.8510\n",
      "[Epoch 83 | Iter 00011] loss=0.8510\n",
      "[Epoch 83 | Iter 00012] loss=0.8437\n",
      "[Epoch 83 | Iter 00013] loss=0.8469\n",
      "[Epoch 83 | Iter 00014] loss=0.8431\n",
      "[Epoch 83 | Iter 00015] loss=0.8398\n",
      "[Epoch 83 | Iter 00016] loss=0.8370\n",
      "[Epoch 83 | Iter 00017] loss=0.8349\n",
      "[Epoch 83 | Iter 00018] loss=0.8351\n",
      "[Epoch 83 | Iter 00019] loss=0.8393\n",
      "[Epoch 83 | Iter 00020] loss=0.8414\n",
      "[Epoch 83 | Iter 00021] loss=0.8433\n",
      "[Epoch 83 | Iter 00022] loss=0.8442\n",
      "[Epoch 83 | Iter 00023] loss=0.8444\n",
      "[Epoch 83 | Iter 00024] loss=0.8447\n",
      "[Epoch 83 | Iter 00025] loss=0.8463\n",
      "[Epoch 83] Train: loss=0.8155 mIoU=0.3750 pixacc=0.7662 (73.7s+44.5s, 10.8 smp/s) | Val: loss=1.5564 mIoU=0.1764 pixacc=0.5789 (14.9s, 6.7 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(133.6s) | Breakdown: Train(55.2%) Val(11.2%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3750) >> Val mIoU (0.1764), gap: 0.1987\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5564) >> Train loss (0.8155), gap: 0.7409\n",
      "[Epoch 84 | Iter 00001] loss=0.8992\n",
      "[Epoch 84 | Iter 00002] loss=0.8899\n",
      "[Epoch 84 | Iter 00003] loss=0.9026\n",
      "[Epoch 84 | Iter 00004] loss=0.8905\n",
      "[Epoch 84 | Iter 00005] loss=0.8734\n",
      "[Epoch 84 | Iter 00006] loss=0.8603\n",
      "[Epoch 84 | Iter 00007] loss=0.8484\n",
      "[Epoch 84 | Iter 00008] loss=0.8438\n",
      "[Epoch 84 | Iter 00009] loss=0.8462\n",
      "[Epoch 84 | Iter 00010] loss=0.8367\n",
      "[Epoch 84 | Iter 00011] loss=0.8309\n",
      "[Epoch 84 | Iter 00012] loss=0.8423\n",
      "[Epoch 84 | Iter 00013] loss=0.8407\n",
      "[Epoch 84 | Iter 00014] loss=0.8497\n",
      "[Epoch 84 | Iter 00015] loss=0.8516\n",
      "[Epoch 84 | Iter 00016] loss=0.8523\n",
      "[Epoch 84 | Iter 00017] loss=0.8495\n",
      "[Epoch 84 | Iter 00018] loss=0.8461\n",
      "[Epoch 84 | Iter 00019] loss=0.8462\n",
      "[Epoch 84 | Iter 00020] loss=0.8475\n",
      "[Epoch 84 | Iter 00021] loss=0.8478\n",
      "[Epoch 84 | Iter 00022] loss=0.8530\n",
      "[Epoch 84 | Iter 00023] loss=0.8510\n",
      "[Epoch 84 | Iter 00024] loss=0.8496\n",
      "[Epoch 84 | Iter 00025] loss=0.8480\n",
      "[Epoch 84] Train: loss=0.7986 mIoU=0.3871 pixacc=0.7729 (93.8s+41.5s, 8.5 smp/s) | Val: loss=1.5460 mIoU=0.1792 pixacc=0.5862 (13.6s, 7.3 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1792) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.8s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(1.2s)\n",
      "‚è±Ô∏è  Timing: Save(1.2s) | Total(150.2s) | Breakdown: Train(62.5%) Val(9.1%) Save(0.8%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3871) >> Val mIoU (0.1792), gap: 0.2079\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5460) >> Train loss (0.7986), gap: 0.7474\n",
      "[Epoch 85 | Iter 00001] loss=0.7535\n",
      "[Epoch 85 | Iter 00002] loss=0.8020\n",
      "[Epoch 85 | Iter 00003] loss=0.8283\n",
      "[Epoch 85 | Iter 00004] loss=0.8325\n",
      "[Epoch 85 | Iter 00005] loss=0.8297\n",
      "[Epoch 85 | Iter 00006] loss=0.8240\n",
      "[Epoch 85 | Iter 00007] loss=0.8195\n",
      "[Epoch 85 | Iter 00008] loss=0.8319\n",
      "[Epoch 85 | Iter 00009] loss=0.8417\n",
      "[Epoch 85 | Iter 00010] loss=0.8422\n",
      "[Epoch 85 | Iter 00011] loss=0.8392\n",
      "[Epoch 85 | Iter 00012] loss=0.8376\n",
      "[Epoch 85 | Iter 00013] loss=0.8384\n",
      "[Epoch 85 | Iter 00014] loss=0.8367\n",
      "[Epoch 85 | Iter 00015] loss=0.8383\n",
      "[Epoch 85 | Iter 00016] loss=0.8344\n",
      "[Epoch 85 | Iter 00017] loss=0.8355\n",
      "[Epoch 85 | Iter 00018] loss=0.8434\n",
      "[Epoch 85 | Iter 00019] loss=0.8433\n",
      "[Epoch 85 | Iter 00020] loss=0.8426\n",
      "[Epoch 85 | Iter 00021] loss=0.8414\n",
      "[Epoch 85 | Iter 00022] loss=0.8361\n",
      "[Epoch 85 | Iter 00023] loss=0.8365\n",
      "[Epoch 85 | Iter 00024] loss=0.8370\n",
      "[Epoch 85 | Iter 00025] loss=0.8380\n",
      "[Epoch 85] Train: loss=0.8062 mIoU=0.3831 pixacc=0.7695 (77.5s+37.1s, 10.3 smp/s) | Val: loss=1.5676 mIoU=0.1832 pixacc=0.5868 (14.0s, 7.1 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1832) to checkpoints/dual_encoder_unet_mobilenet/best.pth (0.7s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_085.pt (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(1.5s)\n",
      "‚è±Ô∏è  Timing: Save(1.5s) | Total(130.1s) | Breakdown: Train(59.6%) Val(10.8%) Save(1.1%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3831) >> Val mIoU (0.1832), gap: 0.1999\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5676) >> Train loss (0.8062), gap: 0.7614\n",
      "[Epoch 86 | Iter 00001] loss=0.7703\n",
      "[Epoch 86 | Iter 00002] loss=0.8228\n",
      "[Epoch 86 | Iter 00003] loss=0.8587\n",
      "[Epoch 86 | Iter 00004] loss=0.8464\n",
      "[Epoch 86 | Iter 00005] loss=0.8483\n",
      "[Epoch 86 | Iter 00006] loss=0.8583\n",
      "[Epoch 86 | Iter 00007] loss=0.8605\n",
      "[Epoch 86 | Iter 00008] loss=0.8578\n",
      "[Epoch 86 | Iter 00009] loss=0.8518\n",
      "[Epoch 86 | Iter 00010] loss=0.8463\n",
      "[Epoch 86 | Iter 00011] loss=0.8466\n",
      "[Epoch 86 | Iter 00012] loss=0.8518\n",
      "[Epoch 86 | Iter 00013] loss=0.8499\n",
      "[Epoch 86 | Iter 00014] loss=0.8453\n",
      "[Epoch 86 | Iter 00015] loss=0.8443\n",
      "[Epoch 86 | Iter 00016] loss=0.8468\n",
      "[Epoch 86 | Iter 00017] loss=0.8447\n",
      "[Epoch 86 | Iter 00018] loss=0.8461\n",
      "[Epoch 86 | Iter 00019] loss=0.8436\n",
      "[Epoch 86 | Iter 00020] loss=0.8422\n",
      "[Epoch 86 | Iter 00021] loss=0.8409\n",
      "[Epoch 86 | Iter 00022] loss=0.8403\n",
      "[Epoch 86 | Iter 00023] loss=0.8413\n",
      "[Epoch 86 | Iter 00024] loss=0.8394\n",
      "[Epoch 86 | Iter 00025] loss=0.8413\n",
      "[Epoch 86] Train: loss=0.7934 mIoU=0.3870 pixacc=0.7718 (70.6s+41.4s, 11.3 smp/s) | Val: loss=1.5622 mIoU=0.1792 pixacc=0.5831 (13.8s, 7.2 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(126.3s) | Breakdown: Train(55.9%) Val(10.9%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3870) >> Val mIoU (0.1792), gap: 0.2078\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5622) >> Train loss (0.7934), gap: 0.7689\n",
      "[Epoch 87 | Iter 00001] loss=0.7972\n",
      "[Epoch 87 | Iter 00002] loss=0.8308\n",
      "[Epoch 87 | Iter 00003] loss=0.8355\n",
      "[Epoch 87 | Iter 00004] loss=0.8314\n",
      "[Epoch 87 | Iter 00005] loss=0.8369\n",
      "[Epoch 87 | Iter 00006] loss=0.8364\n",
      "[Epoch 87 | Iter 00007] loss=0.8246\n",
      "[Epoch 87 | Iter 00008] loss=0.8296\n",
      "[Epoch 87 | Iter 00009] loss=0.8276\n",
      "[Epoch 87 | Iter 00010] loss=0.8350\n",
      "[Epoch 87 | Iter 00011] loss=0.8312\n",
      "[Epoch 87 | Iter 00012] loss=0.8306\n",
      "[Epoch 87 | Iter 00013] loss=0.8262\n",
      "[Epoch 87 | Iter 00014] loss=0.8337\n",
      "[Epoch 87 | Iter 00015] loss=0.8370\n",
      "[Epoch 87 | Iter 00016] loss=0.8368\n",
      "[Epoch 87 | Iter 00017] loss=0.8326\n",
      "[Epoch 87 | Iter 00018] loss=0.8341\n",
      "[Epoch 87 | Iter 00019] loss=0.8316\n",
      "[Epoch 87 | Iter 00020] loss=0.8283\n",
      "[Epoch 87 | Iter 00021] loss=0.8297\n",
      "[Epoch 87 | Iter 00022] loss=0.8314\n",
      "[Epoch 87 | Iter 00023] loss=0.8312\n",
      "[Epoch 87 | Iter 00024] loss=0.8296\n",
      "[Epoch 87 | Iter 00025] loss=0.8292\n",
      "[Epoch 87] Train: loss=0.7885 mIoU=0.3946 pixacc=0.7757 (71.8s+40.0s, 11.1 smp/s) | Val: loss=1.5630 mIoU=0.1810 pixacc=0.5828 (14.3s, 7.0 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(126.5s) | Breakdown: Train(56.7%) Val(11.3%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3946) >> Val mIoU (0.1810), gap: 0.2136\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5630) >> Train loss (0.7885), gap: 0.7745\n",
      "[Epoch 88 | Iter 00001] loss=0.8021\n",
      "[Epoch 88 | Iter 00002] loss=0.7805\n",
      "[Epoch 88 | Iter 00003] loss=0.8166\n",
      "[Epoch 88 | Iter 00004] loss=0.8157\n",
      "[Epoch 88 | Iter 00005] loss=0.8098\n",
      "[Epoch 88 | Iter 00006] loss=0.8147\n",
      "[Epoch 88 | Iter 00007] loss=0.8204\n",
      "[Epoch 88 | Iter 00008] loss=0.8309\n",
      "[Epoch 88 | Iter 00009] loss=0.8271\n",
      "[Epoch 88 | Iter 00010] loss=0.8294\n",
      "[Epoch 88 | Iter 00011] loss=0.8346\n",
      "[Epoch 88 | Iter 00012] loss=0.8341\n",
      "[Epoch 88 | Iter 00013] loss=0.8327\n",
      "[Epoch 88 | Iter 00014] loss=0.8325\n",
      "[Epoch 88 | Iter 00015] loss=0.8316\n",
      "[Epoch 88 | Iter 00016] loss=0.8325\n",
      "[Epoch 88 | Iter 00017] loss=0.8389\n",
      "[Epoch 88 | Iter 00018] loss=0.8367\n",
      "[Epoch 88 | Iter 00019] loss=0.8336\n",
      "[Epoch 88 | Iter 00020] loss=0.8349\n",
      "[Epoch 88 | Iter 00021] loss=0.8375\n",
      "[Epoch 88 | Iter 00022] loss=0.8370\n",
      "[Epoch 88 | Iter 00023] loss=0.8393\n",
      "[Epoch 88 | Iter 00024] loss=0.8371\n",
      "[Epoch 88 | Iter 00025] loss=0.8386\n",
      "[Epoch 88] Train: loss=0.7783 mIoU=0.3974 pixacc=0.7772 (75.1s+43.4s, 10.6 smp/s) | Val: loss=1.5569 mIoU=0.1811 pixacc=0.5814 (18.3s, 5.5 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(0.5s)\n",
      "‚è±Ô∏è  Timing: Save(0.5s) | Total(137.2s) | Breakdown: Train(54.7%) Val(13.3%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3974) >> Val mIoU (0.1811), gap: 0.2163\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5569) >> Train loss (0.7783), gap: 0.7786\n",
      "[Epoch 89 | Iter 00001] loss=0.8811\n",
      "[Epoch 89 | Iter 00002] loss=0.7922\n",
      "[Epoch 89 | Iter 00003] loss=0.8055\n",
      "[Epoch 89 | Iter 00004] loss=0.8083\n",
      "[Epoch 89 | Iter 00005] loss=0.8134\n",
      "[Epoch 89 | Iter 00006] loss=0.8112\n",
      "[Epoch 89 | Iter 00007] loss=0.8134\n",
      "[Epoch 89 | Iter 00008] loss=0.8147\n",
      "[Epoch 89 | Iter 00009] loss=0.8091\n",
      "[Epoch 89 | Iter 00010] loss=0.8055\n",
      "[Epoch 89 | Iter 00011] loss=0.8086\n",
      "[Epoch 89 | Iter 00012] loss=0.8138\n",
      "[Epoch 89 | Iter 00013] loss=0.8101\n",
      "[Epoch 89 | Iter 00014] loss=0.8158\n",
      "[Epoch 89 | Iter 00015] loss=0.8183\n",
      "[Epoch 89 | Iter 00016] loss=0.8181\n",
      "[Epoch 89 | Iter 00017] loss=0.8183\n",
      "[Epoch 89 | Iter 00018] loss=0.8238\n",
      "[Epoch 89 | Iter 00019] loss=0.8229\n",
      "[Epoch 89 | Iter 00020] loss=0.8265\n",
      "[Epoch 89 | Iter 00021] loss=0.8254\n",
      "[Epoch 89 | Iter 00022] loss=0.8274\n",
      "[Epoch 89 | Iter 00023] loss=0.8257\n",
      "[Epoch 89 | Iter 00024] loss=0.8246\n",
      "[Epoch 89 | Iter 00025] loss=0.8258\n",
      "[Epoch 89] Train: loss=0.7768 mIoU=0.3971 pixacc=0.7781 (110.7s+85.1s, 7.2 smp/s) | Val: loss=1.5573 mIoU=0.1820 pixacc=0.5841 (15.1s, 6.6 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(211.3s) | Breakdown: Train(52.4%) Val(7.1%) Save(0.2%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3971) >> Val mIoU (0.1820), gap: 0.2150\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.5573) >> Train loss (0.7768), gap: 0.7805\n",
      "[Epoch 90 | Iter 00001] loss=0.7873\n",
      "[Epoch 90 | Iter 00002] loss=0.8075\n",
      "[Epoch 90 | Iter 00003] loss=0.8154\n",
      "[Epoch 90 | Iter 00004] loss=0.8282\n",
      "[Epoch 90 | Iter 00005] loss=0.8277\n",
      "[Epoch 90 | Iter 00006] loss=0.8253\n",
      "[Epoch 90 | Iter 00007] loss=0.8083\n",
      "[Epoch 90 | Iter 00008] loss=0.8170\n",
      "[Epoch 90 | Iter 00009] loss=0.8254\n",
      "[Epoch 90 | Iter 00010] loss=0.8288\n",
      "[Epoch 90 | Iter 00011] loss=0.8231\n",
      "[Epoch 90 | Iter 00012] loss=0.8127\n",
      "[Epoch 90 | Iter 00013] loss=0.8203\n",
      "[Epoch 90 | Iter 00014] loss=0.8209\n",
      "[Epoch 90 | Iter 00015] loss=0.8182\n",
      "[Epoch 90 | Iter 00016] loss=0.8185\n",
      "[Epoch 90 | Iter 00017] loss=0.8152\n",
      "[Epoch 90 | Iter 00018] loss=0.8149\n",
      "[Epoch 90 | Iter 00019] loss=0.8142\n",
      "[Epoch 90 | Iter 00020] loss=0.8141\n",
      "[Epoch 90 | Iter 00021] loss=0.8132\n",
      "[Epoch 90 | Iter 00022] loss=0.8146\n",
      "[Epoch 90 | Iter 00023] loss=0.8156\n",
      "[Epoch 90 | Iter 00024] loss=0.8144\n",
      "[Epoch 90 | Iter 00025] loss=0.8161\n",
      "[Epoch 90] Train: loss=0.7741 mIoU=0.4006 pixacc=0.7791 (1034.1s+25.7s, 0.8 smp/s) | Val: loss=1.5728 mIoU=0.1812 pixacc=0.5855 (14.9s, 6.7 smp/s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_090.pt (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(37.8MB) total(0.9s)\n",
      "‚è±Ô∏è  Timing: Save(0.9s) | Total(1075.5s) | Breakdown: Train(96.1%) Val(1.4%) Save(0.1%)\n",
      "EarlyStopping: Stopping early at epoch 90\n",
      "Best val_miou: 0.183190\n",
      "üõë Early stopping triggered at epoch 90\n",
      "Training complete!\n",
      "Best mIoU: 0.1832\n",
      "\n",
      "üîÑ Loading best model for final evaluation...\n",
      "Final validation metrics: loss=1.5676 mIoU=0.1832, PixelAcc=0.5868 (load: 0.4s, eval: 505.5s)\n"
     ]
    }
   ],
   "source": [
    "model.unfreeze_backbone()\n",
    "config.epochs = 100\n",
    "config.lr = 1e-4 # lower learning rate for fine-tuning\n",
    "trainer = SegmentationTrainer(config)\n",
    "trained_model = trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aec558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload SegmentationTrainer with new config\n",
    "model.unfreeze_backbone()\n",
    "config_stage_3 = config\n",
    "config_stage_3.epochs = 100 # go essentially until early stopping\n",
    "config_stage_3.lr = 1e-4 # lower learning rate for fine-tuning\n",
    "trainer = SegmentationTrainer(config_stage_3)\n",
    "trained_model = trainer.train(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
