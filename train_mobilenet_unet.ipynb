{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf04d1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Library/Frameworks/Python.framework/Versions/3.10/lib/python310.zip', '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10', '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload', '', '/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "from src.training import SegmentationTrainer, TrainingConfig\n",
    "from src.models.unet_mobilenet import build_unet_mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa5499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageNet pretrained MobileNetV3-Small weights...\n",
      "‚úì Successfully loaded ImageNet pretrained MobileNetV3-Small weights\n",
      "UNet-MobileNetV3-SMALL initialized:\n",
      "  Total parameters: 2,361,960\n",
      "  Trainable parameters: 2,361,960\n",
      "  Encoder channels: [16, 16, 24, 48, 96]\n",
      "Using device: mps\n",
      "EarlyStopping: monitoring 'val_miou' with patience=5 (mode=max)\n"
     ]
    }
   ],
   "source": [
    "config = TrainingConfig(\n",
    "      data_root=\"datasets/NYUDepthv2\",\n",
    "      use_rgb=True,\n",
    "      use_depth=False,\n",
    "      lr=1e-3,\n",
    "      epochs=20,\n",
    "      batch_size=32,\n",
    "      early_stopping_enabled=True,\n",
    "      early_stopping_patience=5,\n",
    "      device=\"auto\",\n",
    "      save_best_path=\"checkpoints/unet_mobilenet/best3.pth\",\n",
    "      save_latest_path=\"checkpoints/unet_mobilenet/latest2.pth\",\n",
    "      num_classes=40,\n",
    ")\n",
    "\n",
    "# Create model and train\n",
    "model = build_unet_mobilenet(num_classes=config.num_classes)\n",
    "\n",
    "trainer = SegmentationTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7b1f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3-small encoder frozen: parameters will not be updated during training\n",
      "Training configuration:\n",
      "  Use RGB: True\n",
      "  Use Depth: False\n",
      "  Input channels: 3\n",
      "  Label mode: nyu40\n",
      "  Num classes: 40\n",
      "Training samples: 795\n",
      "Validation samples: 100\n",
      "Total parameters: 2,361,960\n",
      "Trainable parameters: 1,434,952\n",
      "Starting training for 20 epochs (from epoch 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 | Iter 00001] loss=3.7191\n",
      "[Epoch 1 | Iter 00002] loss=3.7004\n",
      "[Epoch 1 | Iter 00003] loss=3.6970\n",
      "[Epoch 1 | Iter 00004] loss=3.6887\n",
      "[Epoch 1 | Iter 00005] loss=3.6804\n",
      "[Epoch 1 | Iter 00006] loss=3.6748\n",
      "[Epoch 1 | Iter 00007] loss=3.6645\n",
      "[Epoch 1 | Iter 00008] loss=3.6565\n",
      "[Epoch 1 | Iter 00009] loss=3.6479\n",
      "[Epoch 1 | Iter 00010] loss=3.6387\n",
      "[Epoch 1 | Iter 00011] loss=3.6281\n",
      "[Epoch 1 | Iter 00012] loss=3.6180\n",
      "[Epoch 1 | Iter 00013] loss=3.6075\n",
      "[Epoch 1 | Iter 00014] loss=3.5979\n",
      "[Epoch 1 | Iter 00015] loss=3.5875\n",
      "[Epoch 1 | Iter 00016] loss=3.5771\n",
      "[Epoch 1 | Iter 00017] loss=3.5666\n",
      "[Epoch 1 | Iter 00018] loss=3.5548\n",
      "[Epoch 1 | Iter 00019] loss=3.5445\n",
      "[Epoch 1 | Iter 00020] loss=3.5347\n",
      "[Epoch 1 | Iter 00021] loss=3.5250\n",
      "[Epoch 1 | Iter 00022] loss=3.5126\n",
      "[Epoch 1 | Iter 00023] loss=3.5003\n",
      "[Epoch 1 | Iter 00024] loss=3.4887\n",
      "[Epoch 1 | Iter 00025] loss=3.4775\n",
      "[Epoch 1] Train: loss=3.4775 (28.7s, 27.7 samples/s) | Val: mIoU=0.0252 PixelAcc=0.3587 (19.6s, 5.1 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0252) to checkpoints/unet_mobilenet/best2.pth (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(20.1MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(48.7s) | Breakdown: Train(59.0%) Val(40.1%) Save(0.9%)\n",
      "[Epoch 2 | Iter 00001] loss=3.2038\n",
      "[Epoch 2 | Iter 00002] loss=3.1821\n",
      "[Epoch 2 | Iter 00003] loss=3.1744\n",
      "[Epoch 2 | Iter 00004] loss=3.1537\n",
      "[Epoch 2 | Iter 00005] loss=3.1473\n",
      "[Epoch 2 | Iter 00006] loss=3.1283\n",
      "[Epoch 2 | Iter 00007] loss=3.1079\n",
      "[Epoch 2 | Iter 00008] loss=3.0938\n",
      "[Epoch 2 | Iter 00009] loss=3.0836\n",
      "[Epoch 2 | Iter 00010] loss=3.0680\n",
      "[Epoch 2 | Iter 00011] loss=3.0509\n",
      "[Epoch 2 | Iter 00012] loss=3.0401\n",
      "[Epoch 2 | Iter 00013] loss=3.0287\n",
      "[Epoch 2 | Iter 00014] loss=3.0220\n",
      "[Epoch 2 | Iter 00015] loss=3.0099\n",
      "[Epoch 2 | Iter 00016] loss=2.9971\n",
      "[Epoch 2 | Iter 00017] loss=2.9842\n",
      "[Epoch 2 | Iter 00018] loss=2.9726\n",
      "[Epoch 2 | Iter 00019] loss=2.9671\n",
      "[Epoch 2 | Iter 00020] loss=2.9596\n",
      "[Epoch 2 | Iter 00021] loss=2.9487\n",
      "[Epoch 2 | Iter 00022] loss=2.9361\n",
      "[Epoch 2 | Iter 00023] loss=2.9212\n",
      "[Epoch 2 | Iter 00024] loss=2.9121\n",
      "[Epoch 2 | Iter 00025] loss=2.9052\n",
      "[Epoch 2] Train: loss=2.9052 (30.2s, 26.3 samples/s) | Val: mIoU=0.0283 PixelAcc=0.4248 (17.7s, 5.6 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0283) to checkpoints/unet_mobilenet/best2.pth (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.1s) size(20.1MB) total(0.3s)\n",
      "‚è±Ô∏è  Timing: Save(0.3s) | Total(48.3s) | Breakdown: Train(62.6%) Val(36.7%) Save(0.7%)\n",
      "[Epoch 3 | Iter 00001] loss=2.6751\n",
      "[Epoch 3 | Iter 00002] loss=2.6732\n",
      "[Epoch 3 | Iter 00003] loss=2.6331\n",
      "[Epoch 3 | Iter 00004] loss=2.6090\n",
      "[Epoch 3 | Iter 00005] loss=2.5868\n",
      "[Epoch 3 | Iter 00006] loss=2.5912\n",
      "[Epoch 3 | Iter 00007] loss=2.5821\n",
      "[Epoch 3 | Iter 00008] loss=2.5794\n",
      "[Epoch 3 | Iter 00009] loss=2.5746\n",
      "[Epoch 3 | Iter 00010] loss=2.5770\n",
      "[Epoch 3 | Iter 00011] loss=2.5624\n",
      "[Epoch 3 | Iter 00012] loss=2.5420\n",
      "[Epoch 3 | Iter 00013] loss=2.5390\n",
      "[Epoch 3 | Iter 00014] loss=2.5320\n",
      "[Epoch 3 | Iter 00015] loss=2.5227\n",
      "[Epoch 3 | Iter 00016] loss=2.5213\n",
      "[Epoch 3 | Iter 00017] loss=2.5208\n",
      "[Epoch 3 | Iter 00018] loss=2.5230\n",
      "[Epoch 3 | Iter 00019] loss=2.5183\n",
      "[Epoch 3 | Iter 00020] loss=2.5148\n",
      "[Epoch 3 | Iter 00021] loss=2.5078\n",
      "[Epoch 3 | Iter 00022] loss=2.5083\n",
      "[Epoch 3 | Iter 00023] loss=2.5012\n",
      "[Epoch 3 | Iter 00024] loss=2.5001\n",
      "[Epoch 3 | Iter 00025] loss=2.4973\n",
      "[Epoch 3] Train: loss=2.4973 (29.0s, 27.4 samples/s) | Val: mIoU=0.0268 PixelAcc=0.4303 (19.1s, 5.2 samples/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.1s) size(20.1MB) total(0.1s)\n",
      "‚è±Ô∏è  Timing: Save(0.1s) | Total(48.3s) | Breakdown: Train(60.1%) Val(39.6%) Save(0.3%)\n",
      "[Epoch 4 | Iter 00001] loss=2.3449\n",
      "[Epoch 4 | Iter 00002] loss=2.3459\n",
      "[Epoch 4 | Iter 00003] loss=2.3845\n",
      "[Epoch 4 | Iter 00004] loss=2.4017\n",
      "[Epoch 4 | Iter 00005] loss=2.3814\n",
      "[Epoch 4 | Iter 00006] loss=2.3460\n",
      "[Epoch 4 | Iter 00007] loss=2.3426\n",
      "[Epoch 4 | Iter 00008] loss=2.3394\n",
      "[Epoch 4 | Iter 00009] loss=2.3369\n",
      "[Epoch 4 | Iter 00010] loss=2.3232\n",
      "[Epoch 4 | Iter 00011] loss=2.3224\n",
      "[Epoch 4 | Iter 00012] loss=2.3207\n",
      "[Epoch 4 | Iter 00013] loss=2.3167\n",
      "[Epoch 4 | Iter 00014] loss=2.3145\n",
      "[Epoch 4 | Iter 00015] loss=2.3149\n",
      "[Epoch 4 | Iter 00016] loss=2.3253\n",
      "[Epoch 4 | Iter 00017] loss=2.3200\n",
      "[Epoch 4 | Iter 00018] loss=2.3113\n",
      "[Epoch 4 | Iter 00019] loss=2.3123\n",
      "[Epoch 4 | Iter 00020] loss=2.3057\n",
      "[Epoch 4 | Iter 00021] loss=2.3004\n",
      "[Epoch 4 | Iter 00022] loss=2.2967\n",
      "[Epoch 4 | Iter 00023] loss=2.2937\n",
      "[Epoch 4 | Iter 00024] loss=2.2923\n",
      "[Epoch 4 | Iter 00025] loss=2.2891\n",
      "[Epoch 4] Train: loss=2.2891 (31.0s, 25.6 samples/s) | Val: mIoU=0.0271 PixelAcc=0.4343 (19.4s, 5.2 samples/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.1s) size(20.1MB) total(0.1s)\n",
      "‚è±Ô∏è  Timing: Save(0.1s) | Total(50.5s) | Breakdown: Train(61.4%) Val(38.3%) Save(0.3%)\n",
      "[Epoch 5 | Iter 00001] loss=2.3072\n",
      "[Epoch 5 | Iter 00002] loss=2.2429\n",
      "[Epoch 5 | Iter 00003] loss=2.2063\n",
      "[Epoch 5 | Iter 00004] loss=2.2119\n",
      "[Epoch 5 | Iter 00005] loss=2.2086\n",
      "[Epoch 5 | Iter 00006] loss=2.2129\n",
      "[Epoch 5 | Iter 00007] loss=2.1929\n",
      "[Epoch 5 | Iter 00008] loss=2.1913\n",
      "[Epoch 5 | Iter 00009] loss=2.2004\n",
      "[Epoch 5 | Iter 00010] loss=2.1922\n",
      "[Epoch 5 | Iter 00011] loss=2.1790\n",
      "[Epoch 5 | Iter 00012] loss=2.1793\n",
      "[Epoch 5 | Iter 00013] loss=2.1803\n",
      "[Epoch 5 | Iter 00014] loss=2.1765\n",
      "[Epoch 5 | Iter 00015] loss=2.1777\n",
      "[Epoch 5 | Iter 00016] loss=2.1775\n",
      "[Epoch 5 | Iter 00017] loss=2.1741\n",
      "[Epoch 5 | Iter 00018] loss=2.1850\n",
      "[Epoch 5 | Iter 00019] loss=2.1797\n",
      "[Epoch 5 | Iter 00020] loss=2.1788\n",
      "[Epoch 5 | Iter 00021] loss=2.1797\n",
      "[Epoch 5 | Iter 00022] loss=2.1804\n",
      "[Epoch 5 | Iter 00023] loss=2.1757\n",
      "[Epoch 5 | Iter 00024] loss=2.1763\n",
      "[Epoch 5 | Iter 00025] loss=2.1769\n",
      "[Epoch 5] Train: loss=2.1769 (30.2s, 26.4 samples/s) | Val: mIoU=0.0367 PixelAcc=0.4467 (17.9s, 5.6 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0367) to checkpoints/unet_mobilenet/best2.pth (0.2s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_005.pt (0.1s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.1s) size(20.1MB) total(0.5s)\n",
      "‚è±Ô∏è  Timing: Save(0.5s) | Total(48.5s) | Breakdown: Train(62.2%) Val(36.8%) Save(1.0%)\n",
      "[Epoch 6 | Iter 00001] loss=2.1547\n",
      "[Epoch 6 | Iter 00002] loss=2.1374\n",
      "[Epoch 6 | Iter 00003] loss=2.1505\n",
      "[Epoch 6 | Iter 00004] loss=2.1592\n",
      "[Epoch 6 | Iter 00005] loss=2.1498\n",
      "[Epoch 6 | Iter 00006] loss=2.1531\n",
      "[Epoch 6 | Iter 00007] loss=2.1545\n",
      "[Epoch 6 | Iter 00008] loss=2.1371\n",
      "[Epoch 6 | Iter 00009] loss=2.1274\n",
      "[Epoch 6 | Iter 00010] loss=2.1272\n",
      "[Epoch 6 | Iter 00011] loss=2.1300\n",
      "[Epoch 6 | Iter 00012] loss=2.1317\n",
      "[Epoch 6 | Iter 00013] loss=2.1209\n",
      "[Epoch 6 | Iter 00014] loss=2.1055\n",
      "[Epoch 6 | Iter 00015] loss=2.0995\n",
      "[Epoch 6 | Iter 00016] loss=2.1097\n",
      "[Epoch 6 | Iter 00017] loss=2.1044\n",
      "[Epoch 6 | Iter 00018] loss=2.1091\n",
      "[Epoch 6 | Iter 00019] loss=2.1067\n",
      "[Epoch 6 | Iter 00020] loss=2.1037\n",
      "[Epoch 6 | Iter 00021] loss=2.0999\n",
      "[Epoch 6 | Iter 00022] loss=2.0962\n",
      "[Epoch 6 | Iter 00023] loss=2.0973\n",
      "[Epoch 6 | Iter 00024] loss=2.0942\n",
      "[Epoch 6 | Iter 00025] loss=2.0962\n",
      "[Epoch 6] Train: loss=2.0962 (29.6s, 26.8 samples/s) | Val: mIoU=0.0374 PixelAcc=0.4477 (17.7s, 5.6 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0374) to checkpoints/unet_mobilenet/best2.pth (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(20.1MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(47.7s) | Breakdown: Train(62.1%) Val(37.1%) Save(0.8%)\n",
      "[Epoch 7 | Iter 00001] loss=2.0962\n",
      "[Epoch 7 | Iter 00002] loss=2.1013\n",
      "[Epoch 7 | Iter 00003] loss=2.0905\n",
      "[Epoch 7 | Iter 00004] loss=2.1038\n",
      "[Epoch 7 | Iter 00005] loss=2.1075\n",
      "[Epoch 7 | Iter 00006] loss=2.0825\n",
      "[Epoch 7 | Iter 00007] loss=2.0919\n",
      "[Epoch 7 | Iter 00008] loss=2.0767\n",
      "[Epoch 7 | Iter 00009] loss=2.0673\n",
      "[Epoch 7 | Iter 00010] loss=2.0434\n",
      "[Epoch 7 | Iter 00011] loss=2.0341\n",
      "[Epoch 7 | Iter 00012] loss=2.0311\n",
      "[Epoch 7 | Iter 00013] loss=2.0385\n",
      "[Epoch 7 | Iter 00014] loss=2.0311\n",
      "[Epoch 7 | Iter 00015] loss=2.0330\n",
      "[Epoch 7 | Iter 00016] loss=2.0328\n",
      "[Epoch 7 | Iter 00017] loss=2.0371\n",
      "[Epoch 7 | Iter 00018] loss=2.0358\n",
      "[Epoch 7 | Iter 00019] loss=2.0415\n",
      "[Epoch 7 | Iter 00020] loss=2.0390\n",
      "[Epoch 7 | Iter 00021] loss=2.0433\n",
      "[Epoch 7 | Iter 00022] loss=2.0344\n",
      "[Epoch 7 | Iter 00023] loss=2.0373\n",
      "[Epoch 7 | Iter 00024] loss=2.0328\n",
      "[Epoch 7 | Iter 00025] loss=2.0273\n",
      "[Epoch 7] Train: loss=2.0273 (29.2s, 27.3 samples/s) | Val: mIoU=0.0366 PixelAcc=0.4445 (19.3s, 5.2 samples/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(20.1MB) total(0.2s)\n",
      "‚è±Ô∏è  Timing: Save(0.2s) | Total(48.6s) | Breakdown: Train(60.0%) Val(39.6%) Save(0.3%)\n",
      "[Epoch 8 | Iter 00001] loss=2.0649\n",
      "[Epoch 8 | Iter 00002] loss=2.0485\n",
      "[Epoch 8 | Iter 00003] loss=2.0162\n",
      "[Epoch 8 | Iter 00004] loss=1.9829\n",
      "[Epoch 8 | Iter 00005] loss=1.9894\n",
      "[Epoch 8 | Iter 00006] loss=1.9857\n",
      "[Epoch 8 | Iter 00007] loss=1.9703\n",
      "[Epoch 8 | Iter 00008] loss=1.9748\n",
      "[Epoch 8 | Iter 00009] loss=1.9748\n",
      "[Epoch 8 | Iter 00010] loss=1.9695\n",
      "[Epoch 8 | Iter 00011] loss=1.9699\n",
      "[Epoch 8 | Iter 00012] loss=1.9727\n",
      "[Epoch 8 | Iter 00013] loss=1.9649\n",
      "[Epoch 8 | Iter 00014] loss=1.9707\n",
      "[Epoch 8 | Iter 00015] loss=1.9767\n",
      "[Epoch 8 | Iter 00016] loss=1.9789\n",
      "[Epoch 8 | Iter 00017] loss=1.9822\n",
      "[Epoch 8 | Iter 00018] loss=1.9798\n",
      "[Epoch 8 | Iter 00019] loss=1.9773\n",
      "[Epoch 8 | Iter 00020] loss=1.9750\n",
      "[Epoch 8 | Iter 00021] loss=1.9695\n",
      "[Epoch 8 | Iter 00022] loss=1.9704\n",
      "[Epoch 8 | Iter 00023] loss=1.9729\n",
      "[Epoch 8 | Iter 00024] loss=1.9744\n",
      "[Epoch 8 | Iter 00025] loss=1.9713\n",
      "[Epoch 8] Train: loss=1.9713 (29.1s, 27.3 samples/s) | Val: mIoU=0.0423 PixelAcc=0.4597 (18.0s, 5.5 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0423) to checkpoints/unet_mobilenet/best2.pth (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.1s) size(20.1MB) total(0.3s)\n",
      "‚è±Ô∏è  Timing: Save(0.3s) | Total(47.5s) | Breakdown: Train(61.3%) Val(38.0%) Save(0.7%)\n",
      "[Epoch 9 | Iter 00001] loss=1.7829\n",
      "[Epoch 9 | Iter 00002] loss=1.7796\n",
      "[Epoch 9 | Iter 00003] loss=1.8637\n",
      "[Epoch 9 | Iter 00004] loss=1.8894\n",
      "[Epoch 9 | Iter 00005] loss=1.8922\n",
      "[Epoch 9 | Iter 00006] loss=1.9346\n",
      "[Epoch 9 | Iter 00007] loss=1.9383\n",
      "[Epoch 9 | Iter 00008] loss=1.9339\n",
      "[Epoch 9 | Iter 00009] loss=1.9393\n",
      "[Epoch 9 | Iter 00010] loss=1.9346\n",
      "[Epoch 9 | Iter 00011] loss=1.9358\n",
      "[Epoch 9 | Iter 00012] loss=1.9279\n",
      "[Epoch 9 | Iter 00013] loss=1.9276\n",
      "[Epoch 9 | Iter 00014] loss=1.9354\n",
      "[Epoch 9 | Iter 00015] loss=1.9268\n",
      "[Epoch 9 | Iter 00016] loss=1.9169\n",
      "[Epoch 9 | Iter 00017] loss=1.9154\n",
      "[Epoch 9 | Iter 00018] loss=1.9111\n",
      "[Epoch 9 | Iter 00019] loss=1.9067\n",
      "[Epoch 9 | Iter 00020] loss=1.9061\n",
      "[Epoch 9 | Iter 00021] loss=1.9047\n",
      "[Epoch 9 | Iter 00022] loss=1.9083\n",
      "[Epoch 9 | Iter 00023] loss=1.9105\n",
      "[Epoch 9 | Iter 00024] loss=1.9080\n",
      "[Epoch 9 | Iter 00025] loss=1.9080\n",
      "[Epoch 9] Train: loss=1.9080 (29.7s, 26.8 samples/s) | Val: mIoU=0.0499 PixelAcc=0.4613 (17.7s, 5.6 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0499) to checkpoints/unet_mobilenet/best2.pth (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.1s) size(20.1MB) total(0.3s)\n",
      "‚è±Ô∏è  Timing: Save(0.3s) | Total(47.7s) | Breakdown: Train(62.2%) Val(37.1%) Save(0.7%)\n",
      "[Epoch 10 | Iter 00001] loss=1.8072\n",
      "[Epoch 10 | Iter 00002] loss=1.8202\n",
      "[Epoch 10 | Iter 00003] loss=1.8129\n",
      "[Epoch 10 | Iter 00004] loss=1.7879\n",
      "[Epoch 10 | Iter 00005] loss=1.8155\n",
      "[Epoch 10 | Iter 00006] loss=1.8186\n",
      "[Epoch 10 | Iter 00007] loss=1.8216\n",
      "[Epoch 10 | Iter 00008] loss=1.8160\n",
      "[Epoch 10 | Iter 00009] loss=1.8062\n",
      "[Epoch 10 | Iter 00010] loss=1.8320\n",
      "[Epoch 10 | Iter 00011] loss=1.8288\n",
      "[Epoch 10 | Iter 00012] loss=1.8383\n",
      "[Epoch 10 | Iter 00013] loss=1.8544\n",
      "[Epoch 10 | Iter 00014] loss=1.8515\n",
      "[Epoch 10 | Iter 00015] loss=1.8493\n",
      "[Epoch 10 | Iter 00016] loss=1.8522\n",
      "[Epoch 10 | Iter 00017] loss=1.8431\n",
      "[Epoch 10 | Iter 00018] loss=1.8455\n",
      "[Epoch 10 | Iter 00019] loss=1.8432\n",
      "[Epoch 10 | Iter 00020] loss=1.8446\n",
      "[Epoch 10 | Iter 00021] loss=1.8523\n",
      "[Epoch 10 | Iter 00022] loss=1.8537\n",
      "[Epoch 10 | Iter 00023] loss=1.8555\n",
      "[Epoch 10 | Iter 00024] loss=1.8570\n",
      "[Epoch 10 | Iter 00025] loss=1.8573\n",
      "[Epoch 10] Train: loss=1.8573 (29.3s, 27.1 samples/s) | Val: mIoU=0.0493 PixelAcc=0.4691 (17.6s, 5.7 samples/s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_010.pt (0.1s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.4s) size(20.1MB) total(0.5s)\n",
      "‚è±Ô∏è  Timing: Save(0.5s) | Total(47.4s) | Breakdown: Train(61.9%) Val(37.1%) Save(1.0%)\n",
      "[Epoch 11 | Iter 00001] loss=1.9066\n",
      "[Epoch 11 | Iter 00002] loss=1.8730\n",
      "[Epoch 11 | Iter 00003] loss=1.8582\n",
      "[Epoch 11 | Iter 00004] loss=1.8163\n",
      "[Epoch 11 | Iter 00005] loss=1.8271\n",
      "[Epoch 11 | Iter 00006] loss=1.8156\n",
      "[Epoch 11 | Iter 00007] loss=1.8157\n",
      "[Epoch 11 | Iter 00008] loss=1.8095\n",
      "[Epoch 11 | Iter 00009] loss=1.8091\n",
      "[Epoch 11 | Iter 00010] loss=1.8235\n",
      "[Epoch 11 | Iter 00011] loss=1.8136\n",
      "[Epoch 11 | Iter 00012] loss=1.8110\n",
      "[Epoch 11 | Iter 00013] loss=1.8095\n",
      "[Epoch 11 | Iter 00014] loss=1.8104\n",
      "[Epoch 11 | Iter 00015] loss=1.8133\n",
      "[Epoch 11 | Iter 00016] loss=1.8133\n",
      "[Epoch 11 | Iter 00017] loss=1.8142\n",
      "[Epoch 11 | Iter 00018] loss=1.8163\n",
      "[Epoch 11 | Iter 00019] loss=1.8173\n",
      "[Epoch 11 | Iter 00020] loss=1.8131\n",
      "[Epoch 11 | Iter 00021] loss=1.8064\n",
      "[Epoch 11 | Iter 00022] loss=1.8057\n",
      "[Epoch 11 | Iter 00023] loss=1.8056\n",
      "[Epoch 11 | Iter 00024] loss=1.7996\n",
      "[Epoch 11 | Iter 00025] loss=1.8057\n",
      "[Epoch 11] Train: loss=1.8057 (28.3s, 28.1 samples/s) | Val: mIoU=0.0611 PixelAcc=0.4813 (17.7s, 5.6 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0611) to checkpoints/unet_mobilenet/best2.pth (0.5s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.1s) size(20.1MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(46.7s) | Breakdown: Train(60.6%) Val(38.0%) Save(1.4%)\n",
      "[Epoch 12 | Iter 00001] loss=1.7444\n",
      "[Epoch 12 | Iter 00002] loss=1.7363\n",
      "[Epoch 12 | Iter 00003] loss=1.7886\n",
      "[Epoch 12 | Iter 00004] loss=1.8053\n",
      "[Epoch 12 | Iter 00005] loss=1.7712\n",
      "[Epoch 12 | Iter 00006] loss=1.7868\n",
      "[Epoch 12 | Iter 00007] loss=1.7840\n",
      "[Epoch 12 | Iter 00008] loss=1.7729\n",
      "[Epoch 12 | Iter 00009] loss=1.7929\n",
      "[Epoch 12 | Iter 00010] loss=1.7895\n",
      "[Epoch 12 | Iter 00011] loss=1.7791\n",
      "[Epoch 12 | Iter 00012] loss=1.7791\n",
      "[Epoch 12 | Iter 00013] loss=1.7659\n",
      "[Epoch 12 | Iter 00014] loss=1.7599\n",
      "[Epoch 12 | Iter 00015] loss=1.7588\n",
      "[Epoch 12 | Iter 00016] loss=1.7576\n",
      "[Epoch 12 | Iter 00017] loss=1.7622\n",
      "[Epoch 12 | Iter 00018] loss=1.7565\n",
      "[Epoch 12 | Iter 00019] loss=1.7690\n",
      "[Epoch 12 | Iter 00020] loss=1.7685\n",
      "[Epoch 12 | Iter 00021] loss=1.7668\n",
      "[Epoch 12 | Iter 00022] loss=1.7696\n",
      "[Epoch 12 | Iter 00023] loss=1.7596\n",
      "[Epoch 12 | Iter 00024] loss=1.7678\n",
      "[Epoch 12 | Iter 00025] loss=1.7663\n",
      "[Epoch 12] Train: loss=1.7663 (28.5s, 27.9 samples/s) | Val: mIoU=0.0602 PixelAcc=0.4854 (17.4s, 5.7 samples/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(20.1MB) total(0.2s)\n",
      "‚è±Ô∏è  Timing: Save(0.2s) | Total(46.0s) | Breakdown: Train(61.8%) Val(37.8%) Save(0.3%)\n",
      "[Epoch 13 | Iter 00001] loss=1.7463\n",
      "[Epoch 13 | Iter 00002] loss=1.7820\n",
      "[Epoch 13 | Iter 00003] loss=1.7857\n",
      "[Epoch 13 | Iter 00004] loss=1.7694\n",
      "[Epoch 13 | Iter 00005] loss=1.7487\n",
      "[Epoch 13 | Iter 00006] loss=1.7515\n",
      "[Epoch 13 | Iter 00007] loss=1.7376\n",
      "[Epoch 13 | Iter 00008] loss=1.7472\n",
      "[Epoch 13 | Iter 00009] loss=1.7463\n",
      "[Epoch 13 | Iter 00010] loss=1.7539\n",
      "[Epoch 13 | Iter 00011] loss=1.7526\n",
      "[Epoch 13 | Iter 00012] loss=1.7457\n",
      "[Epoch 13 | Iter 00013] loss=1.7381\n",
      "[Epoch 13 | Iter 00014] loss=1.7324\n",
      "[Epoch 13 | Iter 00015] loss=1.7300\n",
      "[Epoch 13 | Iter 00016] loss=1.7288\n",
      "[Epoch 13 | Iter 00017] loss=1.7290\n",
      "[Epoch 13 | Iter 00018] loss=1.7226\n",
      "[Epoch 13 | Iter 00019] loss=1.7260\n",
      "[Epoch 13 | Iter 00020] loss=1.7229\n",
      "[Epoch 13 | Iter 00021] loss=1.7226\n",
      "[Epoch 13 | Iter 00022] loss=1.7222\n",
      "[Epoch 13 | Iter 00023] loss=1.7159\n",
      "[Epoch 13 | Iter 00024] loss=1.7202\n",
      "[Epoch 13 | Iter 00025] loss=1.7241\n",
      "[Epoch 13] Train: loss=1.7241 (28.7s, 27.7 samples/s) | Val: mIoU=0.0639 PixelAcc=0.4843 (17.7s, 5.7 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0639) to checkpoints/unet_mobilenet/best2.pth (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(20.1MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(46.8s) | Breakdown: Train(61.4%) Val(37.8%) Save(0.9%)\n",
      "[Epoch 14 | Iter 00001] loss=1.7796\n",
      "[Epoch 14 | Iter 00002] loss=1.7149\n",
      "[Epoch 14 | Iter 00003] loss=1.7090\n",
      "[Epoch 14 | Iter 00004] loss=1.6847\n",
      "[Epoch 14 | Iter 00005] loss=1.6872\n",
      "[Epoch 14 | Iter 00006] loss=1.6843\n",
      "[Epoch 14 | Iter 00007] loss=1.6905\n",
      "[Epoch 14 | Iter 00008] loss=1.6774\n",
      "[Epoch 14 | Iter 00009] loss=1.6709\n",
      "[Epoch 14 | Iter 00010] loss=1.6674\n",
      "[Epoch 14 | Iter 00011] loss=1.6616\n",
      "[Epoch 14 | Iter 00012] loss=1.6762\n",
      "[Epoch 14 | Iter 00013] loss=1.6749\n",
      "[Epoch 14 | Iter 00014] loss=1.6769\n",
      "[Epoch 14 | Iter 00015] loss=1.6794\n",
      "[Epoch 14 | Iter 00016] loss=1.6800\n",
      "[Epoch 14 | Iter 00017] loss=1.6799\n",
      "[Epoch 14 | Iter 00018] loss=1.6852\n",
      "[Epoch 14 | Iter 00019] loss=1.6830\n",
      "[Epoch 14 | Iter 00020] loss=1.6782\n",
      "[Epoch 14 | Iter 00021] loss=1.6762\n",
      "[Epoch 14 | Iter 00022] loss=1.6800\n",
      "[Epoch 14 | Iter 00023] loss=1.6782\n",
      "[Epoch 14 | Iter 00024] loss=1.6760\n",
      "[Epoch 14 | Iter 00025] loss=1.6766\n",
      "[Epoch 14] Train: loss=1.6766 (28.3s, 28.0 samples/s) | Val: mIoU=0.0673 PixelAcc=0.4886 (19.4s, 5.2 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0673) to checkpoints/unet_mobilenet/best2.pth (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(20.1MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(48.1s) | Breakdown: Train(59.0%) Val(40.3%) Save(0.7%)\n",
      "[Epoch 15 | Iter 00001] loss=1.8068\n",
      "[Epoch 15 | Iter 00002] loss=1.7561\n",
      "[Epoch 15 | Iter 00003] loss=1.6657\n",
      "[Epoch 15 | Iter 00004] loss=1.6896\n",
      "[Epoch 15 | Iter 00005] loss=1.7093\n",
      "[Epoch 15 | Iter 00006] loss=1.6913\n",
      "[Epoch 15 | Iter 00007] loss=1.6685\n",
      "[Epoch 15 | Iter 00008] loss=1.6540\n",
      "[Epoch 15 | Iter 00009] loss=1.6363\n",
      "[Epoch 15 | Iter 00010] loss=1.6254\n",
      "[Epoch 15 | Iter 00011] loss=1.6337\n",
      "[Epoch 15 | Iter 00012] loss=1.6367\n",
      "[Epoch 15 | Iter 00013] loss=1.6227\n",
      "[Epoch 15 | Iter 00014] loss=1.6137\n",
      "[Epoch 15 | Iter 00015] loss=1.6183\n",
      "[Epoch 15 | Iter 00016] loss=1.6147\n",
      "[Epoch 15 | Iter 00017] loss=1.6240\n",
      "[Epoch 15 | Iter 00018] loss=1.6294\n",
      "[Epoch 15 | Iter 00019] loss=1.6326\n",
      "[Epoch 15 | Iter 00020] loss=1.6311\n",
      "[Epoch 15 | Iter 00021] loss=1.6318\n",
      "[Epoch 15 | Iter 00022] loss=1.6326\n",
      "[Epoch 15 | Iter 00023] loss=1.6330\n",
      "[Epoch 15 | Iter 00024] loss=1.6380\n",
      "[Epoch 15 | Iter 00025] loss=1.6393\n",
      "[Epoch 15] Train: loss=1.6393 (28.3s, 28.1 samples/s) | Val: mIoU=0.0749 PixelAcc=0.4963 (17.7s, 5.6 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0749) to checkpoints/unet_mobilenet/best2.pth (0.2s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_015.pt (0.1s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(20.1MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(46.5s) | Breakdown: Train(60.9%) Val(38.2%) Save(1.0%)\n",
      "[Epoch 16 | Iter 00001] loss=1.6128\n",
      "[Epoch 16 | Iter 00002] loss=1.6238\n",
      "[Epoch 16 | Iter 00003] loss=1.6147\n",
      "[Epoch 16 | Iter 00004] loss=1.5733\n",
      "[Epoch 16 | Iter 00005] loss=1.5615\n",
      "[Epoch 16 | Iter 00006] loss=1.5585\n",
      "[Epoch 16 | Iter 00007] loss=1.5701\n",
      "[Epoch 16 | Iter 00008] loss=1.5936\n",
      "[Epoch 16 | Iter 00009] loss=1.5940\n",
      "[Epoch 16 | Iter 00010] loss=1.6000\n",
      "[Epoch 16 | Iter 00011] loss=1.6133\n",
      "[Epoch 16 | Iter 00012] loss=1.6177\n",
      "[Epoch 16 | Iter 00013] loss=1.6181\n",
      "[Epoch 16 | Iter 00014] loss=1.6246\n",
      "[Epoch 16 | Iter 00015] loss=1.6165\n",
      "[Epoch 16 | Iter 00016] loss=1.6133\n",
      "[Epoch 16 | Iter 00017] loss=1.6043\n",
      "[Epoch 16 | Iter 00018] loss=1.6054\n",
      "[Epoch 16 | Iter 00019] loss=1.6071\n",
      "[Epoch 16 | Iter 00020] loss=1.6051\n",
      "[Epoch 16 | Iter 00021] loss=1.6027\n",
      "[Epoch 16 | Iter 00022] loss=1.6056\n",
      "[Epoch 16 | Iter 00023] loss=1.6123\n",
      "[Epoch 16 | Iter 00024] loss=1.6110\n",
      "[Epoch 16 | Iter 00025] loss=1.6076\n",
      "[Epoch 16] Train: loss=1.6076 (27.6s, 28.8 samples/s) | Val: mIoU=0.0800 PixelAcc=0.4976 (17.6s, 5.7 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0800) to checkpoints/unet_mobilenet/best2.pth (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.5s) size(20.1MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(45.8s) | Breakdown: Train(60.2%) Val(38.3%) Save(1.4%)\n",
      "[Epoch 17 | Iter 00001] loss=1.4460\n",
      "[Epoch 17 | Iter 00002] loss=1.5022\n",
      "[Epoch 17 | Iter 00003] loss=1.5153\n",
      "[Epoch 17 | Iter 00004] loss=1.5240\n",
      "[Epoch 17 | Iter 00005] loss=1.5315\n",
      "[Epoch 17 | Iter 00006] loss=1.5372\n",
      "[Epoch 17 | Iter 00007] loss=1.5298\n",
      "[Epoch 17 | Iter 00008] loss=1.5276\n",
      "[Epoch 17 | Iter 00009] loss=1.5396\n",
      "[Epoch 17 | Iter 00010] loss=1.5362\n",
      "[Epoch 17 | Iter 00011] loss=1.5320\n",
      "[Epoch 17 | Iter 00012] loss=1.5404\n",
      "[Epoch 17 | Iter 00013] loss=1.5395\n",
      "[Epoch 17 | Iter 00014] loss=1.5366\n",
      "[Epoch 17 | Iter 00015] loss=1.5405\n",
      "[Epoch 17 | Iter 00016] loss=1.5466\n",
      "[Epoch 17 | Iter 00017] loss=1.5414\n",
      "[Epoch 17 | Iter 00018] loss=1.5464\n",
      "[Epoch 17 | Iter 00019] loss=1.5541\n",
      "[Epoch 17 | Iter 00020] loss=1.5543\n",
      "[Epoch 17 | Iter 00021] loss=1.5571\n",
      "[Epoch 17 | Iter 00022] loss=1.5583\n",
      "[Epoch 17 | Iter 00023] loss=1.5610\n",
      "[Epoch 17 | Iter 00024] loss=1.5563\n",
      "[Epoch 17 | Iter 00025] loss=1.5560\n",
      "[Epoch 17] Train: loss=1.5560 (28.0s, 28.4 samples/s) | Val: mIoU=0.0832 PixelAcc=0.5057 (17.3s, 5.8 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0832) to checkpoints/unet_mobilenet/best2.pth (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.1s) size(20.1MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(45.7s) | Breakdown: Train(61.3%) Val(37.9%) Save(0.9%)\n",
      "[Epoch 18 | Iter 00001] loss=1.5461\n",
      "[Epoch 18 | Iter 00002] loss=1.5296\n",
      "[Epoch 18 | Iter 00003] loss=1.5145\n",
      "[Epoch 18 | Iter 00004] loss=1.5232\n",
      "[Epoch 18 | Iter 00005] loss=1.5170\n",
      "[Epoch 18 | Iter 00006] loss=1.5026\n",
      "[Epoch 18 | Iter 00007] loss=1.5014\n",
      "[Epoch 18 | Iter 00008] loss=1.5031\n",
      "[Epoch 18 | Iter 00009] loss=1.4973\n",
      "[Epoch 18 | Iter 00010] loss=1.4996\n",
      "[Epoch 18 | Iter 00011] loss=1.5144\n",
      "[Epoch 18 | Iter 00012] loss=1.5163\n",
      "[Epoch 18 | Iter 00013] loss=1.5140\n",
      "[Epoch 18 | Iter 00014] loss=1.5057\n",
      "[Epoch 18 | Iter 00015] loss=1.5070\n",
      "[Epoch 18 | Iter 00016] loss=1.5101\n",
      "[Epoch 18 | Iter 00017] loss=1.5150\n",
      "[Epoch 18 | Iter 00018] loss=1.5146\n",
      "[Epoch 18 | Iter 00019] loss=1.5175\n",
      "[Epoch 18 | Iter 00020] loss=1.5119\n",
      "[Epoch 18 | Iter 00021] loss=1.5163\n",
      "[Epoch 18 | Iter 00022] loss=1.5190\n",
      "[Epoch 18 | Iter 00023] loss=1.5172\n",
      "[Epoch 18 | Iter 00024] loss=1.5172\n",
      "[Epoch 18 | Iter 00025] loss=1.5224\n",
      "[Epoch 18] Train: loss=1.5224 (27.4s, 29.1 samples/s) | Val: mIoU=0.0876 PixelAcc=0.5031 (17.3s, 5.8 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0876) to checkpoints/unet_mobilenet/best2.pth (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(20.1MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(45.0s) | Breakdown: Train(60.8%) Val(38.4%) Save(0.8%)\n",
      "[Epoch 19 | Iter 00001] loss=1.4326\n",
      "[Epoch 19 | Iter 00002] loss=1.4428\n",
      "[Epoch 19 | Iter 00003] loss=1.4337\n",
      "[Epoch 19 | Iter 00004] loss=1.4814\n",
      "[Epoch 19 | Iter 00005] loss=1.4806\n",
      "[Epoch 19 | Iter 00006] loss=1.4934\n",
      "[Epoch 19 | Iter 00007] loss=1.4799\n",
      "[Epoch 19 | Iter 00008] loss=1.4836\n",
      "[Epoch 19 | Iter 00009] loss=1.4944\n",
      "[Epoch 19 | Iter 00010] loss=1.4802\n",
      "[Epoch 19 | Iter 00011] loss=1.4847\n",
      "[Epoch 19 | Iter 00012] loss=1.4876\n",
      "[Epoch 19 | Iter 00013] loss=1.4867\n",
      "[Epoch 19 | Iter 00014] loss=1.4791\n",
      "[Epoch 19 | Iter 00015] loss=1.4788\n",
      "[Epoch 19 | Iter 00016] loss=1.4813\n",
      "[Epoch 19 | Iter 00017] loss=1.4751\n",
      "[Epoch 19 | Iter 00018] loss=1.4838\n",
      "[Epoch 19 | Iter 00019] loss=1.4827\n",
      "[Epoch 19 | Iter 00020] loss=1.4825\n",
      "[Epoch 19 | Iter 00021] loss=1.4834\n",
      "[Epoch 19 | Iter 00022] loss=1.4834\n",
      "[Epoch 19 | Iter 00023] loss=1.4868\n",
      "[Epoch 19 | Iter 00024] loss=1.4891\n",
      "[Epoch 19 | Iter 00025] loss=1.4872\n",
      "[Epoch 19] Train: loss=1.4872 (26.9s, 29.5 samples/s) | Val: mIoU=0.0840 PixelAcc=0.5041 (17.3s, 5.8 samples/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(20.1MB) total(0.2s)\n",
      "‚è±Ô∏è  Timing: Save(0.2s) | Total(44.4s) | Breakdown: Train(60.6%) Val(38.9%) Save(0.5%)\n",
      "[Epoch 20 | Iter 00001] loss=1.4501\n",
      "[Epoch 20 | Iter 00002] loss=1.4339\n",
      "[Epoch 20 | Iter 00003] loss=1.4321\n",
      "[Epoch 20 | Iter 00004] loss=1.4125\n",
      "[Epoch 20 | Iter 00005] loss=1.4233\n",
      "[Epoch 20 | Iter 00006] loss=1.4185\n",
      "[Epoch 20 | Iter 00007] loss=1.4081\n",
      "[Epoch 20 | Iter 00008] loss=1.4252\n",
      "[Epoch 20 | Iter 00009] loss=1.4261\n",
      "[Epoch 20 | Iter 00010] loss=1.4413\n",
      "[Epoch 20 | Iter 00011] loss=1.4400\n",
      "[Epoch 20 | Iter 00012] loss=1.4498\n",
      "[Epoch 20 | Iter 00013] loss=1.4560\n",
      "[Epoch 20 | Iter 00014] loss=1.4593\n",
      "[Epoch 20 | Iter 00015] loss=1.4646\n",
      "[Epoch 20 | Iter 00016] loss=1.4642\n",
      "[Epoch 20 | Iter 00017] loss=1.4651\n",
      "[Epoch 20 | Iter 00018] loss=1.4645\n",
      "[Epoch 20 | Iter 00019] loss=1.4638\n",
      "[Epoch 20 | Iter 00020] loss=1.4603\n",
      "[Epoch 20 | Iter 00021] loss=1.4704\n",
      "[Epoch 20 | Iter 00022] loss=1.4702\n",
      "[Epoch 20 | Iter 00023] loss=1.4667\n",
      "[Epoch 20 | Iter 00024] loss=1.4657\n",
      "[Epoch 20 | Iter 00025] loss=1.4685\n",
      "[Epoch 20] Train: loss=1.4685 (26.9s, 29.5 samples/s) | Val: mIoU=0.0894 PixelAcc=0.5036 (17.2s, 5.8 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0894) to checkpoints/unet_mobilenet/best2.pth (0.2s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_020.pt (0.1s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(20.1MB) total(0.5s)\n",
      "‚è±Ô∏è  Timing: Save(0.5s) | Total(44.6s) | Breakdown: Train(60.3%) Val(38.5%) Save(1.2%)\n",
      "Training complete!\n",
      "Best mIoU: 0.0894\n",
      "\n",
      "üîÑ Loading best model for final evaluation...\n",
      "Final validation metrics: mIoU=0.0894, PixelAcc=0.5036 (load: 0.1s, eval: 16.8s)\n"
     ]
    }
   ],
   "source": [
    "model.freeze_backbone()\n",
    "trained_model = trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2cf87a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3-small encoder unfrozen: parameters will be updated during training\n",
      "Using device: mps\n",
      "Training configuration:\n",
      "  Use RGB: True\n",
      "  Use Depth: False\n",
      "  Input channels: 3\n",
      "  Label mode: nyu40\n",
      "  Num classes: 40\n",
      "Training samples: 795\n",
      "Validation samples: 100\n",
      "Total parameters: 2,361,960\n",
      "Trainable parameters: 2,361,960\n",
      "Resuming training from: checkpoints/unet_mobilenet/latest2.pth\n",
      "‚úì Resumed from epoch 20\n",
      "‚úì Training history loaded with 20 epochs\n",
      "‚úì Best mIoU so far: 0.0894\n",
      "Starting training for 30 epochs (from epoch 21)...\n",
      "[Epoch 21 | Iter 00001] loss=1.3446\n",
      "[Epoch 21 | Iter 00002] loss=1.3771\n",
      "[Epoch 21 | Iter 00003] loss=1.4331\n",
      "[Epoch 21 | Iter 00004] loss=1.4333\n",
      "[Epoch 21 | Iter 00005] loss=1.4436\n",
      "[Epoch 21 | Iter 00006] loss=1.4600\n",
      "[Epoch 21 | Iter 00007] loss=1.4629\n",
      "[Epoch 21 | Iter 00008] loss=1.4803\n",
      "[Epoch 21 | Iter 00009] loss=1.4754\n",
      "[Epoch 21 | Iter 00010] loss=1.4899\n",
      "[Epoch 21 | Iter 00011] loss=1.4888\n",
      "[Epoch 21 | Iter 00012] loss=1.4913\n",
      "[Epoch 21 | Iter 00013] loss=1.4926\n",
      "[Epoch 21 | Iter 00014] loss=1.5010\n",
      "[Epoch 21 | Iter 00015] loss=1.4983\n",
      "[Epoch 21 | Iter 00016] loss=1.5005\n",
      "[Epoch 21 | Iter 00017] loss=1.5068\n",
      "[Epoch 21 | Iter 00018] loss=1.5071\n",
      "[Epoch 21 | Iter 00019] loss=1.5138\n",
      "[Epoch 21 | Iter 00020] loss=1.5193\n",
      "[Epoch 21 | Iter 00021] loss=1.5216\n",
      "[Epoch 21 | Iter 00022] loss=1.5146\n",
      "[Epoch 21 | Iter 00023] loss=1.5037\n",
      "[Epoch 21 | Iter 00024] loss=1.5034\n",
      "[Epoch 21 | Iter 00025] loss=1.5034\n",
      "[Epoch 21] Train: loss=1.5034 (38.3s, 20.8 samples/s) | Val: mIoU=0.0731 PixelAcc=0.4530 (20.7s, 4.8 samples/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(26.9MB) total(0.3s)\n",
      "‚è±Ô∏è  Timing: Save(0.3s) | Total(59.2s) | Breakdown: Train(64.6%) Val(35.0%) Save(0.4%)\n",
      "[Epoch 22 | Iter 00001] loss=1.5170\n",
      "[Epoch 22 | Iter 00002] loss=1.5008\n",
      "[Epoch 22 | Iter 00003] loss=1.5060\n",
      "[Epoch 22 | Iter 00004] loss=1.4526\n",
      "[Epoch 22 | Iter 00005] loss=1.4674\n",
      "[Epoch 22 | Iter 00006] loss=1.4641\n",
      "[Epoch 22 | Iter 00007] loss=1.4521\n",
      "[Epoch 22 | Iter 00008] loss=1.4431\n",
      "[Epoch 22 | Iter 00009] loss=1.4501\n",
      "[Epoch 22 | Iter 00010] loss=1.4337\n",
      "[Epoch 22 | Iter 00011] loss=1.4276\n",
      "[Epoch 22 | Iter 00012] loss=1.4372\n",
      "[Epoch 22 | Iter 00013] loss=1.4404\n",
      "[Epoch 22 | Iter 00014] loss=1.4456\n",
      "[Epoch 22 | Iter 00015] loss=1.4404\n",
      "[Epoch 22 | Iter 00016] loss=1.4324\n",
      "[Epoch 22 | Iter 00017] loss=1.4324\n",
      "[Epoch 22 | Iter 00018] loss=1.4256\n",
      "[Epoch 22 | Iter 00019] loss=1.4328\n",
      "[Epoch 22 | Iter 00020] loss=1.4337\n",
      "[Epoch 22 | Iter 00021] loss=1.4356\n",
      "[Epoch 22 | Iter 00022] loss=1.4333\n",
      "[Epoch 22 | Iter 00023] loss=1.4262\n",
      "[Epoch 22 | Iter 00024] loss=1.4260\n",
      "[Epoch 22 | Iter 00025] loss=1.4288\n",
      "[Epoch 22] Train: loss=1.4288 (36.0s, 22.1 samples/s) | Val: mIoU=0.0919 PixelAcc=0.4783 (17.6s, 5.7 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.0919) to checkpoints/unet_mobilenet/best2.pth (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.6s)\n",
      "‚è±Ô∏è  Timing: Save(0.6s) | Total(54.1s) | Breakdown: Train(66.5%) Val(32.4%) Save(1.1%)\n",
      "[Epoch 23 | Iter 00001] loss=1.4124\n",
      "[Epoch 23 | Iter 00002] loss=1.4200\n",
      "[Epoch 23 | Iter 00003] loss=1.3480\n",
      "[Epoch 23 | Iter 00004] loss=1.3424\n",
      "[Epoch 23 | Iter 00005] loss=1.3270\n",
      "[Epoch 23 | Iter 00006] loss=1.3411\n",
      "[Epoch 23 | Iter 00007] loss=1.3362\n",
      "[Epoch 23 | Iter 00008] loss=1.3481\n",
      "[Epoch 23 | Iter 00009] loss=1.3343\n",
      "[Epoch 23 | Iter 00010] loss=1.3338\n",
      "[Epoch 23 | Iter 00011] loss=1.3255\n",
      "[Epoch 23 | Iter 00012] loss=1.3087\n",
      "[Epoch 23 | Iter 00013] loss=1.3173\n",
      "[Epoch 23 | Iter 00014] loss=1.3176\n",
      "[Epoch 23 | Iter 00015] loss=1.3105\n",
      "[Epoch 23 | Iter 00016] loss=1.3115\n",
      "[Epoch 23 | Iter 00017] loss=1.3159\n",
      "[Epoch 23 | Iter 00018] loss=1.3204\n",
      "[Epoch 23 | Iter 00019] loss=1.3210\n",
      "[Epoch 23 | Iter 00020] loss=1.3251\n",
      "[Epoch 23 | Iter 00021] loss=1.3270\n",
      "[Epoch 23 | Iter 00022] loss=1.3295\n",
      "[Epoch 23 | Iter 00023] loss=1.3248\n",
      "[Epoch 23 | Iter 00024] loss=1.3308\n",
      "[Epoch 23 | Iter 00025] loss=1.3323\n",
      "[Epoch 23] Train: loss=1.3323 (37.6s, 21.1 samples/s) | Val: mIoU=0.0834 PixelAcc=0.4338 (18.4s, 5.4 samples/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(26.9MB) total(0.3s)\n",
      "‚è±Ô∏è  Timing: Save(0.3s) | Total(56.4s) | Breakdown: Train(66.7%) Val(32.7%) Save(0.5%)\n",
      "[Epoch 24 | Iter 00001] loss=1.2819\n",
      "[Epoch 24 | Iter 00002] loss=1.2464\n",
      "[Epoch 24 | Iter 00003] loss=1.2374\n",
      "[Epoch 24 | Iter 00004] loss=1.2443\n",
      "[Epoch 24 | Iter 00005] loss=1.2515\n",
      "[Epoch 24 | Iter 00006] loss=1.2650\n",
      "[Epoch 24 | Iter 00007] loss=1.2718\n",
      "[Epoch 24 | Iter 00008] loss=1.2724\n",
      "[Epoch 24 | Iter 00009] loss=1.2793\n",
      "[Epoch 24 | Iter 00010] loss=1.2786\n",
      "[Epoch 24 | Iter 00011] loss=1.2833\n",
      "[Epoch 24 | Iter 00012] loss=1.2885\n",
      "[Epoch 24 | Iter 00013] loss=1.2879\n",
      "[Epoch 24 | Iter 00014] loss=1.2914\n",
      "[Epoch 24 | Iter 00015] loss=1.2945\n",
      "[Epoch 24 | Iter 00016] loss=1.3048\n",
      "[Epoch 24 | Iter 00017] loss=1.3036\n",
      "[Epoch 24 | Iter 00018] loss=1.3020\n",
      "[Epoch 24 | Iter 00019] loss=1.3011\n",
      "[Epoch 24 | Iter 00020] loss=1.2981\n",
      "[Epoch 24 | Iter 00021] loss=1.2956\n",
      "[Epoch 24 | Iter 00022] loss=1.2945\n",
      "[Epoch 24 | Iter 00023] loss=1.2962\n",
      "[Epoch 24 | Iter 00024] loss=1.2951\n",
      "[Epoch 24 | Iter 00025] loss=1.2921\n",
      "[Epoch 24] Train: loss=1.2921 (36.2s, 22.0 samples/s) | Val: mIoU=0.1026 PixelAcc=0.4977 (19.2s, 5.2 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1026) to checkpoints/unet_mobilenet/best2.pth (0.3s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.6s)\n",
      "‚è±Ô∏è  Timing: Save(0.6s) | Total(56.0s) | Breakdown: Train(64.7%) Val(34.3%) Save(1.1%)\n",
      "[Epoch 25 | Iter 00001] loss=1.3643\n",
      "[Epoch 25 | Iter 00002] loss=1.3161\n",
      "[Epoch 25 | Iter 00003] loss=1.2715\n",
      "[Epoch 25 | Iter 00004] loss=1.2853\n",
      "[Epoch 25 | Iter 00005] loss=1.2628\n",
      "[Epoch 25 | Iter 00006] loss=1.2551\n",
      "[Epoch 25 | Iter 00007] loss=1.2431\n",
      "[Epoch 25 | Iter 00008] loss=1.2378\n",
      "[Epoch 25 | Iter 00009] loss=1.2367\n",
      "[Epoch 25 | Iter 00010] loss=1.2308\n",
      "[Epoch 25 | Iter 00011] loss=1.2220\n",
      "[Epoch 25 | Iter 00012] loss=1.2152\n",
      "[Epoch 25 | Iter 00013] loss=1.2166\n",
      "[Epoch 25 | Iter 00014] loss=1.2140\n",
      "[Epoch 25 | Iter 00015] loss=1.2108\n",
      "[Epoch 25 | Iter 00016] loss=1.2129\n",
      "[Epoch 25 | Iter 00017] loss=1.2131\n",
      "[Epoch 25 | Iter 00018] loss=1.2202\n",
      "[Epoch 25 | Iter 00019] loss=1.2186\n",
      "[Epoch 25 | Iter 00020] loss=1.2185\n",
      "[Epoch 25 | Iter 00021] loss=1.2216\n",
      "[Epoch 25 | Iter 00022] loss=1.2223\n",
      "[Epoch 25 | Iter 00023] loss=1.2218\n",
      "[Epoch 25 | Iter 00024] loss=1.2250\n",
      "[Epoch 25 | Iter 00025] loss=1.2255\n",
      "[Epoch 25] Train: loss=1.2255 (34.7s, 22.9 samples/s) | Val: mIoU=0.1127 PixelAcc=0.5051 (18.0s, 5.5 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1127) to checkpoints/unet_mobilenet/best2.pth (0.3s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_025.pt (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.8s)\n",
      "‚è±Ô∏è  Timing: Save(0.8s) | Total(53.5s) | Breakdown: Train(64.8%) Val(33.7%) Save(1.4%)\n",
      "[Epoch 26 | Iter 00001] loss=1.1749\n",
      "[Epoch 26 | Iter 00002] loss=1.1727\n",
      "[Epoch 26 | Iter 00003] loss=1.2087\n",
      "[Epoch 26 | Iter 00004] loss=1.2038\n",
      "[Epoch 26 | Iter 00005] loss=1.2056\n",
      "[Epoch 26 | Iter 00006] loss=1.2009\n",
      "[Epoch 26 | Iter 00007] loss=1.2028\n",
      "[Epoch 26 | Iter 00008] loss=1.2030\n",
      "[Epoch 26 | Iter 00009] loss=1.1922\n",
      "[Epoch 26 | Iter 00010] loss=1.1930\n",
      "[Epoch 26 | Iter 00011] loss=1.1952\n",
      "[Epoch 26 | Iter 00012] loss=1.1937\n",
      "[Epoch 26 | Iter 00013] loss=1.1857\n",
      "[Epoch 26 | Iter 00014] loss=1.1793\n",
      "[Epoch 26 | Iter 00015] loss=1.1752\n",
      "[Epoch 26 | Iter 00016] loss=1.1824\n",
      "[Epoch 26 | Iter 00017] loss=1.1808\n",
      "[Epoch 26 | Iter 00018] loss=1.1876\n",
      "[Epoch 26 | Iter 00019] loss=1.1863\n",
      "[Epoch 26 | Iter 00020] loss=1.1838\n",
      "[Epoch 26 | Iter 00021] loss=1.1837\n",
      "[Epoch 26 | Iter 00022] loss=1.1820\n",
      "[Epoch 26 | Iter 00023] loss=1.1843\n",
      "[Epoch 26 | Iter 00024] loss=1.1817\n",
      "[Epoch 26 | Iter 00025] loss=1.1852\n",
      "[Epoch 26] Train: loss=1.1852 (34.5s, 23.1 samples/s) | Val: mIoU=0.1179 PixelAcc=0.5046 (17.7s, 5.6 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1179) to checkpoints/unet_mobilenet/best2.pth (0.3s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.5s)\n",
      "‚è±Ô∏è  Timing: Save(0.5s) | Total(52.7s) | Breakdown: Train(65.4%) Val(33.6%) Save(1.0%)\n",
      "[Epoch 27 | Iter 00001] loss=1.1334\n",
      "[Epoch 27 | Iter 00002] loss=1.1345\n",
      "[Epoch 27 | Iter 00003] loss=1.1402\n",
      "[Epoch 27 | Iter 00004] loss=1.1623\n",
      "[Epoch 27 | Iter 00005] loss=1.1662\n",
      "[Epoch 27 | Iter 00006] loss=1.1440\n",
      "[Epoch 27 | Iter 00007] loss=1.1422\n",
      "[Epoch 27 | Iter 00008] loss=1.1397\n",
      "[Epoch 27 | Iter 00009] loss=1.1358\n",
      "[Epoch 27 | Iter 00010] loss=1.1282\n",
      "[Epoch 27 | Iter 00011] loss=1.1268\n",
      "[Epoch 27 | Iter 00012] loss=1.1224\n",
      "[Epoch 27 | Iter 00013] loss=1.1286\n",
      "[Epoch 27 | Iter 00014] loss=1.1195\n",
      "[Epoch 27 | Iter 00015] loss=1.1194\n",
      "[Epoch 27 | Iter 00016] loss=1.1188\n",
      "[Epoch 27 | Iter 00017] loss=1.1231\n",
      "[Epoch 27 | Iter 00018] loss=1.1251\n",
      "[Epoch 27 | Iter 00019] loss=1.1291\n",
      "[Epoch 27 | Iter 00020] loss=1.1272\n",
      "[Epoch 27 | Iter 00021] loss=1.1280\n",
      "[Epoch 27 | Iter 00022] loss=1.1266\n",
      "[Epoch 27 | Iter 00023] loss=1.1271\n",
      "[Epoch 27 | Iter 00024] loss=1.1267\n",
      "[Epoch 27 | Iter 00025] loss=1.1236\n",
      "[Epoch 27] Train: loss=1.1236 (36.9s, 21.5 samples/s) | Val: mIoU=0.1346 PixelAcc=0.5279 (21.0s, 4.8 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1346) to checkpoints/unet_mobilenet/best2.pth (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(26.9MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(58.6s) | Breakdown: Train(63.0%) Val(35.9%) Save(1.1%)\n",
      "[Epoch 28 | Iter 00001] loss=1.1177\n",
      "[Epoch 28 | Iter 00002] loss=1.1136\n",
      "[Epoch 28 | Iter 00003] loss=1.0946\n",
      "[Epoch 28 | Iter 00004] loss=1.0855\n",
      "[Epoch 28 | Iter 00005] loss=1.0728\n",
      "[Epoch 28 | Iter 00006] loss=1.0664\n",
      "[Epoch 28 | Iter 00007] loss=1.0568\n",
      "[Epoch 28 | Iter 00008] loss=1.0630\n",
      "[Epoch 28 | Iter 00009] loss=1.0578\n",
      "[Epoch 28 | Iter 00010] loss=1.0561\n",
      "[Epoch 28 | Iter 00011] loss=1.0592\n",
      "[Epoch 28 | Iter 00012] loss=1.0554\n",
      "[Epoch 28 | Iter 00013] loss=1.0546\n",
      "[Epoch 28 | Iter 00014] loss=1.0552\n",
      "[Epoch 28 | Iter 00015] loss=1.0628\n",
      "[Epoch 28 | Iter 00016] loss=1.0645\n",
      "[Epoch 28 | Iter 00017] loss=1.0650\n",
      "[Epoch 28 | Iter 00018] loss=1.0643\n",
      "[Epoch 28 | Iter 00019] loss=1.0658\n",
      "[Epoch 28 | Iter 00020] loss=1.0652\n",
      "[Epoch 28 | Iter 00021] loss=1.0639\n",
      "[Epoch 28 | Iter 00022] loss=1.0665\n",
      "[Epoch 28 | Iter 00023] loss=1.0698\n",
      "[Epoch 28 | Iter 00024] loss=1.0719\n",
      "[Epoch 28 | Iter 00025] loss=1.0675\n",
      "[Epoch 28] Train: loss=1.0675 (36.6s, 21.7 samples/s) | Val: mIoU=0.1212 PixelAcc=0.5037 (20.0s, 5.0 samples/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.2s)\n",
      "‚è±Ô∏è  Timing: Save(0.2s) | Total(56.8s) | Breakdown: Train(64.4%) Val(35.2%) Save(0.4%)\n",
      "[Epoch 29 | Iter 00001] loss=1.0195\n",
      "[Epoch 29 | Iter 00002] loss=0.9846\n",
      "[Epoch 29 | Iter 00003] loss=1.0126\n",
      "[Epoch 29 | Iter 00004] loss=1.0179\n",
      "[Epoch 29 | Iter 00005] loss=1.0162\n",
      "[Epoch 29 | Iter 00006] loss=1.0469\n",
      "[Epoch 29 | Iter 00007] loss=1.0539\n",
      "[Epoch 29 | Iter 00008] loss=1.0470\n",
      "[Epoch 29 | Iter 00009] loss=1.0463\n",
      "[Epoch 29 | Iter 00010] loss=1.0448\n",
      "[Epoch 29 | Iter 00011] loss=1.0510\n",
      "[Epoch 29 | Iter 00012] loss=1.0436\n",
      "[Epoch 29 | Iter 00013] loss=1.0457\n",
      "[Epoch 29 | Iter 00014] loss=1.0490\n",
      "[Epoch 29 | Iter 00015] loss=1.0412\n",
      "[Epoch 29 | Iter 00016] loss=1.0378\n",
      "[Epoch 29 | Iter 00017] loss=1.0373\n",
      "[Epoch 29 | Iter 00018] loss=1.0342\n",
      "[Epoch 29 | Iter 00019] loss=1.0340\n",
      "[Epoch 29 | Iter 00020] loss=1.0350\n",
      "[Epoch 29 | Iter 00021] loss=1.0343\n",
      "[Epoch 29 | Iter 00022] loss=1.0366\n",
      "[Epoch 29 | Iter 00023] loss=1.0366\n",
      "[Epoch 29 | Iter 00024] loss=1.0339\n",
      "[Epoch 29 | Iter 00025] loss=1.0349\n",
      "[Epoch 29] Train: loss=1.0349 (34.5s, 23.1 samples/s) | Val: mIoU=0.1367 PixelAcc=0.5096 (18.9s, 5.3 samples/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1367) to checkpoints/unet_mobilenet/best2.pth (0.3s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.6s)\n",
      "‚è±Ô∏è  Timing: Save(0.6s) | Total(53.9s) | Breakdown: Train(63.9%) Val(35.0%) Save(1.0%)\n",
      "[Epoch 30 | Iter 00001] loss=0.9887\n",
      "[Epoch 30 | Iter 00002] loss=1.0015\n",
      "[Epoch 30 | Iter 00003] loss=0.9775\n",
      "[Epoch 30 | Iter 00004] loss=0.9626\n",
      "[Epoch 30 | Iter 00005] loss=0.9709\n",
      "[Epoch 30 | Iter 00006] loss=0.9725\n",
      "[Epoch 30 | Iter 00007] loss=0.9712\n",
      "[Epoch 30 | Iter 00008] loss=0.9716\n",
      "[Epoch 30 | Iter 00009] loss=0.9614\n",
      "[Epoch 30 | Iter 00010] loss=0.9763\n",
      "[Epoch 30 | Iter 00011] loss=0.9761\n",
      "[Epoch 30 | Iter 00012] loss=0.9740\n",
      "[Epoch 30 | Iter 00013] loss=0.9858\n",
      "[Epoch 30 | Iter 00014] loss=0.9845\n",
      "[Epoch 30 | Iter 00015] loss=0.9855\n",
      "[Epoch 30 | Iter 00016] loss=0.9870\n",
      "[Epoch 30 | Iter 00017] loss=0.9846\n",
      "[Epoch 30 | Iter 00018] loss=0.9887\n",
      "[Epoch 30 | Iter 00019] loss=0.9889\n",
      "[Epoch 30 | Iter 00020] loss=0.9883\n",
      "[Epoch 30 | Iter 00021] loss=0.9926\n",
      "[Epoch 30 | Iter 00022] loss=0.9932\n",
      "[Epoch 30 | Iter 00023] loss=0.9914\n",
      "[Epoch 30 | Iter 00024] loss=0.9928\n",
      "[Epoch 30 | Iter 00025] loss=0.9925\n",
      "[Epoch 30] Train: loss=0.9925 (35.7s, 22.2 samples/s) | Val: mIoU=0.1345 PixelAcc=0.5110 (19.7s, 5.1 samples/s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_030.pt (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(55.8s) | Breakdown: Train(64.0%) Val(35.3%) Save(0.7%)\n",
      "Training complete!\n",
      "Best mIoU: 0.1367\n",
      "\n",
      "üîÑ Loading best model for final evaluation...\n",
      "Final validation metrics: mIoU=0.1367, PixelAcc=0.5096 (load: 0.8s, eval: 19.1s)\n"
     ]
    }
   ],
   "source": [
    "model.unfreeze_backbone()\n",
    "config_stage_2 = config\n",
    "config_stage_2.epochs = 30\n",
    "config_stage_2.lr = 1e-4 # lower learning rate for fine-tuning\n",
    "trainer = SegmentationTrainer(config_stage_2)\n",
    "trained_model = trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a54d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3-small encoder unfrozen: parameters will be updated during training\n",
      "Using device: mps\n",
      "Training configuration:\n",
      "  Use RGB: True\n",
      "  Use Depth: False\n",
      "  Input channels: 3\n",
      "  Label mode: nyu40\n",
      "  Num classes: 40\n",
      "Training samples: 795\n",
      "Validation samples: 100\n",
      "Total parameters: 2,361,960\n",
      "Trainable parameters: 2,361,960\n",
      "Resuming training from: checkpoints/unet_mobilenet/latest2.pth\n",
      "‚úì Resumed from epoch 30\n",
      "‚úì Training history loaded with 30 epochs\n",
      "‚úì Best mIoU so far: 0.1367\n",
      "üîß Applied config overrides:\n",
      "  learning_rate: 0.001000 ‚Üí 0.000100\n",
      "Starting training for 40 epochs (from epoch 31)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31 | Iter 00001] loss=0.8898\n",
      "[Epoch 31 | Iter 00002] loss=0.9343\n",
      "[Epoch 31 | Iter 00003] loss=0.9540\n",
      "[Epoch 31 | Iter 00004] loss=0.9425\n",
      "[Epoch 31 | Iter 00005] loss=0.9420\n",
      "[Epoch 31 | Iter 00006] loss=0.9426\n",
      "[Epoch 31 | Iter 00007] loss=0.9390\n",
      "[Epoch 31 | Iter 00008] loss=0.9503\n",
      "[Epoch 31 | Iter 00009] loss=0.9527\n",
      "[Epoch 31 | Iter 00010] loss=0.9474\n",
      "[Epoch 31 | Iter 00011] loss=0.9365\n",
      "[Epoch 31 | Iter 00012] loss=0.9348\n",
      "[Epoch 31 | Iter 00013] loss=0.9351\n",
      "[Epoch 31 | Iter 00014] loss=0.9344\n",
      "[Epoch 31 | Iter 00015] loss=0.9318\n",
      "[Epoch 31 | Iter 00016] loss=0.9307\n",
      "[Epoch 31 | Iter 00017] loss=0.9302\n",
      "[Epoch 31 | Iter 00018] loss=0.9251\n",
      "[Epoch 31 | Iter 00019] loss=0.9281\n",
      "[Epoch 31 | Iter 00020] loss=0.9283\n",
      "[Epoch 31 | Iter 00021] loss=0.9285\n",
      "[Epoch 31 | Iter 00022] loss=0.9248\n",
      "[Epoch 31 | Iter 00023] loss=0.9185\n",
      "[Epoch 31 | Iter 00024] loss=0.9170\n",
      "[Epoch 31 | Iter 00025] loss=0.9135\n",
      "[Epoch 31] Train: loss=0.8756 mIoU=0.3556 pixacc=0.7464 (35.9s+24.4s, 22.2 smp/s) | Val: loss=1.7044 mIoU=0.1571 pixacc=0.5311 (15.4s, 6.5 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1571) to checkpoints/unet_mobilenet/best2.pth (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(76.4s) | Breakdown: Train(47.0%) Val(20.2%) Save(0.9%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3556) >> Val mIoU (0.1571), gap: 0.1985\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.7044) >> Train loss (0.8756), gap: 0.8287\n",
      "[Epoch 32 | Iter 00001] loss=0.9209\n",
      "[Epoch 32 | Iter 00002] loss=0.8694\n",
      "[Epoch 32 | Iter 00003] loss=0.8627\n",
      "[Epoch 32 | Iter 00004] loss=0.8857\n",
      "[Epoch 32 | Iter 00005] loss=0.8726\n",
      "[Epoch 32 | Iter 00006] loss=0.8713\n",
      "[Epoch 32 | Iter 00007] loss=0.8740\n",
      "[Epoch 32 | Iter 00008] loss=0.8747\n",
      "[Epoch 32 | Iter 00009] loss=0.8768\n",
      "[Epoch 32 | Iter 00010] loss=0.8754\n",
      "[Epoch 32 | Iter 00011] loss=0.8758\n",
      "[Epoch 32 | Iter 00012] loss=0.8779\n",
      "[Epoch 32 | Iter 00013] loss=0.8737\n",
      "[Epoch 32 | Iter 00014] loss=0.8684\n",
      "[Epoch 32 | Iter 00015] loss=0.8763\n",
      "[Epoch 32 | Iter 00016] loss=0.8734\n",
      "[Epoch 32 | Iter 00017] loss=0.8682\n",
      "[Epoch 32 | Iter 00018] loss=0.8741\n",
      "[Epoch 32 | Iter 00019] loss=0.8736\n",
      "[Epoch 32 | Iter 00020] loss=0.8744\n",
      "[Epoch 32 | Iter 00021] loss=0.8733\n",
      "[Epoch 32 | Iter 00022] loss=0.8719\n",
      "[Epoch 32 | Iter 00023] loss=0.8705\n",
      "[Epoch 32 | Iter 00024] loss=0.8704\n",
      "[Epoch 32 | Iter 00025] loss=0.8724\n",
      "[Epoch 32] Train: loss=0.8350 mIoU=0.3758 pixacc=0.7591 (39.2s+23.3s, 20.3 smp/s) | Val: loss=1.6739 mIoU=0.1627 pixacc=0.5444 (14.9s, 6.7 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1627) to checkpoints/unet_mobilenet/best2.pth (0.5s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(26.9MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(78.1s) | Breakdown: Train(50.2%) Val(19.0%) Save(0.9%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3758) >> Val mIoU (0.1627), gap: 0.2131\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.6739) >> Train loss (0.8350), gap: 0.8389\n",
      "[Epoch 33 | Iter 00001] loss=0.8792\n",
      "[Epoch 33 | Iter 00002] loss=0.8426\n",
      "[Epoch 33 | Iter 00003] loss=0.8541\n",
      "[Epoch 33 | Iter 00004] loss=0.8610\n",
      "[Epoch 33 | Iter 00005] loss=0.8419\n",
      "[Epoch 33 | Iter 00006] loss=0.8511\n",
      "[Epoch 33 | Iter 00007] loss=0.8413\n",
      "[Epoch 33 | Iter 00008] loss=0.8399\n",
      "[Epoch 33 | Iter 00009] loss=0.8377\n",
      "[Epoch 33 | Iter 00010] loss=0.8379\n",
      "[Epoch 33 | Iter 00011] loss=0.8375\n",
      "[Epoch 33 | Iter 00012] loss=0.8367\n",
      "[Epoch 33 | Iter 00013] loss=0.8420\n",
      "[Epoch 33 | Iter 00014] loss=0.8414\n",
      "[Epoch 33 | Iter 00015] loss=0.8434\n",
      "[Epoch 33 | Iter 00016] loss=0.8420\n",
      "[Epoch 33 | Iter 00017] loss=0.8399\n",
      "[Epoch 33 | Iter 00018] loss=0.8437\n",
      "[Epoch 33 | Iter 00019] loss=0.8446\n",
      "[Epoch 33 | Iter 00020] loss=0.8445\n",
      "[Epoch 33 | Iter 00021] loss=0.8454\n",
      "[Epoch 33 | Iter 00022] loss=0.8484\n",
      "[Epoch 33 | Iter 00023] loss=0.8490\n",
      "[Epoch 33 | Iter 00024] loss=0.8468\n",
      "[Epoch 33 | Iter 00025] loss=0.8477\n",
      "[Epoch 33] Train: loss=0.8084 mIoU=0.3939 pixacc=0.7684 (36.3s+23.1s, 21.9 smp/s) | Val: loss=1.6669 mIoU=0.1645 pixacc=0.5455 (15.1s, 6.6 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1645) to checkpoints/unet_mobilenet/best2.pth (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(75.2s) | Breakdown: Train(48.3%) Val(20.1%) Save(0.9%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3939) >> Val mIoU (0.1645), gap: 0.2294\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.6669) >> Train loss (0.8084), gap: 0.8585\n",
      "[Epoch 34 | Iter 00001] loss=0.8354\n",
      "[Epoch 34 | Iter 00002] loss=0.8503\n",
      "[Epoch 34 | Iter 00003] loss=0.8637\n",
      "[Epoch 34 | Iter 00004] loss=0.8654\n",
      "[Epoch 34 | Iter 00005] loss=0.8594\n",
      "[Epoch 34 | Iter 00006] loss=0.8541\n",
      "[Epoch 34 | Iter 00007] loss=0.8514\n",
      "[Epoch 34 | Iter 00008] loss=0.8481\n",
      "[Epoch 34 | Iter 00009] loss=0.8443\n",
      "[Epoch 34 | Iter 00010] loss=0.8429\n",
      "[Epoch 34 | Iter 00011] loss=0.8465\n",
      "[Epoch 34 | Iter 00012] loss=0.8440\n",
      "[Epoch 34 | Iter 00013] loss=0.8388\n",
      "[Epoch 34 | Iter 00014] loss=0.8347\n",
      "[Epoch 34 | Iter 00015] loss=0.8318\n",
      "[Epoch 34 | Iter 00016] loss=0.8323\n",
      "[Epoch 34 | Iter 00017] loss=0.8314\n",
      "[Epoch 34 | Iter 00018] loss=0.8367\n",
      "[Epoch 34 | Iter 00019] loss=0.8358\n",
      "[Epoch 34 | Iter 00020] loss=0.8328\n",
      "[Epoch 34 | Iter 00021] loss=0.8319\n",
      "[Epoch 34 | Iter 00022] loss=0.8306\n",
      "[Epoch 34 | Iter 00023] loss=0.8325\n",
      "[Epoch 34 | Iter 00024] loss=0.8310\n",
      "[Epoch 34 | Iter 00025] loss=0.8345\n",
      "[Epoch 34] Train: loss=0.7987 mIoU=0.3989 pixacc=0.7715 (36.2s+21.9s, 22.0 smp/s) | Val: loss=1.6694 mIoU=0.1650 pixacc=0.5431 (14.5s, 6.9 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1650) to checkpoints/unet_mobilenet/best2.pth (0.8s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(1.0s)\n",
      "‚è±Ô∏è  Timing: Save(1.0s) | Total(73.6s) | Breakdown: Train(49.1%) Val(19.7%) Save(1.4%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.3989) >> Val mIoU (0.1650), gap: 0.2339\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.6694) >> Train loss (0.7987), gap: 0.8706\n",
      "[Epoch 35 | Iter 00001] loss=0.7574\n",
      "[Epoch 35 | Iter 00002] loss=0.7838\n",
      "[Epoch 35 | Iter 00003] loss=0.7948\n",
      "[Epoch 35 | Iter 00004] loss=0.8146\n",
      "[Epoch 35 | Iter 00005] loss=0.8114\n",
      "[Epoch 35 | Iter 00006] loss=0.8197\n",
      "[Epoch 35 | Iter 00007] loss=0.8299\n",
      "[Epoch 35 | Iter 00008] loss=0.8359\n",
      "[Epoch 35 | Iter 00009] loss=0.8294\n",
      "[Epoch 35 | Iter 00010] loss=0.8312\n",
      "[Epoch 35 | Iter 00011] loss=0.8353\n",
      "[Epoch 35 | Iter 00012] loss=0.8343\n",
      "[Epoch 35 | Iter 00013] loss=0.8322\n",
      "[Epoch 35 | Iter 00014] loss=0.8284\n",
      "[Epoch 35 | Iter 00015] loss=0.8273\n",
      "[Epoch 35 | Iter 00016] loss=0.8275\n",
      "[Epoch 35 | Iter 00017] loss=0.8224\n",
      "[Epoch 35 | Iter 00018] loss=0.8256\n",
      "[Epoch 35 | Iter 00019] loss=0.8277\n",
      "[Epoch 35 | Iter 00020] loss=0.8235\n",
      "[Epoch 35 | Iter 00021] loss=0.8240\n",
      "[Epoch 35 | Iter 00022] loss=0.8251\n",
      "[Epoch 35 | Iter 00023] loss=0.8269\n",
      "[Epoch 35 | Iter 00024] loss=0.8295\n",
      "[Epoch 35 | Iter 00025] loss=0.8272\n",
      "[Epoch 35] Train: loss=0.7797 mIoU=0.4100 pixacc=0.7775 (36.7s+24.2s, 21.7 smp/s) | Val: loss=1.6715 mIoU=0.1663 pixacc=0.5424 (15.0s, 6.7 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1663) to checkpoints/unet_mobilenet/best2.pth (0.4s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_035.pt (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.9s)\n",
      "‚è±Ô∏è  Timing: Save(0.9s) | Total(76.7s) | Breakdown: Train(47.8%) Val(19.6%) Save(1.2%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4100) >> Val mIoU (0.1663), gap: 0.2437\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.6715) >> Train loss (0.7797), gap: 0.8917\n",
      "[Epoch 36 | Iter 00001] loss=0.7863\n",
      "[Epoch 36 | Iter 00002] loss=0.7862\n",
      "[Epoch 36 | Iter 00003] loss=0.8011\n",
      "[Epoch 36 | Iter 00004] loss=0.8002\n",
      "[Epoch 36 | Iter 00005] loss=0.7995\n",
      "[Epoch 36 | Iter 00006] loss=0.7952\n",
      "[Epoch 36 | Iter 00007] loss=0.7878\n",
      "[Epoch 36 | Iter 00008] loss=0.7900\n",
      "[Epoch 36 | Iter 00009] loss=0.7958\n",
      "[Epoch 36 | Iter 00010] loss=0.8006\n",
      "[Epoch 36 | Iter 00011] loss=0.8024\n",
      "[Epoch 36 | Iter 00012] loss=0.8076\n",
      "[Epoch 36 | Iter 00013] loss=0.8107\n",
      "[Epoch 36 | Iter 00014] loss=0.8091\n",
      "[Epoch 36 | Iter 00015] loss=0.8126\n",
      "[Epoch 36 | Iter 00016] loss=0.8175\n",
      "[Epoch 36 | Iter 00017] loss=0.8148\n",
      "[Epoch 36 | Iter 00018] loss=0.8163\n",
      "[Epoch 36 | Iter 00019] loss=0.8136\n",
      "[Epoch 36 | Iter 00020] loss=0.8121\n",
      "[Epoch 36 | Iter 00021] loss=0.8122\n",
      "[Epoch 36 | Iter 00022] loss=0.8143\n",
      "[Epoch 36 | Iter 00023] loss=0.8145\n",
      "[Epoch 36 | Iter 00024] loss=0.8161\n",
      "[Epoch 36 | Iter 00025] loss=0.8149\n",
      "[Epoch 36] Train: loss=0.7635 mIoU=0.4182 pixacc=0.7822 (37.9s+22.6s, 21.0 smp/s) | Val: loss=1.6738 mIoU=0.1678 pixacc=0.5451 (13.4s, 7.5 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1678) to checkpoints/unet_mobilenet/best2.pth (0.5s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(74.6s) | Breakdown: Train(50.9%) Val(17.9%) Save(0.9%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4182) >> Val mIoU (0.1678), gap: 0.2505\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.6738) >> Train loss (0.7635), gap: 0.9103\n",
      "[Epoch 37 | Iter 00001] loss=0.7794\n",
      "[Epoch 37 | Iter 00002] loss=0.7857\n",
      "[Epoch 37 | Iter 00003] loss=0.7925\n",
      "[Epoch 37 | Iter 00004] loss=0.7924\n",
      "[Epoch 37 | Iter 00005] loss=0.7920\n",
      "[Epoch 37 | Iter 00006] loss=0.7924\n",
      "[Epoch 37 | Iter 00007] loss=0.8004\n",
      "[Epoch 37 | Iter 00008] loss=0.7991\n",
      "[Epoch 37 | Iter 00009] loss=0.7950\n",
      "[Epoch 37 | Iter 00010] loss=0.8000\n",
      "[Epoch 37 | Iter 00011] loss=0.7991\n",
      "[Epoch 37 | Iter 00012] loss=0.8036\n",
      "[Epoch 37 | Iter 00013] loss=0.8038\n",
      "[Epoch 37 | Iter 00014] loss=0.8019\n",
      "[Epoch 37 | Iter 00015] loss=0.8034\n",
      "[Epoch 37 | Iter 00016] loss=0.8036\n",
      "[Epoch 37 | Iter 00017] loss=0.8051\n",
      "[Epoch 37 | Iter 00018] loss=0.8074\n",
      "[Epoch 37 | Iter 00019] loss=0.8080\n",
      "[Epoch 37 | Iter 00020] loss=0.8103\n",
      "[Epoch 37 | Iter 00021] loss=0.8074\n",
      "[Epoch 37 | Iter 00022] loss=0.8075\n",
      "[Epoch 37 | Iter 00023] loss=0.8069\n",
      "[Epoch 37 | Iter 00024] loss=0.8067\n",
      "[Epoch 37 | Iter 00025] loss=0.8082\n",
      "[Epoch 37] Train: loss=0.7666 mIoU=0.4203 pixacc=0.7820 (36.5s+22.7s, 21.8 smp/s) | Val: loss=1.6694 mIoU=0.1693 pixacc=0.5466 (14.6s, 6.8 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1693) to checkpoints/unet_mobilenet/best2.pth (0.5s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(26.9MB) total(0.8s)\n",
      "‚è±Ô∏è  Timing: Save(0.8s) | Total(74.6s) | Breakdown: Train(48.9%) Val(19.6%) Save(1.0%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4203) >> Val mIoU (0.1693), gap: 0.2510\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.6694) >> Train loss (0.7666), gap: 0.9028\n",
      "[Epoch 38 | Iter 00001] loss=0.7970\n",
      "[Epoch 38 | Iter 00002] loss=0.8136\n",
      "[Epoch 38 | Iter 00003] loss=0.7841\n",
      "[Epoch 38 | Iter 00004] loss=0.7683\n",
      "[Epoch 38 | Iter 00005] loss=0.7811\n",
      "[Epoch 38 | Iter 00006] loss=0.8046\n",
      "[Epoch 38 | Iter 00007] loss=0.8116\n",
      "[Epoch 38 | Iter 00008] loss=0.8091\n",
      "[Epoch 38 | Iter 00009] loss=0.8063\n",
      "[Epoch 38 | Iter 00010] loss=0.8044\n",
      "[Epoch 38 | Iter 00011] loss=0.8044\n",
      "[Epoch 38 | Iter 00012] loss=0.8104\n",
      "[Epoch 38 | Iter 00013] loss=0.8148\n",
      "[Epoch 38 | Iter 00014] loss=0.8129\n",
      "[Epoch 38 | Iter 00015] loss=0.8114\n",
      "[Epoch 38 | Iter 00016] loss=0.8059\n",
      "[Epoch 38 | Iter 00017] loss=0.8032\n",
      "[Epoch 38 | Iter 00018] loss=0.8031\n",
      "[Epoch 38 | Iter 00019] loss=0.8054\n",
      "[Epoch 38 | Iter 00020] loss=0.8028\n",
      "[Epoch 38 | Iter 00021] loss=0.8043\n",
      "[Epoch 38 | Iter 00022] loss=0.8062\n",
      "[Epoch 38 | Iter 00023] loss=0.8038\n",
      "[Epoch 38 | Iter 00024] loss=0.8032\n",
      "[Epoch 38 | Iter 00025] loss=0.8031\n",
      "[Epoch 38] Train: loss=0.7530 mIoU=0.4256 pixacc=0.7850 (36.4s+24.3s, 21.8 smp/s) | Val: loss=1.6784 mIoU=0.1706 pixacc=0.5455 (14.5s, 6.9 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1706) to checkpoints/unet_mobilenet/best2.pth (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.7s)\n",
      "‚è±Ô∏è  Timing: Save(0.7s) | Total(75.9s) | Breakdown: Train(48.0%) Val(19.1%) Save(0.9%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4256) >> Val mIoU (0.1706), gap: 0.2550\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.6784) >> Train loss (0.7530), gap: 0.9254\n",
      "[Epoch 39 | Iter 00001] loss=0.7904\n",
      "[Epoch 39 | Iter 00002] loss=0.7984\n",
      "[Epoch 39 | Iter 00003] loss=0.7883\n",
      "[Epoch 39 | Iter 00004] loss=0.7916\n",
      "[Epoch 39 | Iter 00005] loss=0.7866\n",
      "[Epoch 39 | Iter 00006] loss=0.7759\n",
      "[Epoch 39 | Iter 00007] loss=0.7733\n",
      "[Epoch 39 | Iter 00008] loss=0.7713\n",
      "[Epoch 39 | Iter 00009] loss=0.7727\n",
      "[Epoch 39 | Iter 00010] loss=0.7856\n",
      "[Epoch 39 | Iter 00011] loss=0.7911\n",
      "[Epoch 39 | Iter 00012] loss=0.7926\n",
      "[Epoch 39 | Iter 00013] loss=0.7972\n",
      "[Epoch 39 | Iter 00014] loss=0.7954\n",
      "[Epoch 39 | Iter 00015] loss=0.7960\n",
      "[Epoch 39 | Iter 00016] loss=0.7930\n",
      "[Epoch 39 | Iter 00017] loss=0.7933\n",
      "[Epoch 39 | Iter 00018] loss=0.7931\n",
      "[Epoch 39 | Iter 00019] loss=0.7916\n",
      "[Epoch 39 | Iter 00020] loss=0.7892\n",
      "[Epoch 39 | Iter 00021] loss=0.7895\n",
      "[Epoch 39 | Iter 00022] loss=0.7925\n",
      "[Epoch 39 | Iter 00023] loss=0.7912\n",
      "[Epoch 39 | Iter 00024] loss=0.7920\n",
      "[Epoch 39 | Iter 00025] loss=0.7937\n",
      "[Epoch 39] Train: loss=0.7467 mIoU=0.4344 pixacc=0.7879 (37.2s+23.0s, 21.4 smp/s) | Val: loss=1.6739 mIoU=0.1732 pixacc=0.5489 (14.6s, 6.9 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1732) to checkpoints/unet_mobilenet/best2.pth (0.4s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.6s)\n",
      "‚è±Ô∏è  Timing: Save(0.6s) | Total(75.4s) | Breakdown: Train(49.4%) Val(19.4%) Save(0.8%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4344) >> Val mIoU (0.1732), gap: 0.2613\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.6739) >> Train loss (0.7467), gap: 0.9271\n",
      "[Epoch 40 | Iter 00001] loss=0.7916\n",
      "[Epoch 40 | Iter 00002] loss=0.7853\n",
      "[Epoch 40 | Iter 00003] loss=0.7735\n",
      "[Epoch 40 | Iter 00004] loss=0.7554\n",
      "[Epoch 40 | Iter 00005] loss=0.7595\n",
      "[Epoch 40 | Iter 00006] loss=0.7622\n",
      "[Epoch 40 | Iter 00007] loss=0.7657\n",
      "[Epoch 40 | Iter 00008] loss=0.7765\n",
      "[Epoch 40 | Iter 00009] loss=0.7816\n",
      "[Epoch 40 | Iter 00010] loss=0.7827\n",
      "[Epoch 40 | Iter 00011] loss=0.7865\n",
      "[Epoch 40 | Iter 00012] loss=0.7885\n",
      "[Epoch 40 | Iter 00013] loss=0.7880\n",
      "[Epoch 40 | Iter 00014] loss=0.7882\n",
      "[Epoch 40 | Iter 00015] loss=0.7848\n",
      "[Epoch 40 | Iter 00016] loss=0.7832\n",
      "[Epoch 40 | Iter 00017] loss=0.7781\n",
      "[Epoch 40 | Iter 00018] loss=0.7779\n",
      "[Epoch 40 | Iter 00019] loss=0.7781\n",
      "[Epoch 40 | Iter 00020] loss=0.7747\n",
      "[Epoch 40 | Iter 00021] loss=0.7743\n",
      "[Epoch 40 | Iter 00022] loss=0.7770\n",
      "[Epoch 40 | Iter 00023] loss=0.7762\n",
      "[Epoch 40 | Iter 00024] loss=0.7766\n",
      "[Epoch 40 | Iter 00025] loss=0.7745\n",
      "[Epoch 40] Train: loss=0.7426 mIoU=0.4390 pixacc=0.7911 (35.5s+22.6s, 22.4 smp/s) | Val: loss=1.6835 mIoU=0.1687 pixacc=0.5464 (13.8s, 7.2 smp/s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_040.pt (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.5s)\n",
      "‚è±Ô∏è  Timing: Save(0.5s) | Total(72.3s) | Breakdown: Train(49.0%) Val(19.1%) Save(0.6%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4390) >> Val mIoU (0.1687), gap: 0.2703\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.6835) >> Train loss (0.7426), gap: 0.9409\n",
      "Training complete!\n",
      "Best mIoU: 0.1732\n",
      "\n",
      "üîÑ Loading best model for final evaluation...\n",
      "Final validation metrics: loss=1.6739 mIoU=0.1732, PixelAcc=0.5489 (load: 0.2s, eval: 14.6s)\n"
     ]
    }
   ],
   "source": [
    "# reload SegmentationTrainer with new config\n",
    "model.unfreeze_backbone()\n",
    "config_stage_2 = config\n",
    "config_stage_2.epochs = 40\n",
    "config_stage_2.lr = 1e-4 # lower learning rate for fine-tuning\n",
    "trainer = SegmentationTrainer(config_stage_2)\n",
    "trained_model = trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525a2f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3-small encoder unfrozen: parameters will be updated during training\n",
      "Using device: mps\n",
      "EarlyStopping: monitoring 'val_miou' with patience=5 (mode=max)\n",
      "Training configuration:\n",
      "  Use RGB: True\n",
      "  Use Depth: False\n",
      "  Input channels: 3\n",
      "  Label mode: nyu40\n",
      "  Num classes: 40\n",
      "Training samples: 795\n",
      "Validation samples: 100\n",
      "Total parameters: 2,361,960\n",
      "Trainable parameters: 2,361,960\n",
      "Resuming training from: checkpoints/unet_mobilenet/latest2.pth\n",
      "‚úì Resumed from epoch 40\n",
      "‚úì Training history loaded with 40 epochs\n",
      "‚úì Best mIoU so far: 0.1732\n",
      "‚úì No optimizer parameter changes needed\n",
      "Starting training for 50 epochs (from epoch 41)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41 | Iter 00001] loss=0.7218\n",
      "[Epoch 41 | Iter 00002] loss=0.7464\n",
      "[Epoch 41 | Iter 00003] loss=0.7663\n",
      "[Epoch 41 | Iter 00004] loss=0.7557\n",
      "[Epoch 41 | Iter 00005] loss=0.7623\n",
      "[Epoch 41 | Iter 00006] loss=0.7714\n",
      "[Epoch 41 | Iter 00007] loss=0.7703\n",
      "[Epoch 41 | Iter 00008] loss=0.7830\n",
      "[Epoch 41 | Iter 00009] loss=0.7879\n",
      "[Epoch 41 | Iter 00010] loss=0.7843\n",
      "[Epoch 41 | Iter 00011] loss=0.7767\n",
      "[Epoch 41 | Iter 00012] loss=0.7764\n",
      "[Epoch 41 | Iter 00013] loss=0.7783\n",
      "[Epoch 41 | Iter 00014] loss=0.7791\n",
      "[Epoch 41 | Iter 00015] loss=0.7783\n",
      "[Epoch 41 | Iter 00016] loss=0.7788\n",
      "[Epoch 41 | Iter 00017] loss=0.7794\n",
      "[Epoch 41 | Iter 00018] loss=0.7752\n",
      "[Epoch 41 | Iter 00019] loss=0.7787\n",
      "[Epoch 41 | Iter 00020] loss=0.7805\n",
      "[Epoch 41 | Iter 00021] loss=0.7823\n",
      "[Epoch 41 | Iter 00022] loss=0.7803\n",
      "[Epoch 41 | Iter 00023] loss=0.7758\n",
      "[Epoch 41 | Iter 00024] loss=0.7752\n",
      "[Epoch 41 | Iter 00025] loss=0.7733\n",
      "[Epoch 41] Train: loss=0.7339 mIoU=0.4419 pixacc=0.7923 (36.6s+25.1s, 21.7 smp/s) | Val: loss=1.6903 mIoU=0.1681 pixacc=0.5408 (16.4s, 6.1 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(26.9MB) total(0.3s)\n",
      "‚è±Ô∏è  Timing: Save(0.3s) | Total(78.4s) | Breakdown: Train(46.7%) Val(20.9%) Save(0.4%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4419) >> Val mIoU (0.1681), gap: 0.2738\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.6903) >> Train loss (0.7339), gap: 0.9564\n",
      "[Epoch 42 | Iter 00001] loss=0.7993\n",
      "[Epoch 42 | Iter 00002] loss=0.7568\n",
      "[Epoch 42 | Iter 00003] loss=0.7535\n",
      "[Epoch 42 | Iter 00004] loss=0.7684\n",
      "[Epoch 42 | Iter 00005] loss=0.7599\n",
      "[Epoch 42 | Iter 00006] loss=0.7586\n",
      "[Epoch 42 | Iter 00007] loss=0.7612\n",
      "[Epoch 42 | Iter 00008] loss=0.7646\n",
      "[Epoch 42 | Iter 00009] loss=0.7660\n",
      "[Epoch 42 | Iter 00010] loss=0.7658\n",
      "[Epoch 42 | Iter 00011] loss=0.7665\n",
      "[Epoch 42 | Iter 00012] loss=0.7693\n",
      "[Epoch 42 | Iter 00013] loss=0.7660\n",
      "[Epoch 42 | Iter 00014] loss=0.7617\n",
      "[Epoch 42 | Iter 00015] loss=0.7687\n",
      "[Epoch 42 | Iter 00016] loss=0.7668\n",
      "[Epoch 42 | Iter 00017] loss=0.7624\n",
      "[Epoch 42 | Iter 00018] loss=0.7682\n",
      "[Epoch 42 | Iter 00019] loss=0.7685\n",
      "[Epoch 42 | Iter 00020] loss=0.7693\n",
      "[Epoch 42 | Iter 00021] loss=0.7687\n",
      "[Epoch 42 | Iter 00022] loss=0.7677\n",
      "[Epoch 42 | Iter 00023] loss=0.7670\n",
      "[Epoch 42 | Iter 00024] loss=0.7674\n",
      "[Epoch 42 | Iter 00025] loss=0.7696\n",
      "[Epoch 42] Train: loss=0.7287 mIoU=0.4477 pixacc=0.7937 (38.2s+24.3s, 20.8 smp/s) | Val: loss=1.6921 mIoU=0.1692 pixacc=0.5491 (14.8s, 6.7 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(26.9MB) total(0.3s)\n",
      "‚è±Ô∏è  Timing: Save(0.3s) | Total(77.5s) | Breakdown: Train(49.2%) Val(19.1%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4477) >> Val mIoU (0.1692), gap: 0.2785\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.6921) >> Train loss (0.7287), gap: 0.9633\n",
      "[Epoch 43 | Iter 00001] loss=0.7829\n",
      "[Epoch 43 | Iter 00002] loss=0.7504\n",
      "[Epoch 43 | Iter 00003] loss=0.7597\n",
      "[Epoch 43 | Iter 00004] loss=0.7669\n",
      "[Epoch 43 | Iter 00005] loss=0.7509\n",
      "[Epoch 43 | Iter 00006] loss=0.7587\n",
      "[Epoch 43 | Iter 00007] loss=0.7511\n",
      "[Epoch 43 | Iter 00008] loss=0.7500\n",
      "[Epoch 43 | Iter 00009] loss=0.7482\n",
      "[Epoch 43 | Iter 00010] loss=0.7483\n",
      "[Epoch 43 | Iter 00011] loss=0.7472\n",
      "[Epoch 43 | Iter 00012] loss=0.7470\n",
      "[Epoch 43 | Iter 00013] loss=0.7514\n",
      "[Epoch 43 | Iter 00014] loss=0.7509\n",
      "[Epoch 43 | Iter 00015] loss=0.7534\n",
      "[Epoch 43 | Iter 00016] loss=0.7526\n",
      "[Epoch 43 | Iter 00017] loss=0.7508\n",
      "[Epoch 43 | Iter 00018] loss=0.7543\n",
      "[Epoch 43 | Iter 00019] loss=0.7553\n",
      "[Epoch 43 | Iter 00020] loss=0.7551\n",
      "[Epoch 43 | Iter 00021] loss=0.7557\n",
      "[Epoch 43 | Iter 00022] loss=0.7579\n",
      "[Epoch 43 | Iter 00023] loss=0.7591\n",
      "[Epoch 43 | Iter 00024] loss=0.7573\n",
      "[Epoch 43 | Iter 00025] loss=0.7580\n",
      "[Epoch 43] Train: loss=0.7213 mIoU=0.4584 pixacc=0.7978 (38.9s+24.0s, 20.5 smp/s) | Val: loss=1.7041 mIoU=0.1670 pixacc=0.5444 (15.2s, 6.6 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.2s)\n",
      "‚è±Ô∏è  Timing: Save(0.2s) | Total(78.3s) | Breakdown: Train(49.6%) Val(19.4%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4584) >> Val mIoU (0.1670), gap: 0.2914\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.7041) >> Train loss (0.7213), gap: 0.9828\n",
      "[Epoch 44 | Iter 00001] loss=0.7461\n",
      "[Epoch 44 | Iter 00002] loss=0.7649\n",
      "[Epoch 44 | Iter 00003] loss=0.7764\n",
      "[Epoch 44 | Iter 00004] loss=0.7807\n",
      "[Epoch 44 | Iter 00005] loss=0.7743\n",
      "[Epoch 44 | Iter 00006] loss=0.7694\n",
      "[Epoch 44 | Iter 00007] loss=0.7659\n",
      "[Epoch 44 | Iter 00008] loss=0.7631\n",
      "[Epoch 44 | Iter 00009] loss=0.7605\n",
      "[Epoch 44 | Iter 00010] loss=0.7589\n",
      "[Epoch 44 | Iter 00011] loss=0.7613\n",
      "[Epoch 44 | Iter 00012] loss=0.7593\n",
      "[Epoch 44 | Iter 00013] loss=0.7550\n",
      "[Epoch 44 | Iter 00014] loss=0.7518\n",
      "[Epoch 44 | Iter 00015] loss=0.7494\n",
      "[Epoch 44 | Iter 00016] loss=0.7496\n",
      "[Epoch 44 | Iter 00017] loss=0.7490\n",
      "[Epoch 44 | Iter 00018] loss=0.7536\n",
      "[Epoch 44 | Iter 00019] loss=0.7534\n",
      "[Epoch 44 | Iter 00020] loss=0.7505\n",
      "[Epoch 44 | Iter 00021] loss=0.7495\n",
      "[Epoch 44 | Iter 00022] loss=0.7484\n",
      "[Epoch 44 | Iter 00023] loss=0.7505\n",
      "[Epoch 44 | Iter 00024] loss=0.7496\n",
      "[Epoch 44 | Iter 00025] loss=0.7527\n",
      "[Epoch 44] Train: loss=0.7160 mIoU=0.4571 pixacc=0.7981 (37.3s+24.9s, 21.3 smp/s) | Val: loss=1.7069 mIoU=0.1678 pixacc=0.5415 (14.8s, 6.7 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.2s)\n",
      "‚è±Ô∏è  Timing: Save(0.2s) | Total(77.2s) | Breakdown: Train(48.3%) Val(19.2%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4571) >> Val mIoU (0.1678), gap: 0.2892\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.7069) >> Train loss (0.7160), gap: 0.9909\n",
      "[Epoch 45 | Iter 00001] loss=0.6777\n",
      "[Epoch 45 | Iter 00002] loss=0.7048\n",
      "[Epoch 45 | Iter 00003] loss=0.7130\n",
      "[Epoch 45 | Iter 00004] loss=0.7314\n",
      "[Epoch 45 | Iter 00005] loss=0.7291\n",
      "[Epoch 45 | Iter 00006] loss=0.7378\n",
      "[Epoch 45 | Iter 00007] loss=0.7469\n",
      "[Epoch 45 | Iter 00008] loss=0.7522\n",
      "[Epoch 45 | Iter 00009] loss=0.7468\n",
      "[Epoch 45 | Iter 00010] loss=0.7480\n",
      "[Epoch 45 | Iter 00011] loss=0.7519\n",
      "[Epoch 45 | Iter 00012] loss=0.7520\n",
      "[Epoch 45 | Iter 00013] loss=0.7502\n",
      "[Epoch 45 | Iter 00014] loss=0.7468\n",
      "[Epoch 45 | Iter 00015] loss=0.7461\n",
      "[Epoch 45 | Iter 00016] loss=0.7462\n",
      "[Epoch 45 | Iter 00017] loss=0.7418\n",
      "[Epoch 45 | Iter 00018] loss=0.7457\n",
      "[Epoch 45 | Iter 00019] loss=0.7479\n",
      "[Epoch 45 | Iter 00020] loss=0.7439\n",
      "[Epoch 45 | Iter 00021] loss=0.7447\n",
      "[Epoch 45 | Iter 00022] loss=0.7455\n",
      "[Epoch 45 | Iter 00023] loss=0.7472\n",
      "[Epoch 45 | Iter 00024] loss=0.7499\n",
      "[Epoch 45 | Iter 00025] loss=0.7482\n",
      "[Epoch 45] Train: loss=0.7022 mIoU=0.4680 pixacc=0.8031 (41.9s+23.0s, 19.0 smp/s) | Val: loss=1.7146 mIoU=0.1694 pixacc=0.5405 (15.1s, 6.6 smp/s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_045.pt (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.4s)\n",
      "‚è±Ô∏è  Timing: Save(0.4s) | Total(80.5s) | Breakdown: Train(52.1%) Val(18.8%) Save(0.6%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4680) >> Val mIoU (0.1694), gap: 0.2985\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.7146) >> Train loss (0.7022), gap: 1.0123\n",
      "[Epoch 46 | Iter 00001] loss=0.7043\n",
      "[Epoch 46 | Iter 00002] loss=0.7082\n",
      "[Epoch 46 | Iter 00003] loss=0.7211\n",
      "[Epoch 46 | Iter 00004] loss=0.7209\n",
      "[Epoch 46 | Iter 00005] loss=0.7214\n",
      "[Epoch 46 | Iter 00006] loss=0.7190\n",
      "[Epoch 46 | Iter 00007] loss=0.7123\n",
      "[Epoch 46 | Iter 00008] loss=0.7145\n",
      "[Epoch 46 | Iter 00009] loss=0.7194\n",
      "[Epoch 46 | Iter 00010] loss=0.7232\n",
      "[Epoch 46 | Iter 00011] loss=0.7242\n",
      "[Epoch 46 | Iter 00012] loss=0.7300\n",
      "[Epoch 46 | Iter 00013] loss=0.7330\n",
      "[Epoch 46 | Iter 00014] loss=0.7319\n",
      "[Epoch 46 | Iter 00015] loss=0.7358\n",
      "[Epoch 46 | Iter 00016] loss=0.7404\n",
      "[Epoch 46 | Iter 00017] loss=0.7381\n",
      "[Epoch 46 | Iter 00018] loss=0.7393\n",
      "[Epoch 46 | Iter 00019] loss=0.7369\n",
      "[Epoch 46 | Iter 00020] loss=0.7356\n",
      "[Epoch 46 | Iter 00021] loss=0.7356\n",
      "[Epoch 46 | Iter 00022] loss=0.7377\n",
      "[Epoch 46 | Iter 00023] loss=0.7374\n",
      "[Epoch 46 | Iter 00024] loss=0.7390\n",
      "[Epoch 46 | Iter 00025] loss=0.7379\n",
      "[Epoch 46] Train: loss=0.6934 mIoU=0.4708 pixacc=0.8048 (37.0s+23.4s, 21.5 smp/s) | Val: loss=1.7151 mIoU=0.1722 pixacc=0.5451 (14.9s, 6.7 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.2s)\n",
      "‚è±Ô∏è  Timing: Save(0.2s) | Total(75.5s) | Breakdown: Train(49.0%) Val(19.7%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4708) >> Val mIoU (0.1722), gap: 0.2986\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.7151) >> Train loss (0.6934), gap: 1.0217\n",
      "[Epoch 47 | Iter 00001] loss=0.7086\n",
      "[Epoch 47 | Iter 00002] loss=0.7121\n",
      "[Epoch 47 | Iter 00003] loss=0.7175\n",
      "[Epoch 47 | Iter 00004] loss=0.7189\n",
      "[Epoch 47 | Iter 00005] loss=0.7183\n",
      "[Epoch 47 | Iter 00006] loss=0.7196\n",
      "[Epoch 47 | Iter 00007] loss=0.7273\n",
      "[Epoch 47 | Iter 00008] loss=0.7268\n",
      "[Epoch 47 | Iter 00009] loss=0.7222\n",
      "[Epoch 47 | Iter 00010] loss=0.7258\n",
      "[Epoch 47 | Iter 00011] loss=0.7249\n",
      "[Epoch 47 | Iter 00012] loss=0.7288\n",
      "[Epoch 47 | Iter 00013] loss=0.7291\n",
      "[Epoch 47 | Iter 00014] loss=0.7269\n",
      "[Epoch 47 | Iter 00015] loss=0.7282\n",
      "[Epoch 47 | Iter 00016] loss=0.7285\n",
      "[Epoch 47 | Iter 00017] loss=0.7303\n",
      "[Epoch 47 | Iter 00018] loss=0.7326\n",
      "[Epoch 47 | Iter 00019] loss=0.7333\n",
      "[Epoch 47 | Iter 00020] loss=0.7355\n",
      "[Epoch 47 | Iter 00021] loss=0.7329\n",
      "[Epoch 47 | Iter 00022] loss=0.7327\n",
      "[Epoch 47 | Iter 00023] loss=0.7320\n",
      "[Epoch 47 | Iter 00024] loss=0.7322\n",
      "[Epoch 47 | Iter 00025] loss=0.7335\n",
      "[Epoch 47] Train: loss=0.6937 mIoU=0.4770 pixacc=0.8060 (36.6s+25.2s, 21.7 smp/s) | Val: loss=1.7100 mIoU=0.1726 pixacc=0.5442 (15.4s, 6.5 smp/s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.2s)\n",
      "‚è±Ô∏è  Timing: Save(0.2s) | Total(77.4s) | Breakdown: Train(47.3%) Val(19.9%) Save(0.3%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4770) >> Val mIoU (0.1726), gap: 0.3044\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.7100) >> Train loss (0.6937), gap: 1.0163\n",
      "[Epoch 48 | Iter 00001] loss=0.7246\n",
      "[Epoch 48 | Iter 00002] loss=0.7421\n",
      "[Epoch 48 | Iter 00003] loss=0.7123\n",
      "[Epoch 48 | Iter 00004] loss=0.6981\n",
      "[Epoch 48 | Iter 00005] loss=0.7082\n",
      "[Epoch 48 | Iter 00006] loss=0.7290\n",
      "[Epoch 48 | Iter 00007] loss=0.7358\n",
      "[Epoch 48 | Iter 00008] loss=0.7340\n",
      "[Epoch 48 | Iter 00009] loss=0.7315\n",
      "[Epoch 48 | Iter 00010] loss=0.7297\n",
      "[Epoch 48 | Iter 00011] loss=0.7303\n",
      "[Epoch 48 | Iter 00012] loss=0.7360\n",
      "[Epoch 48 | Iter 00013] loss=0.7398\n",
      "[Epoch 48 | Iter 00014] loss=0.7381\n",
      "[Epoch 48 | Iter 00015] loss=0.7372\n",
      "[Epoch 48 | Iter 00016] loss=0.7324\n",
      "[Epoch 48 | Iter 00017] loss=0.7296\n",
      "[Epoch 48 | Iter 00018] loss=0.7296\n",
      "[Epoch 48 | Iter 00019] loss=0.7319\n",
      "[Epoch 48 | Iter 00020] loss=0.7296\n",
      "[Epoch 48 | Iter 00021] loss=0.7308\n",
      "[Epoch 48 | Iter 00022] loss=0.7330\n",
      "[Epoch 48 | Iter 00023] loss=0.7307\n",
      "[Epoch 48 | Iter 00024] loss=0.7299\n",
      "[Epoch 48 | Iter 00025] loss=0.7295\n",
      "[Epoch 48] Train: loss=0.6821 mIoU=0.4808 pixacc=0.8084 (36.6s+22.4s, 21.7 smp/s) | Val: loss=1.7291 mIoU=0.1742 pixacc=0.5423 (14.9s, 6.7 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1742) to checkpoints/unet_mobilenet/best2.pth (0.8s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(1.0s)\n",
      "‚è±Ô∏è  Timing: Save(1.0s) | Total(74.9s) | Breakdown: Train(48.8%) Val(19.9%) Save(1.4%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4808) >> Val mIoU (0.1742), gap: 0.3067\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.7291) >> Train loss (0.6821), gap: 1.0470\n",
      "[Epoch 49 | Iter 00001] loss=0.7217\n",
      "[Epoch 49 | Iter 00002] loss=0.7291\n",
      "[Epoch 49 | Iter 00003] loss=0.7188\n",
      "[Epoch 49 | Iter 00004] loss=0.7188\n",
      "[Epoch 49 | Iter 00005] loss=0.7139\n",
      "[Epoch 49 | Iter 00006] loss=0.7037\n",
      "[Epoch 49 | Iter 00007] loss=0.7025\n",
      "[Epoch 49 | Iter 00008] loss=0.7008\n",
      "[Epoch 49 | Iter 00009] loss=0.7020\n",
      "[Epoch 49 | Iter 00010] loss=0.7135\n",
      "[Epoch 49 | Iter 00011] loss=0.7188\n",
      "[Epoch 49 | Iter 00012] loss=0.7209\n",
      "[Epoch 49 | Iter 00013] loss=0.7254\n",
      "[Epoch 49 | Iter 00014] loss=0.7238\n",
      "[Epoch 49 | Iter 00015] loss=0.7239\n",
      "[Epoch 49 | Iter 00016] loss=0.7215\n",
      "[Epoch 49 | Iter 00017] loss=0.7215\n",
      "[Epoch 49 | Iter 00018] loss=0.7215\n",
      "[Epoch 49 | Iter 00019] loss=0.7202\n",
      "[Epoch 49 | Iter 00020] loss=0.7178\n",
      "[Epoch 49 | Iter 00021] loss=0.7182\n",
      "[Epoch 49 | Iter 00022] loss=0.7210\n",
      "[Epoch 49 | Iter 00023] loss=0.7198\n",
      "[Epoch 49 | Iter 00024] loss=0.7205\n",
      "[Epoch 49 | Iter 00025] loss=0.7219\n",
      "[Epoch 49] Train: loss=0.6794 mIoU=0.4844 pixacc=0.8091 (38.4s+25.7s, 20.7 smp/s) | Val: loss=1.7260 mIoU=0.1776 pixacc=0.5464 (15.0s, 6.7 smp/s)\n",
      "‚úì Saved best checkpoint (mIoU=0.1776) to checkpoints/unet_mobilenet/best2.pth (0.5s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.3s) size(26.9MB) total(0.8s)\n",
      "‚è±Ô∏è  Timing: Save(0.8s) | Total(79.8s) | Breakdown: Train(48.1%) Val(18.8%) Save(1.0%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4844) >> Val mIoU (0.1776), gap: 0.3068\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.7260) >> Train loss (0.6794), gap: 1.0467\n",
      "[Epoch 50 | Iter 00001] loss=0.7204\n",
      "[Epoch 50 | Iter 00002] loss=0.7143\n",
      "[Epoch 50 | Iter 00003] loss=0.7041\n",
      "[Epoch 50 | Iter 00004] loss=0.6875\n",
      "[Epoch 50 | Iter 00005] loss=0.6921\n",
      "[Epoch 50 | Iter 00006] loss=0.6940\n",
      "[Epoch 50 | Iter 00007] loss=0.6963\n",
      "[Epoch 50 | Iter 00008] loss=0.7064\n",
      "[Epoch 50 | Iter 00009] loss=0.7111\n",
      "[Epoch 50 | Iter 00010] loss=0.7116\n",
      "[Epoch 50 | Iter 00011] loss=0.7158\n",
      "[Epoch 50 | Iter 00012] loss=0.7167\n",
      "[Epoch 50 | Iter 00013] loss=0.7166\n",
      "[Epoch 50 | Iter 00014] loss=0.7164\n",
      "[Epoch 50 | Iter 00015] loss=0.7138\n",
      "[Epoch 50 | Iter 00016] loss=0.7119\n",
      "[Epoch 50 | Iter 00017] loss=0.7075\n",
      "[Epoch 50 | Iter 00018] loss=0.7071\n",
      "[Epoch 50 | Iter 00019] loss=0.7071\n",
      "[Epoch 50 | Iter 00020] loss=0.7042\n",
      "[Epoch 50 | Iter 00021] loss=0.7039\n",
      "[Epoch 50 | Iter 00022] loss=0.7066\n",
      "[Epoch 50 | Iter 00023] loss=0.7055\n",
      "[Epoch 50 | Iter 00024] loss=0.7061\n",
      "[Epoch 50 | Iter 00025] loss=0.7042\n",
      "[Epoch 50] Train: loss=0.6747 mIoU=0.4873 pixacc=0.8115 (48.3s+24.7s, 16.5 smp/s) | Val: loss=1.7393 mIoU=0.1714 pixacc=0.5430 (15.0s, 6.7 smp/s)\n",
      "‚úì Saved periodic checkpoint to checkpoint_epoch_050.pt (0.2s)\n",
      "üíæ Checkpoint timing: prep(0.0s) latest(0.2s) size(26.9MB) total(0.5s)\n",
      "‚è±Ô∏è  Timing: Save(0.5s) | Total(88.4s) | Breakdown: Train(54.6%) Val(16.9%) Save(0.5%)\n",
      "‚ö†Ô∏è  Potential overfitting: Train mIoU (0.4873) >> Val mIoU (0.1714), gap: 0.3159\n",
      "‚ö†Ô∏è  Potential overfitting: Val loss (1.7393) >> Train loss (0.6747), gap: 1.0646\n",
      "Training complete!\n",
      "Best mIoU: 0.1776\n",
      "\n",
      "üîÑ Loading best model for final evaluation...\n",
      "Final validation metrics: loss=1.7260 mIoU=0.1776, PixelAcc=0.5464 (load: 0.2s, eval: 15.1s)\n"
     ]
    }
   ],
   "source": [
    "# now do so with early stopping\n",
    "model.unfreeze_backbone()\n",
    "config_stage_3 = config\n",
    "config_stage_3.epochs = 50\n",
    "config_stage_3.lr = 1e-4 \n",
    "trainer = SegmentationTrainer(config_stage_3)\n",
    "trained_model = trainer.train(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
