{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf04d1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Library/Frameworks/Python.framework/Versions/3.10/lib/python310.zip', '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10', '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload', '', '/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages', '/var/folders/ns/l6n061w51tsbx932m6xf8w3m0000gn/T/tmpdb8dpupp']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "from src.training import SegmentationTrainer, TrainingConfig\n",
    "from src.models.unet_mobilenet import build_unet_mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa5499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageNet pretrained MobileNetV3-Small weights...\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /Users/reubendrummond/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully loaded ImageNet pretrained MobileNetV3-Small weights\n",
      "UNet-MobileNetV3-SMALL initialized:\n",
      "  Total parameters: 2,361,960\n",
      "  Trainable parameters: 2,361,960\n",
      "  Encoder channels: [16, 16, 24, 48, 96]\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "config = TrainingConfig(\n",
    "      data_root=\"datasets/NYUDepthv2\",\n",
    "      use_rgb=True,\n",
    "      use_depth=False,\n",
    "      lr=1e-4,\n",
    "      epochs=10,\n",
    "      batch_size=32,\n",
    "      device=\"auto\",\n",
    "      save_best_path=\"checkpoints/unet_mobilenet/best2.pth\",\n",
    "      save_latest_path=\"checkpoints/unet_mobilenet/latest2.pth\",\n",
    "      num_classes=40,\n",
    ")\n",
    "\n",
    "# Create model and train\n",
    "model = build_unet_mobilenet(num_classes=config.num_classes)\n",
    "\n",
    "trainer = SegmentationTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7b1f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3-small encoder frozen: parameters will not be updated during training\n",
      "Training configuration:\n",
      "  Use RGB: True\n",
      "  Use Depth: False\n",
      "  Input channels: 3\n",
      "  Label mode: nyu40\n",
      "  Num classes: 40\n",
      "Training samples: 795\n",
      "Validation samples: 654\n",
      "Total parameters: 2,361,960\n",
      "Trainable parameters: 1,434,952\n",
      "Starting training for 10 epochs (from epoch 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reubendrummond/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 | Iter 00001] loss=3.7258\n",
      "[Epoch 1 | Iter 00002] loss=3.7248\n",
      "[Epoch 1 | Iter 00003] loss=3.7251\n",
      "[Epoch 1 | Iter 00004] loss=3.7235\n",
      "[Epoch 1 | Iter 00005] loss=3.7232\n",
      "[Epoch 1 | Iter 00006] loss=3.7233\n",
      "[Epoch 1 | Iter 00007] loss=3.7240\n",
      "[Epoch 1 | Iter 00008] loss=3.7235\n",
      "[Epoch 1 | Iter 00009] loss=3.7210\n",
      "[Epoch 1 | Iter 00010] loss=3.7210\n",
      "[Epoch 1 | Iter 00011] loss=3.7198\n",
      "[Epoch 1 | Iter 00012] loss=3.7191\n",
      "[Epoch 1 | Iter 00013] loss=3.7174\n",
      "[Epoch 1 | Iter 00014] loss=3.7164\n",
      "[Epoch 1 | Iter 00015] loss=3.7160\n",
      "[Epoch 1 | Iter 00016] loss=3.7145\n",
      "[Epoch 1 | Iter 00017] loss=3.7131\n",
      "[Epoch 1 | Iter 00018] loss=3.7115\n",
      "[Epoch 1 | Iter 00019] loss=3.7109\n",
      "[Epoch 1 | Iter 00020] loss=3.7104\n",
      "[Epoch 1 | Iter 00021] loss=3.7100\n",
      "[Epoch 1 | Iter 00022] loss=3.7093\n",
      "[Epoch 1 | Iter 00023] loss=3.7086\n",
      "[Epoch 1 | Iter 00024] loss=3.7077\n",
      "[Epoch 1 | Iter 00025] loss=3.7069\n",
      "[Epoch 1] Train: loss=3.7069 | Val: mIoU=0.0023 PixelAcc=0.0129 (time 139.7s)\n",
      "✓ Saved best checkpoint (mIoU=0.0023) to checkpoints/unet_mobilenet/best.pth\n",
      "✓ Saved latest checkpoint to checkpoints/unet_mobilenet/latest.pth\n",
      "[Epoch 2 | Iter 00001] loss=3.6821\n",
      "[Epoch 2 | Iter 00002] loss=3.6836\n",
      "[Epoch 2 | Iter 00003] loss=3.6808\n",
      "[Epoch 2 | Iter 00004] loss=3.6812\n",
      "[Epoch 2 | Iter 00005] loss=3.6818\n",
      "[Epoch 2 | Iter 00006] loss=3.6803\n",
      "[Epoch 2 | Iter 00007] loss=3.6780\n",
      "[Epoch 2 | Iter 00008] loss=3.6761\n",
      "[Epoch 2 | Iter 00009] loss=3.6738\n",
      "[Epoch 2 | Iter 00010] loss=3.6709\n",
      "[Epoch 2 | Iter 00011] loss=3.6690\n",
      "[Epoch 2 | Iter 00012] loss=3.6674\n",
      "[Epoch 2 | Iter 00013] loss=3.6671\n",
      "[Epoch 2 | Iter 00014] loss=3.6656\n",
      "[Epoch 2 | Iter 00015] loss=3.6640\n",
      "[Epoch 2 | Iter 00016] loss=3.6627\n",
      "[Epoch 2 | Iter 00017] loss=3.6611\n",
      "[Epoch 2 | Iter 00018] loss=3.6598\n",
      "[Epoch 2 | Iter 00019] loss=3.6596\n",
      "[Epoch 2 | Iter 00020] loss=3.6592\n",
      "[Epoch 2 | Iter 00021] loss=3.6581\n",
      "[Epoch 2 | Iter 00022] loss=3.6561\n",
      "[Epoch 2 | Iter 00023] loss=3.6551\n",
      "[Epoch 2 | Iter 00024] loss=3.6538\n",
      "[Epoch 2 | Iter 00025] loss=3.6531\n",
      "[Epoch 2] Train: loss=3.6531 | Val: mIoU=0.0086 PixelAcc=0.0679 (time 191.1s)\n",
      "✓ Saved best checkpoint (mIoU=0.0086) to checkpoints/unet_mobilenet/best.pth\n",
      "✓ Saved latest checkpoint to checkpoints/unet_mobilenet/latest.pth\n",
      "[Epoch 3 | Iter 00001] loss=3.6226\n",
      "[Epoch 3 | Iter 00002] loss=3.6134\n",
      "[Epoch 3 | Iter 00003] loss=3.6114\n",
      "[Epoch 3 | Iter 00004] loss=3.6148\n",
      "[Epoch 3 | Iter 00005] loss=3.6109\n",
      "[Epoch 3 | Iter 00006] loss=3.6122\n",
      "[Epoch 3 | Iter 00007] loss=3.6119\n",
      "[Epoch 3 | Iter 00008] loss=3.6098\n",
      "[Epoch 3 | Iter 00009] loss=3.6086\n",
      "[Epoch 3 | Iter 00010] loss=3.6078\n",
      "[Epoch 3 | Iter 00011] loss=3.6053\n",
      "[Epoch 3 | Iter 00012] loss=3.6033\n",
      "[Epoch 3 | Iter 00013] loss=3.6025\n",
      "[Epoch 3 | Iter 00014] loss=3.6006\n",
      "[Epoch 3 | Iter 00015] loss=3.5989\n",
      "[Epoch 3 | Iter 00016] loss=3.5982\n",
      "[Epoch 3 | Iter 00017] loss=3.5969\n",
      "[Epoch 3 | Iter 00018] loss=3.5960\n",
      "[Epoch 3 | Iter 00019] loss=3.5946\n",
      "[Epoch 3 | Iter 00020] loss=3.5940\n",
      "[Epoch 3 | Iter 00021] loss=3.5929\n",
      "[Epoch 3 | Iter 00022] loss=3.5925\n",
      "[Epoch 3 | Iter 00023] loss=3.5911\n",
      "[Epoch 3 | Iter 00024] loss=3.5905\n",
      "[Epoch 3 | Iter 00025] loss=3.5893\n",
      "[Epoch 3] Train: loss=3.5893 | Val: mIoU=0.0127 PixelAcc=0.1078 (time 129.8s)\n",
      "✓ Saved best checkpoint (mIoU=0.0127) to checkpoints/unet_mobilenet/best.pth\n",
      "✓ Saved latest checkpoint to checkpoints/unet_mobilenet/latest.pth\n",
      "[Epoch 4 | Iter 00001] loss=3.5307\n",
      "[Epoch 4 | Iter 00002] loss=3.5381\n",
      "[Epoch 4 | Iter 00003] loss=3.5468\n",
      "[Epoch 4 | Iter 00004] loss=3.5503\n",
      "[Epoch 4 | Iter 00005] loss=3.5483\n",
      "[Epoch 4 | Iter 00006] loss=3.5443\n",
      "[Epoch 4 | Iter 00007] loss=3.5409\n",
      "[Epoch 4 | Iter 00008] loss=3.5404\n",
      "[Epoch 4 | Iter 00009] loss=3.5385\n",
      "[Epoch 4 | Iter 00010] loss=3.5365\n",
      "[Epoch 4 | Iter 00011] loss=3.5375\n",
      "[Epoch 4 | Iter 00012] loss=3.5372\n",
      "[Epoch 4 | Iter 00013] loss=3.5346\n",
      "[Epoch 4 | Iter 00014] loss=3.5344\n",
      "[Epoch 4 | Iter 00015] loss=3.5336\n",
      "[Epoch 4 | Iter 00016] loss=3.5343\n",
      "[Epoch 4 | Iter 00017] loss=3.5325\n",
      "[Epoch 4 | Iter 00018] loss=3.5297\n",
      "[Epoch 4 | Iter 00019] loss=3.5280\n",
      "[Epoch 4 | Iter 00020] loss=3.5259\n",
      "[Epoch 4 | Iter 00021] loss=3.5240\n",
      "[Epoch 4 | Iter 00022] loss=3.5223\n",
      "[Epoch 4 | Iter 00023] loss=3.5205\n",
      "[Epoch 4 | Iter 00024] loss=3.5195\n",
      "[Epoch 4 | Iter 00025] loss=3.5185\n",
      "[Epoch 4] Train: loss=3.5185 | Val: mIoU=0.0217 PixelAcc=0.1750 (time 162.1s)\n",
      "✓ Saved best checkpoint (mIoU=0.0217) to checkpoints/unet_mobilenet/best.pth\n",
      "✓ Saved latest checkpoint to checkpoints/unet_mobilenet/latest.pth\n",
      "[Epoch 5 | Iter 00001] loss=3.5000\n",
      "[Epoch 5 | Iter 00002] loss=3.4788\n",
      "[Epoch 5 | Iter 00003] loss=3.4750\n",
      "[Epoch 5 | Iter 00004] loss=3.4732\n",
      "[Epoch 5 | Iter 00005] loss=3.4743\n",
      "[Epoch 5 | Iter 00006] loss=3.4722\n",
      "[Epoch 5 | Iter 00007] loss=3.4699\n",
      "[Epoch 5 | Iter 00008] loss=3.4676\n",
      "[Epoch 5 | Iter 00009] loss=3.4666\n",
      "[Epoch 5 | Iter 00010] loss=3.4638\n",
      "[Epoch 5 | Iter 00011] loss=3.4613\n",
      "[Epoch 5 | Iter 00012] loss=3.4602\n",
      "[Epoch 5 | Iter 00013] loss=3.4588\n",
      "[Epoch 5 | Iter 00014] loss=3.4572\n",
      "[Epoch 5 | Iter 00015] loss=3.4564\n",
      "[Epoch 5 | Iter 00016] loss=3.4544\n",
      "[Epoch 5 | Iter 00017] loss=3.4526\n",
      "[Epoch 5 | Iter 00018] loss=3.4532\n",
      "[Epoch 5 | Iter 00019] loss=3.4512\n",
      "[Epoch 5 | Iter 00020] loss=3.4498\n",
      "[Epoch 5 | Iter 00021] loss=3.4484\n",
      "[Epoch 5 | Iter 00022] loss=3.4467\n",
      "[Epoch 5 | Iter 00023] loss=3.4447\n",
      "[Epoch 5 | Iter 00024] loss=3.4431\n",
      "[Epoch 5 | Iter 00025] loss=3.4418\n",
      "[Epoch 5] Train: loss=3.4418 | Val: mIoU=0.0258 PixelAcc=0.2029 (time 139.5s)\n",
      "✓ Saved best checkpoint (mIoU=0.0258) to checkpoints/unet_mobilenet/best.pth\n",
      "✓ Saved periodic checkpoint to checkpoint_epoch_005.pt\n",
      "✓ Saved latest checkpoint to checkpoints/unet_mobilenet/latest.pth\n",
      "[Epoch 6 | Iter 00001] loss=3.3909\n",
      "[Epoch 6 | Iter 00002] loss=3.3926\n",
      "[Epoch 6 | Iter 00003] loss=3.3954\n",
      "[Epoch 6 | Iter 00004] loss=3.3934\n",
      "[Epoch 6 | Iter 00005] loss=3.3923\n",
      "[Epoch 6 | Iter 00006] loss=3.3921\n",
      "[Epoch 6 | Iter 00007] loss=3.3924\n",
      "[Epoch 6 | Iter 00008] loss=3.3926\n",
      "[Epoch 6 | Iter 00009] loss=3.3902\n",
      "[Epoch 6 | Iter 00010] loss=3.3894\n",
      "[Epoch 6 | Iter 00011] loss=3.3895\n",
      "[Epoch 6 | Iter 00012] loss=3.3886\n",
      "[Epoch 6 | Iter 00013] loss=3.3868\n",
      "[Epoch 6 | Iter 00014] loss=3.3832\n",
      "[Epoch 6 | Iter 00015] loss=3.3809\n",
      "[Epoch 6 | Iter 00016] loss=3.3808\n",
      "[Epoch 6 | Iter 00017] loss=3.3783\n",
      "[Epoch 6 | Iter 00018] loss=3.3785\n",
      "[Epoch 6 | Iter 00019] loss=3.3767\n",
      "[Epoch 6 | Iter 00020] loss=3.3743\n",
      "[Epoch 6 | Iter 00021] loss=3.3723\n",
      "[Epoch 6 | Iter 00022] loss=3.3702\n",
      "[Epoch 6 | Iter 00023] loss=3.3701\n",
      "[Epoch 6 | Iter 00024] loss=3.3678\n",
      "[Epoch 6 | Iter 00025] loss=3.3671\n",
      "[Epoch 6] Train: loss=3.3671 | Val: mIoU=0.0333 PixelAcc=0.2443 (time 139.2s)\n",
      "✓ Saved best checkpoint (mIoU=0.0333) to checkpoints/unet_mobilenet/best.pth\n",
      "✓ Saved latest checkpoint to checkpoints/unet_mobilenet/latest.pth\n",
      "[Epoch 7 | Iter 00001] loss=3.3309\n",
      "[Epoch 7 | Iter 00002] loss=3.3305\n",
      "[Epoch 7 | Iter 00003] loss=3.3258\n",
      "[Epoch 7 | Iter 00004] loss=3.3318\n",
      "[Epoch 7 | Iter 00005] loss=3.3296\n",
      "[Epoch 7 | Iter 00006] loss=3.3265\n",
      "[Epoch 7 | Iter 00007] loss=3.3274\n",
      "[Epoch 7 | Iter 00008] loss=3.3264\n",
      "[Epoch 7 | Iter 00009] loss=3.3224\n",
      "[Epoch 7 | Iter 00010] loss=3.3154\n",
      "[Epoch 7 | Iter 00011] loss=3.3131\n",
      "[Epoch 7 | Iter 00012] loss=3.3103\n",
      "[Epoch 7 | Iter 00013] loss=3.3127\n",
      "[Epoch 7 | Iter 00014] loss=3.3100\n",
      "[Epoch 7 | Iter 00015] loss=3.3074\n",
      "[Epoch 7 | Iter 00016] loss=3.3049\n",
      "[Epoch 7 | Iter 00017] loss=3.3038\n",
      "[Epoch 7 | Iter 00018] loss=3.3023\n",
      "[Epoch 7 | Iter 00019] loss=3.3018\n",
      "[Epoch 7 | Iter 00020] loss=3.3006\n",
      "[Epoch 7 | Iter 00021] loss=3.3009\n",
      "[Epoch 7 | Iter 00022] loss=3.2971\n",
      "[Epoch 7 | Iter 00023] loss=3.2960\n",
      "[Epoch 7 | Iter 00024] loss=3.2937\n",
      "[Epoch 7 | Iter 00025] loss=3.2914\n",
      "[Epoch 7] Train: loss=3.2914 | Val: mIoU=0.0351 PixelAcc=0.2750 (time 145.2s)\n",
      "✓ Saved best checkpoint (mIoU=0.0351) to checkpoints/unet_mobilenet/best.pth\n",
      "✓ Saved latest checkpoint to checkpoints/unet_mobilenet/latest.pth\n",
      "[Epoch 8 | Iter 00001] loss=3.2556\n",
      "[Epoch 8 | Iter 00002] loss=3.2645\n",
      "[Epoch 8 | Iter 00003] loss=3.2586\n",
      "[Epoch 8 | Iter 00004] loss=3.2460\n",
      "[Epoch 8 | Iter 00005] loss=3.2483\n",
      "[Epoch 8 | Iter 00006] loss=3.2475\n",
      "[Epoch 8 | Iter 00007] loss=3.2426\n",
      "[Epoch 8 | Iter 00008] loss=3.2432\n",
      "[Epoch 8 | Iter 00009] loss=3.2408\n",
      "[Epoch 8 | Iter 00010] loss=3.2375\n",
      "[Epoch 8 | Iter 00011] loss=3.2347\n",
      "[Epoch 8 | Iter 00012] loss=3.2338\n",
      "[Epoch 8 | Iter 00013] loss=3.2292\n",
      "[Epoch 8 | Iter 00014] loss=3.2268\n",
      "[Epoch 8 | Iter 00015] loss=3.2271\n",
      "[Epoch 8 | Iter 00016] loss=3.2270\n",
      "[Epoch 8 | Iter 00017] loss=3.2260\n",
      "[Epoch 8 | Iter 00018] loss=3.2227\n",
      "[Epoch 8 | Iter 00019] loss=3.2206\n",
      "[Epoch 8 | Iter 00020] loss=3.2197\n",
      "[Epoch 8 | Iter 00021] loss=3.2171\n",
      "[Epoch 8 | Iter 00022] loss=3.2163\n",
      "[Epoch 8 | Iter 00023] loss=3.2154\n",
      "[Epoch 8 | Iter 00024] loss=3.2148\n",
      "[Epoch 8 | Iter 00025] loss=3.2127\n",
      "[Epoch 8] Train: loss=3.2127 | Val: mIoU=0.0428 PixelAcc=0.3374 (time 132.6s)\n",
      "✓ Saved best checkpoint (mIoU=0.0428) to checkpoints/unet_mobilenet/best.pth\n",
      "✓ Saved latest checkpoint to checkpoints/unet_mobilenet/latest.pth\n",
      "[Epoch 9 | Iter 00001] loss=3.1439\n",
      "[Epoch 9 | Iter 00002] loss=3.1325\n",
      "[Epoch 9 | Iter 00003] loss=3.1556\n",
      "[Epoch 9 | Iter 00004] loss=3.1609\n",
      "[Epoch 9 | Iter 00005] loss=3.1581\n",
      "[Epoch 9 | Iter 00006] loss=3.1616\n",
      "[Epoch 9 | Iter 00007] loss=3.1626\n",
      "[Epoch 9 | Iter 00008] loss=3.1585\n",
      "[Epoch 9 | Iter 00009] loss=3.1589\n",
      "[Epoch 9 | Iter 00010] loss=3.1554\n",
      "[Epoch 9 | Iter 00011] loss=3.1557\n",
      "[Epoch 9 | Iter 00012] loss=3.1529\n",
      "[Epoch 9 | Iter 00013] loss=3.1526\n",
      "[Epoch 9 | Iter 00014] loss=3.1515\n",
      "[Epoch 9 | Iter 00015] loss=3.1490\n",
      "[Epoch 9 | Iter 00016] loss=3.1445\n",
      "[Epoch 9 | Iter 00017] loss=3.1431\n",
      "[Epoch 9 | Iter 00018] loss=3.1403\n",
      "[Epoch 9 | Iter 00019] loss=3.1376\n",
      "[Epoch 9 | Iter 00020] loss=3.1364\n",
      "[Epoch 9 | Iter 00021] loss=3.1349\n",
      "[Epoch 9 | Iter 00022] loss=3.1339\n",
      "[Epoch 9 | Iter 00023] loss=3.1339\n",
      "[Epoch 9 | Iter 00024] loss=3.1321\n",
      "[Epoch 9 | Iter 00025] loss=3.1307\n",
      "[Epoch 9] Train: loss=3.1307 | Val: mIoU=0.0446 PixelAcc=0.3531 (time 139.0s)\n",
      "✓ Saved best checkpoint (mIoU=0.0446) to checkpoints/unet_mobilenet/best.pth\n",
      "✓ Saved latest checkpoint to checkpoints/unet_mobilenet/latest.pth\n",
      "[Epoch 10 | Iter 00001] loss=3.0570\n",
      "[Epoch 10 | Iter 00002] loss=3.0589\n",
      "[Epoch 10 | Iter 00003] loss=3.0577\n",
      "[Epoch 10 | Iter 00004] loss=3.0561\n",
      "[Epoch 10 | Iter 00005] loss=3.0605\n",
      "[Epoch 10 | Iter 00006] loss=3.0684\n",
      "[Epoch 10 | Iter 00007] loss=3.0638\n",
      "[Epoch 10 | Iter 00008] loss=3.0602\n",
      "[Epoch 10 | Iter 00009] loss=3.0563\n",
      "[Epoch 10 | Iter 00010] loss=3.0611\n",
      "[Epoch 10 | Iter 00011] loss=3.0570\n",
      "[Epoch 10 | Iter 00012] loss=3.0587\n",
      "[Epoch 10 | Iter 00013] loss=3.0646\n",
      "[Epoch 10 | Iter 00014] loss=3.0652\n",
      "[Epoch 10 | Iter 00015] loss=3.0633\n",
      "[Epoch 10 | Iter 00016] loss=3.0619\n",
      "[Epoch 10 | Iter 00017] loss=3.0573\n",
      "[Epoch 10 | Iter 00018] loss=3.0561\n",
      "[Epoch 10 | Iter 00019] loss=3.0525\n",
      "[Epoch 10 | Iter 00020] loss=3.0502\n",
      "[Epoch 10 | Iter 00021] loss=3.0519\n",
      "[Epoch 10 | Iter 00022] loss=3.0517\n",
      "[Epoch 10 | Iter 00023] loss=3.0502\n",
      "[Epoch 10 | Iter 00024] loss=3.0497\n",
      "[Epoch 10 | Iter 00025] loss=3.0486\n",
      "[Epoch 10] Train: loss=3.0486 | Val: mIoU=0.0439 PixelAcc=0.3807 (time 150.0s)\n",
      "✓ Saved periodic checkpoint to checkpoint_epoch_010.pt\n",
      "✓ Saved latest checkpoint to checkpoints/unet_mobilenet/latest.pth\n",
      "Training complete!\n",
      "Best mIoU: 0.0446\n",
      "Final validation metrics: mIoU=0.0446, PixelAcc=0.3531\n"
     ]
    }
   ],
   "source": [
    "model.freeze_backbone()\n",
    "trained_model = trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2cf87a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3-small encoder unfrozen: parameters will be updated during training\n",
      "Using device: mps\n",
      "Training configuration:\n",
      "  Use RGB: True\n",
      "  Use Depth: False\n",
      "  Input channels: 3\n",
      "  Label mode: nyu40\n",
      "  Num classes: 40\n",
      "Training samples: 795\n",
      "Validation samples: 654\n",
      "Total parameters: 2,361,960\n",
      "Trainable parameters: 2,361,960\n",
      "Resuming training from: checkpoints/unet_mobilenet/latest.pth\n",
      "✓ Resumed from epoch 10\n",
      "✓ Training history loaded with 10 epochs\n",
      "✓ Best mIoU so far: 0.0446\n",
      "Starting training for 15 epochs (from epoch 11)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(52496) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(52497) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11 | Iter 00001] loss=2.9414\n",
      "[Epoch 11 | Iter 00002] loss=2.9626\n",
      "[Epoch 11 | Iter 00003] loss=2.9820\n",
      "[Epoch 11 | Iter 00004] loss=2.9879\n",
      "[Epoch 11 | Iter 00005] loss=2.9907\n",
      "[Epoch 11 | Iter 00006] loss=2.9940\n",
      "[Epoch 11 | Iter 00007] loss=2.9976\n",
      "[Epoch 11 | Iter 00008] loss=3.0042\n",
      "[Epoch 11 | Iter 00009] loss=3.0024\n",
      "[Epoch 11 | Iter 00010] loss=3.0022\n",
      "[Epoch 11 | Iter 00011] loss=2.9973\n",
      "[Epoch 11 | Iter 00012] loss=2.9946\n",
      "[Epoch 11 | Iter 00013] loss=2.9913\n",
      "[Epoch 11 | Iter 00014] loss=2.9912\n",
      "[Epoch 11 | Iter 00015] loss=2.9891\n",
      "[Epoch 11 | Iter 00016] loss=2.9875\n",
      "[Epoch 11 | Iter 00017] loss=2.9882\n",
      "[Epoch 11 | Iter 00018] loss=2.9854\n",
      "[Epoch 11 | Iter 00019] loss=2.9843\n",
      "[Epoch 11 | Iter 00020] loss=2.9855\n",
      "[Epoch 11 | Iter 00021] loss=2.9845\n",
      "[Epoch 11 | Iter 00022] loss=2.9796\n",
      "[Epoch 11 | Iter 00023] loss=2.9753\n",
      "[Epoch 11 | Iter 00024] loss=2.9723\n",
      "[Epoch 11 | Iter 00025] loss=2.9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(52623) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(52624) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train: loss=2.9700 | Val: mIoU=0.0450 PixelAcc=0.3761 (time 159.0s)\n",
      "✓ Saved best checkpoint (mIoU=0.0450) to checkpoints/unet_mobilenet/best.pth\n",
      "✓ Saved latest checkpoint to checkpoints/unet_mobilenet/latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(53536) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53537) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12 | Iter 00001] loss=2.9519\n",
      "[Epoch 12 | Iter 00002] loss=2.9427\n",
      "[Epoch 12 | Iter 00003] loss=2.9397\n",
      "[Epoch 12 | Iter 00004] loss=2.9232\n",
      "[Epoch 12 | Iter 00005] loss=2.9364\n",
      "[Epoch 12 | Iter 00006] loss=2.9313\n",
      "[Epoch 12 | Iter 00007] loss=2.9257\n",
      "[Epoch 12 | Iter 00008] loss=2.9165\n",
      "[Epoch 12 | Iter 00009] loss=2.9159\n",
      "[Epoch 12 | Iter 00010] loss=2.9070\n",
      "[Epoch 12 | Iter 00011] loss=2.9002\n",
      "[Epoch 12 | Iter 00012] loss=2.8983\n",
      "[Epoch 12 | Iter 00013] loss=2.8983\n",
      "[Epoch 12 | Iter 00014] loss=2.9000\n",
      "[Epoch 12 | Iter 00015] loss=2.8970\n",
      "[Epoch 12 | Iter 00016] loss=2.8927\n",
      "[Epoch 12 | Iter 00017] loss=2.8918\n",
      "[Epoch 12 | Iter 00018] loss=2.8885\n",
      "[Epoch 12 | Iter 00019] loss=2.8902\n",
      "[Epoch 12 | Iter 00020] loss=2.8896\n",
      "[Epoch 12 | Iter 00021] loss=2.8890\n",
      "[Epoch 12 | Iter 00022] loss=2.8841\n",
      "[Epoch 12 | Iter 00023] loss=2.8803\n",
      "[Epoch 12 | Iter 00024] loss=2.8781\n",
      "[Epoch 12 | Iter 00025] loss=2.8781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(53765) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53766) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train: loss=2.8781 | Val: mIoU=0.0429 PixelAcc=0.3922 (time 154.2s)\n",
      "✓ Saved latest checkpoint to checkpoints/unet_mobilenet/latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(53941) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53942) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13 | Iter 00001] loss=2.8465\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m config_stage_2\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-5\u001b[39m \u001b[38;5;66;03m# lower learning rate for fine-tuning\u001b[39;00m\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SegmentationTrainer(config_stage_2)\n\u001b[0;32m----> 6\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/src/training/trainer.py:200\u001b[0m, in \u001b[0;36mSegmentationTrainer.train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Backward pass with gradient scaling\u001b[39;00m\n\u001b[1;32m    199\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 200\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    203\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:388\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke ``unscale_(optimizer)`` followed by parameter update, if gradients are not infs/NaN.\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m:meth:`step` carries out the following two operations:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    Closure use is not currently supported.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enabled:\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosure\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClosure use is not currently supported if GradScaler is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:516\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    512\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    513\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m             )\n\u001b[0;32m--> 516\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:81\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     80\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 81\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/optim/adam.py:247\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    235\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    237\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    238\u001b[0m         group,\n\u001b[1;32m    239\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    244\u001b[0m         state_steps,\n\u001b[1;32m    245\u001b[0m     )\n\u001b[0;32m--> 247\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupled_weight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:149\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/optim/adam.py:949\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    947\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 949\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/optim/adam.py:517\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    515\u001b[0m         param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 517\u001b[0m     step \u001b[38;5;241m=\u001b[39m \u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstep\n\u001b[1;32m    520\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstep\n",
      "File \u001b[0;32m~/Desktop/Uni/2025/Sem2/EGH444/EGH444-Group-10/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:96\u001b[0m, in \u001b[0;36m_get_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.unfreeze_backbone()\n",
    "config_stage_2 = config\n",
    "config_stage_2.epochs = 15\n",
    "config_stage_2.lr = 1e-5 # lower learning rate for fine-tuning\n",
    "trainer = SegmentationTrainer(config_stage_2)\n",
    "trained_model = trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a54d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
